FaceDetectionandModelingforRecognition
By
Rein-LienHsu
ADissertation
Submittedto
MichiganStateUniversity
inpartialful¯llmentoftherequirements
forthedegreeof
DOCTOROFPHILOSOPHY
DepartmentofComputerScience&Engineering
2002
Abstract
FaceDetectionandModelingforRecognition
By
Rein-LienHsu
Facerecognitionhasreceivedsubstantialattentionfromresearchersinbiometrics,
computervision,patternrecognition,andcognitivepsychologycommunitiesbecause
oftheincreasedattentionbeingdevotedtosecurity,man-machinecommunication,
content-basedimageretrieval,andimage/videocoding.Wehaveproposedtwoau-
tomatedrecognitionparadigmstoadvancefacerecognitiontechnology.Threemajor
tasksinvolvedinfacerecognitionsystemsare:(i)facedetection,(ii)facemodeling,
and(iii)facematching.Wehavedevelopedafacedetectionalgorithmforcolorimages
inthepresenceofvariouslightingconditionsaswellascomplexbackgrounds.Our
detectionmethod¯rstcorrectsthecolorbiasbyalightingcompensationtechnique
thatautomaticallyestimatestheparametersofreferencewhiteforcolorcorrection.
Weovercamethedi±cultyofdetectingthelow-lumaandhigh-lumaskintonesby
applyinganonlineartransformationtothe
YC
b
C
r
colorspace.Ourmethodgener-
atesfacecandidatesbasedonthespatialarrangementofdetectedskinpatches.We
constructedeye,mouth,andfaceboundarymapstoverifyeachfacecandidate.Ex-
perimentalresultsdemonstratesuccessfuldetectionoffaceswithdi®erentsizes,color,
position,scale,orientation,3Dpose,andexpressioninseveralphotocollections.
3Dhumanfacemodelsaugmenttheappearance-basedfacerecognitionapproaches
toassistfacerecognitionundertheilluminationandheadposevariations.Forthetwo
proposedrecognitionparadigms,wehavedesignedtwomethodsformodelinghuman
facesbasedon(i)ageneric3Dfacemodelandanindividual'sfacialmeasurementsof
shapeandtexturecapturedinthefrontalview,and(ii)alignmentofasemanticface
graph,derivedfromageneric3Dfacemodel,ontoafrontalfaceimage.Ourmod-
elingmethodsadaptrecognition-orientedfacialfeaturesofagenericmodeltothose
extractedfromfacialmeasurementsinaglobal-to-localfashion.The¯rstmodeling
methodusesdisplacementpropagationand2.5Dsnakesformodelalignment.The
resulting3Dfacemodelisvisuallysimilartothetrueface,andprovestobequite
usefulforrecognizingnon-frontalviewsbasedonanappearance-basedrecognition
algorithm.Thesecondmodelingmethodusesinteractingsnakesforgraphalignment.
Asuccessfulinteractionofsnakes(associatedwitheyes,mouth,nose,etc.)resultsin
appropriatecomponentweightsbasedondistinctivenessandvisibilityofindividual
facialcomponents.Afteralignment,facialcomponentsaretransformedtoafeature
spaceandweightedforsemanticfacematching.Thesemanticfacegraphfacilitates
facematchingbasedonselectedcomponents,ande®ective3Dmodelupdatingbased
on2Dimages.Theresultsoffacematchingdemonstratethattheproposedmodel
canleadtoclassi¯cationandvisualization(e.g.,thegenerationofcartoonfacesand
facialcaricatures)ofhumanfacesusingthederivedsemanticfacegraphs.
c
°
Copyright2002byRein-LienHsu
AllRightsReserved
Tomyparents;mylovelywife,Pei-Jing;andmyson,Alan
v
Acknowledgments
Firstofall,Iwouldliketothankalltheindividualswhohavehelpedmeduring
myPh.D.studyatMichiganStateUniversity.Iwouldliketoexpressmydeepest
gratitudetomyadvisor,Dr.AnilK.Jain,forhisguidanceinacademicresearchand
hissupportindailylife.Hebroadenedmyviewinresearchareas,especiallyinpattern
recognitionandcomputervision,andtaughtmehowtofocusonresearchproblems.
Iwillneverforgethisadvice\Justdoit,"whilebeingcaughtinmultipletasksatthe
sametime.IamgratefultomyPh.D.committee,Dr.MohamedAbdel-Mottaleb,
Dr.GeorgeStockman,Dr.JohnJ.Weng,andDr.SaratC.Dass,fortheirvaluable
ideas,suggestions,andencouragement.
IwouldalsoliketothankDr.Chaur-ChinChenandDr.Wey-ShiuanHwang
fortheirhelpatthebeginningofmystudyatMSU,andDr.ShaoyunChenand
YonghongLifortheirhelpintheNASAmodelingproject.IamverygratefultoDr.
HelenShenandDr.MihranTuceryanfortheirnumeroussuggestionsanddiscussions
onmodelcompression.SpecialthanksareduetoPhilipsResearch-USAforo®ering
mesummerinternshipsin2000and2001;toDr.MohamedAbdel-Mottalebfor
hisguidanceandsuggestionsinmyworkonfacedetection;toDr.PatrickFlynn
vi
forprovidingtherangedatasets;toDr.Wey-ShiuanHwangforprovidinghisface
recognitionsoftware;andtoDennisBondforhishelpincreatingagraphicaluser
interfaceforfaceediting.
ThanksarealsoduetoCathyM.Davison,LindaMoore,StarrPortice,andBeverly
J.Wallacefortheirassistanceintheadministrativetasks.Specialthankstoallthe
Prippies:LinHong,AdityaVailaya,NicolaeDuta,SalilPrabhakar,DanGutchess,
PaulAlbee,ArunRoss,AnoopNamboodiri,SilviuMinut,UmutUludag,Xiaoguang
Lu,MartinLaw,MiguelFigueroa-Villanue,andYiluZhangfortheirhelpduringmy
stayinthePRIPLabintheDepartmentofComputerScienceandEngineeringat
MSU.IwouldalsoliketothankMichaelE.Farmerforgivingmeanopportunityto
workonhumantrackingresearch.
IwouldliketothankMarkH.McCullenformentoringmetobeateachingas-
sistantinCSE232;Dr.Je®reyA.FesslerattheUniversityofMichigan,AnnArbor,
forhisvaluablehelpduringmytransfertotheDept.ofComputerScienceatMichi-
ganStateUniversity;andDr.Yung-NienSunandDr.Chin-HsingCheninTaiwan
fortheirencouragementandspiritualsupport.SpecialthankstoNASA,Philips
Research-USA,Eatoncorporation,andONR(grantNO.N00014-01-1-0266)fortheir
¯nancialsupportduringmyPh.Dstudies.
Finally,butnottheleast,Iwouldliketothankmyparents,mywife,Dr.Pei-jing
Li,andmyson,Alan,forallthehappinesstheyhavesharedwithme.
vii
TableofContents
LISTOFTABLESx
LISTOFFIGURESxi
1Introduction1
1.1ChallengesinFaceRecognition.......................2
1.2SemanticFacialComponents.........................7
1.3FaceRecognitionSystems..........................13
1.4FaceDetectionandRecognition.......................15
1.5FaceModelingforRecognition........................19
1.5.1FaceAlignmentUsing2.5DSnakes....................23
1.5.2ModelCompression.............................23
1.5.3FaceAlignmentUsingInteractingSnakes.................25
1.6FaceRetrieval.................................26
1.7OutlineofDissertation............................28
1.8DissertationContributions..........................28
2LiteratureReview33
2.1FaceDetection................................33
2.2FaceRecognition...............................38
2.3FaceModeling.................................47
2.3.1GenericFaceModels............................47
2.3.2SnakesforFaceAlignment.........................50
2.3.33DModelCompression..........................52
2.4FaceRetrieval.................................54
2.5Summary...................................55
3FaceDetection58
3.1FaceDetectionAlgorithm..........................58
3.2LightingCompensationandSkinToneDetection.............61
3.3LocalizationofFacialFeatures........................69
3.3.1EyeMap..................................70
3.3.2MouthMap.................................73
3.3.3EyeandMouthCandidates........................74
3.3.4FaceBoundaryMap............................76
3.3.5WeightSelectionforaFaceCandidate..................79
3.4ExperimentalResults.............................82
3.5Summary...................................95
viii
4FaceModeling97
4.1ModelingMethod...............................97
4.2GenericFaceModel..............................99
4.3FacialMeasurements.............................101
4.4ModelConstruction..............................103
4.5Summary...................................110
5SemanticFaceRecognition111
5.1SemanticFaceGraphasMultipleSnakes..................112
5.2CoarseAlignmentofSemanticFaceGraph.................115
5.3FineAlignmentofSemanticFaceGraphviaInteractingSnakes.....118
5.3.1InteractingSnakesandEnergyFunctional................120
5.3.2ParametricActiveContours........................127
5.3.3GeodesicActiveContours.........................127
5.4SemanticFaceMatching...........................130
5.4.1ComponentWeightsandMatchingCost.................132
5.4.2FaceMatchingAlgorithm.........................133
5.4.3FaceMatching...............................134
5.5FacialCaricaturesforRecognitionandVisualization...........140
5.6Summary...................................143
6ConclusionsandFutureDirections144
6.1Conclusions..................................144
6.2FutureDirections...............................147
6.2.1FaceDetection&Tracking.........................147
6.2.2FaceModeling...............................149
6.2.3Facematching...............................151
APPENDICES153
ATransformationofColorSpace153
A.1LinearTransformation............................153
A.2NonlinearTransformation..........................154
A.3SkinClassi¯er.................................156
BDistancebetweenSkinPatches157
CImageProcessingTemplateLibrary(IPTL)160
C.1ImageandImageTemplate.........................160
C.2ExampleCode................................163
BIBLIOGRAPHY165
ix
ListofTables
2.1Summaryofvariousfacedetectionapproaches................34
2.2Geometriccompressione±ciency.......................53
2.3Summaryofperformanceofvariousfacedetectionapproaches.......56
3.1DetectionresultsontheHHIimagedatabase(Imagesize640
£
480)ona
PCwith1.7GHzCPU.FP:FalsePositives,DR:DetectionRate...88
3.2DetectionresultsontheChampiondatabase(Imagesize
»
150
£
220)on
aPCwith860MHzCPU.FP:FalsePositives,DR:DetectionRate..88
5.1Errorratesona50-imagedatabase......................136
5.2Dimensionsofthesemanticgraphdescriptorsforindividualfacialcompo-
nents....................................136
x
ListofFigures
1.1Applicationsusingfacerecognitiontechnology:(a)and(b)automated
videosurveillance(downloadedfromVisionics[1]andFaceSnap[2],
respectively);(c)and(d)accesscontrol(fromVisionics[1]andfrom
Viisage[3],respectively);(e)managementofphotodatabases(fromVi-
isage[3]);(f)multimediacommunication(fromEyematic[4]).
Images
inthisdissertationarepresentedincolor
.................3
1.1(Cont'd)....................................4
1.1(Cont'd)....................................5
1.2Comparisonofvariousbiometricfeatures:(a)basedonzephyranalysis
(downloadedfrom[5]);(b)basedonMRTDcompatibility(from[6])..5
1.3Intra-subjectvariationsinpose,illumination,expression,occlusion,acces-
sories(e.g.,glasses),color,andbrightness................6
1.4Facecomparison:(a)faceveri¯cation/authentication;(b)faceidenti¯ca-
tion/recognition.FaceimagesaretakenfromtheMSUfacedatabase[7].6
1.5Headrecognitionversusfacerecognition:(a)ClintonandGoreheadswith
thesameinternalfacialfeatures,adaptedfrom[8];(b)twofacesof
di®erentsubjectswiththesameinternalfacialcomponentsshowthe
importantroleofhairandfaceoutlinesinhumanfacerecognition...8
1.6Caricaturesof(a)VincentVanGogh;(b)JimCarrey;(c)Arnold
Schwarzenegger;(d)Einstein;(e)G.W.Bush;and(f)BillGates.
Imagesaredownloadedfrom[9],[10]and[10].Caricaturesrevealthe
useofcomponentweightsinfaceidenti¯cation.............9
1.7Cartoonsrevealthathumanscaneasilyrecognizecharacterswhosefacial
componentsaredepictedbysimplelinestrokesandcolorcharacteris-
tics:(a)and(b)areframesadaptedfromthemoviePocahontas;(c)
and(d)areframesextractedfromthemovieLittleMermaidII.(Disney
Enterprises,Inc.).............................9
1.8Con¯gurationoffacialcomponents:(a)faceimage;(b)faceimagein(a)
withenlargedeyebrow-to-eyeandnose-to-mouthdistances;(c)inverted
faceoftheimagein(b).Asmallchangeofcomponentcon¯guration
resultsinasigni¯cantlydi®erentfacialappearanceinanuprightface
in(b);however,thischangemaynotbeperceivedinaninvertedface
in(c)....................................10
xi
1.9Facialfeatures/components:(a)¯vekindsoffacialfeatures(i.e.,eyebrows,
eyes,nose,ears,andmouth)inafaceforreadingfacesinphysiognomy
(downloadedfrom[11]);(b)afrontalsemanticfacegraph,whosenodes
arefacialcomponentsthatare¯lledwithdi®erentshades.......11
1.10Similarityoffrontalfacesbetween(a)twins(downloadedfrom[12]);and
(b)afatherandhisson(downloadedfrom[13]).............13
1.11Systemdiagramofour3Dmodel-basedfacerecognitionsystemusingreg-
isteredrangeandcolorimages......................16
1.12Systemdiagramofour3Dmodel-basedfacerecognitionsystemwithout
theuseofrangedata............................17
1.13Faceimagestakenunderunconstrainedenvironments:(a)acrowdofpeo-
ple(downloadedfrom[14]);(b)aphototakenataswimmingpool..18
1.14Faceimagesforourdetectionalgorithm:(a)amontageimagecontaining
imagesadaptedfromMPEG7contentset[15];(b)afamilyphoto...20
1.15Faceimagesnotsuitableforourdetectionalgorithm:(a)croppedimage
(downloadedfrom[16]);(b)aperformerwearingmake-up(from[14]);
(c)peoplewearingfacemasks(from[14])................20
1.16GraphicaluserinterfacesoftheFaceGenmodeller[17].A3Dfacemodel
shown(a)withtexturemapping;(b)withwireframeoverlaid.....22
1.17AfaceretrievalinterfaceoftheFACEitsystem[18]:thesystemgivesthe
mostsimilarfaceinadatabasegivenaqueryfaceimage........27
2.1Outputsofseveralfacedetectionalgorithms;(a),(b)F¶eraudetal.[19];
(c)Maioetal.[20];(d)Garciaetal.[21];(e),(f)Schneidermanetal.
[22];(g)Rowleyetal.[23];(h),(i)Rowleyetal.[24];(j)Sungetal.
[25];(k)Yowetal.[26];(l)Lewetal.[27]................36
2.1(Cont'd)....................................37
2.2Examplesoffaceimagesareselectedfrom(a)theFERETdatabase[28];
(b)theMITdatabase[29];(c)theXM2VTSdatabase[30].......41
2.3InternalrepresentationsofthePCA-basedapproachandtheLDA-based
approach(fromWengandSwets[31]).Theaverage(mean)imagesare
showninthe¯rstcolumn.MostExpressiveFeatures(MEF)andMost
DiscriminatingFeatures(MDF)areshownin(a)and(b),respectively.42
2.4InternalrepresentationsoftheEBGM-basedapproach(fromWiskottet
al.[32]):(a)agraphisoverlaidonafaceimage;(b)areconstruction
oftheimagefromthegraph;(c)areconstructionoftheimagefroma
facebunchgraphusingthebest¯ttingjetateachnode.Imagesare
downloadedfrom[33];(d)abunchgraphwhosenodesareassociated
withabunchofjets[33];(e)analternativeinterpretationoftheconcept
ofabunchgraph[33]...........................43
2.5InternalrepresentationsoftheLFA-basedapproach(fromPenevandAtick
[34]).(a)Anaveragefaceimageismarkedwith¯velocalizedfeatures;
(b)¯vetopographickernelsassociatedwiththe¯velocalizedfeatures
areshowninthetoprow,andthecorrespondingresidualcorrelations
areshowninthebottomrow.......................44
xii
2.6Abreakdownoffacerecognitionalgorithmsbasedonthepose-dependency,
facerepresentation,andfeaturesusedinmatching...........45
2.7Facemodelingusinganthropometricmeasurements(downloaded
from[35]):(a)anthropometricmeasurements;(b)aB-splinefacemodel.48
2.8Genericfacemodels:(a)Water'sanimationmodel;(b)anthropometric
measurements;(b)sixkindsoffacemodelsforrepresentinggeneral
facialgeometry...............................49
3.1Facedetectionalgorithm.Thefacelocalizationmodule¯ndsfacecan-
didates,whichareveri¯edbythedetectionmodulebasedonfacial
features...................................60
3.2Skindetection:(a)ayellow-biasedfaceimage;(b)alightingcompensated
image;(c)skinregionsof(a)showninwhite;(d)skinregionsof(b)..62
3.3The
YC
b
C
r
colorspace(bluedotsrepresentthereproduciblecoloron
amonitor)andtheskintonemodel(reddotsrepresentskincolor
samples).(a)The
YC
b
C
r
space;(b)a2Dprojectioninthe
C
b
-
C
r
subspace;(c)a2Dprojectioninthe(
C
b
=Y
)-(
C
r
=Y
)subspace.....65
3.4Thedependencyofskintonecoloronluma.Theskintonecluster(red
dots)isshownin(a)the
rgY
,(c)the
CIExyY
,and(e)the
HSV
color
spaces;the2Dprojectionoftheclusterisshownin(b)the
r
¡
g
,(d)
the
x
¡
y
,and(f)
S
¡
H
colorsubspaces,wherebluedotsrepresentthe
reproduciblecoloronamonitor.Forabetterpresentationofcluster
shape,wenormalizetheluma
Y
inthe
rgY
andthe
CIExyY
by255,
andswapthehueandsaturationcoordinatesinthe
HSV
space.The
skintoneclusterislesscompactatlowsaturationvaluesin(e)and(f).66
3.52Dprojectionsofthe3Dskintoneclusterin(a)the
Y
-
C
b
subspace;(b)
the
Y
-
C
r
subspace.Reddotsindicatetheskincluster.Threeblue
dashedcurves,oneforclustercenterandtwoforboundaries,indicate
the¯ttedmodels..............................67
3.6Thenonlineartransformationofthe
YC
b
C
r
colorspace.(a)Thetrans-
formed
YC
b
C
r
colorspace;(b)a2Dprojectionof(a)inthe
C
b
-
C
r
subspace,inwhichtheellipticalskinmodelisoverlaidontheskin
cluster....................................67
3.7Nonlinearcolortransform.Sixdetectionexamples,withandwithoutthe
transformareshown.Foreachexample,theimagesshowninthe¯rst
columnareskinregionsanddetectionswithoutthetransform,while
thoseinthesecondcolumnareresultswiththetransform.......68
3.8Constructionofthefacemask.(a)Facecandidates;(b)oneoftheface
candidates;(c)groupedskinareas;(d)thefacemask..........69
3.9Constructionofeyemaps:(a)fromchroma;(b)fromluma;(c)thecom-
binedeyemap...............................71
3.10Anexampleofahemisphericstructuringelementforgrayscalemorpho-
logicaldilationanderosionwith
¾
=1..................72
3.11Constructionofthemouthmap........................74
3.12Computationoffaceboundaryandtheeye-mouthtriangle.........77
xiii
3.13Geometryofaneye-mouthtriangle,where
~v
1
=
¡
~v
2
;unitvectors
~u
1
and
~u
2
areperpendiculartotheinterocularsegmentandthehorizontalaxis,
respectively.................................81
3.14Attenuationterm,
e
¡
3(1
¡
cos
2
(
µ
r
(
i;j;k
)))
,plottedasafunctionoftheangle
µ
r
(indegrees)hasamaximalvalueof1at
µ
r
=0
±
,andavalueof0.5at
µ
r
=25
±
...................................81
3.15Facedetectionexamplescontainingdarkskin-tonefaces.Eachexample
containsaninputimage,groupedskinregionsshowninpseudocolor,
andalighting-compensatedimageoverlaidwithdetectedfaceandfa-
cialfeatures.................................83
3.16Facedetectionresultsonclosed-eyeoropen-mouthfaces.Eachexample
containsanoriginalimage(top)andalighting-compensatedimage
(bottom)overlaidwithfacedetectionresults...............84
3.17Facedetectionresultsinthepresenceofeyeglasses.Eachexamplecontains
anoriginalimage(top)andalighting-compensatedimage(bottom)
overlaidwithfacedetectionresults....................84
3.18Facedetectionresultsforsubjectswithfacialhair.Eachexamplecontains
anoriginalimage(top)andalighting-compensatedimage(bottom)
overlaidwithfacedetectionresults....................85
3.19Facedetectionresultsonhalf-pro¯lefaces.Eachexamplecontainsanorig-
inalimage(top)andalighting-compensatedimage(bottom)overlaid
withfacedetectionresults.........................86
3.20FacedetectionresultsonasubsetoftheHHIdatabase:(a)inputimages;
(b)groupedskinregions;(c)facecandidates;(d)detectedfacesare
overlaidonthelighting-compensatedimages...............89
3.21FacedetectionresultsonasubsetoftheChampiondatabase:(a)input
images;(b)groupedskinregions;(c)facecandidates;(d)detectedfaces
areoverlaidonthelighting-compensatedimages.............90
3.22Facedetectionresultsonasubsetofelevenfamilyphotos.Eachimage
containsmultiplehumanfaces.Thedetectedfacesareoverlaidonthe
color-compensatedimages.Falsenegativesareduetoextremelighting
conditionsandshadows.Noticethedi®erencebetweentheinputand
color-compensatedimagesintermsofcolorbalance.Thebiascolorin
theoriginalimageshasbeencompensatedintheresultantimages...91
3.22(Cont'd)....................................92
3.22(Cont'd)....................................93
3.23Facedetectionresultsonasubsetof24newsphotos.Thedetectedfaces
areoverlaidonthecolor-compensatedimages.Falsenegativesaredue
toextremelightingconditions,shadows,andlowimagequality(i.e.,
highcompressionrate)...........................94
3.24Graphicaluserinterface(GUI)forfaceediting:(a)detectionmode;(b)
editingmode................................96
4.1Thesystemoverviewoftheproposedmodelingmethodbasedona3D
genericfacemodel.............................98
xiv
4.23Dtriangular-meshmodelanditsfeaturecomponents:(a)thefrontal
view;(b)asideview;(c)featurecomponents..............100
4.3Phong-shaded3Dmodelshownatthreeviewpoints.Illuminationisin
frontofthefacemodel...........................100
4.4Facialmeasurementsofahumanface:(a)colorimage;(b)rangemap;and
therangemapwithtexturemappedfor(c)aleftview;(d)apro¯le
view;(e)arightview...........................102
4.5Facialfeaturesoverlaidonthecolorimage,(a)obtainedfromfacedetec-
tion;(b)generatedforfacemodeling...................102
4.6Globalalignmentofthegenericmodel(inred)tothefacialmeasurements
(inblue):thetargetmeshisplottedin(a)forahiddenlineremoval
modeforasideview;(b)forasee-throughmodeforapro¯leview..103
4.7Displacementpropagation...........................104
4.8Localfeaturealignmentanddisplacementpropagationshownforthe
frontalview:(a)theinputgenericmodel;themodeladaptedto(b)
thelefteye;(c)thenose;(d)mouthandchin..............105
4.9Localfeaturere¯nement:initial(inblue)andre¯ned(inred)contours
overlaidontheenergymapsfor(a)thefaceboundary;(b)thenose;
(c)thelefteye;and(d)themouth....................107
4.10Theadaptedmodel(inred)overlappingthetargetmeasurements(inblue),
plotted(a)in3D;(b)withcoloredfacetsatapro¯leview.......108
4.11TextureMapping.(a)Thetexture-mappedinputrangeimage.The
texture-mappedadaptedmeshmodelshownfor(b)afrontalview;
(d)aleftview;(e)apro¯leview;(f)arightview............109
4.12Facematching:thetoprowshowsthe15trainingimagesgeneratedfrom
the3Dmodel;thebottomrowshows10testimagesofthesubject
capturedfromaCCDcamera.......................110
5.1Semanticfacegraphisshowninafrontalview,whosenodesare(a)in-
dicatedbytext;(b)depictedbypolynomialcurves;(c)¯lledwith
di®erentshades.Theedgesofthesemanticgraphareimplicitlystored
ina3Dgenericfacemodelandarehiddenhere.............113
5.23Dgenericfacemodel:(a)Waters'triangular-meshmodelshowninthe
sideview;(b)modelin(a)overlaidwithfacialcurvesincludinghair
andearsatasideview;(c)modelin(b)showninthefrontalview..114
5.3SemanticfacegraphsforthefrontalviewarereconstructedusingFourier
descriptorswithspatialfrequencycoe±cientsincreasingfrom(a)10%
to(j)100%atincrementsof10%.....................115
5.4Facedetectionresults:(a)and(c)areinputfaceimagesofsize640
£
480
fromtheMPEG7contentset;(b)and(d)aredetectedfaces,eachof
whichisdescribedbyanovalandatriangle...............116
xv
5.5Boundarymapandeyecomponentmapforcoarsealignment:(a)and(b)
aregradientmagnitudeandorientation,respectively,obtainedfrom
multi-scaleGaussian-blurrededgeresponse;(c)aneyemapextracted
fromafaceimageshowninFig.5.4(c);(d)asemanticfacegraph
overlaidona3Dplotoftheeyemap;(e)imageoverlaidwithacoarsely
alignedfacegraph.............................119
5.6Shadowmaps:(a)and(c)arelumacomponentsoffaceimagesinFigs.
5.4(a)and5.4(c),overlaidwithrectangleswithinwhichtheaverage
valuesofskinintensityiscalculated;(b)and(d)areshadowmaps
wherebrightpixelsindicatetheregionsthataredarkerthanaverage
skinintensity................................120
5.7Coarsealignment:(a)inputfaceimagesofsize640
£
480fromtheMPEG7
contentset(¯rstthreerows),andofsize256
£
384fromtheMSU
database(thefourthrow);(b)detectedfaces;(c)locationsofeyebrow,
nostril,andmouthlinesusingshadowmaps;(d)faceimagesoverlaid
withcoarselyalignedfacegraphs.....................121
5.8Interactingsnakes:(a)faceregionextractedfromafaceimageshownin
Fig.5.4(a);(b)imagein(a)overlaidwitha(projected)semanticface
graph;(c)theinitialcon¯gurationofinteractingsnakesobtainedfrom
thesemanticfacegraphshownin(b)...................122
5.9Repulsionforce:(a)interactingsnakeswithindexnumbersmarked;(b)
therepulsionforcecomputedforthehairoutline;(c)therepulsion
forcecomputedforthefaceoutline....................124
5.10Gradientvector¯eld:(a)faceregionofinterestextractedfroma640x480
image;(b)thresholdedgradientmapbasedonthepopulationofedge
pixelsshownasdarkpixels;(c)gradientvector¯eld..........125
5.11Componentenergy(darkerpixelshavestrongerenergy):(a)faceregionof
interest;(b)eyecomponentenergy;(c)mouthcomponentenergy;(d)
noseboundaryenergy;(e)noseboundaryenergyshownasa3Dmesh
surface...................................126
5.12Finealignment:(a)snakedeformationshownevery¯veiterations;(b)
alignedsnakes(currentlysixsnakes|hairstyle,face-border,eyes,and
mouth|areinteracting);(c)gradientvector¯eldoverlaidwiththe
alignedsnakes...............................128
5.13Finealignmentwithevolutionsteps:(a)afaceimage;(b)thefacein
(a)overlaidwithacoarselyalignedfacegraph;(c)initialinteracting
snakeswithdi®erentshadesinfacialcomponents(cartoonface);(d)
curveevolutionshownevery¯veiterations(totally55iterations);(e)
analignedcartoonface..........................130
xvi
5.14Finealignmentusinggeodesicactivecontours:(a)agenericcartoonface
constructedfrominteractingsnakes;(b)to(f)for¯vedi®erentsub-
jects.Foreachsubject,theimageinthe¯rstrowisthecapturedface
image;thesecondrowshowssemanticfacegraphsobtainedaftercoarse
alignment,andoverlaidonthecolorimage;thethirdrowshowsseman-
ticfacegraphswithindividualcomponentsshownindi®erentshades
ofgray;thelastrowshowsfacegraphswithindividualcomponents
after¯nealignment............................131
5.15Asemanticfacematchingalgorithm.....................134
5.16Fivecolorimages(256
£
384)ofasubject..................135
5.17Faceimagesoftensubjects..........................135
5.18Examplesofmisclassi¯cation:(a)inputtestimage;(b)semanticface
graphoftheimagein(a);(c)facegraphofthemisclassi¯edsubject;
(d)facegraphofthegenuinesubjectobtainedfromtheotherimages
ofthesubjectinthedatabase(i.e.,withouttheinputtestimagein
(a)).Eachrowshowsoneexampleofmisclassi¯cation.........137
5.19CartoonfacesreconstructedfromFourierdescriptorsusingallthefre-
quencycomponents:(a)to(j)aretenaveragecartoonfacesforten
di®erentsubjectsbasedon¯veimagesforeachsubject.Individual
componentsareshownindi®erentshadesin(a)to(e).........138
5.20CartoonfacesreconstructedfromFourierdescriptorsusingonly50%of
thefrequencycomponents:(a)to(j)aretenaveragecartoonfacesfor
tendi®erentsubjectsbasedon¯veimagesforeachsubject.Individual
componentsareshownindi®erentshadesin(a)to(e).........139
5.21CartoonfacesreconstructedfromFourierdescriptorsusingonly30%of
thefrequencycomponents:(a)to(j)aretenaveragecartoonfacesfor
tendi®erentsubjectsbasedon¯veimagesforeachsubject.Individual
componentsareshownindi®erentshadesin(a)to(e).........139
5.22Facialcaricaturesgeneratedbasedonageneric3Dfacemodel:(a)apro-
totypeofthesemanticfacegraph,
G
0
,obtainedfromageneric3Dface
model,withindividualcomponentsshaded;(b)faceimagesofsixdif-
ferentsubjects;(c)-(g)caricaturesoffacesin(b)(semanticfacegraphs
withindividualcomponentsshownindi®erentshades)withdi®erent
valuesofexaggerationcoe±cients,
k
,rangingfrom0
:
1to0
:
9......141
5.23Facialcaricaturesgeneratedbasedontheaveragefaceof50faces(5for
eachsubject):(a)aprototypeofthesemanticfacegraph,
G
0
,ob-
tainedfromthemeanfaceofthedatabase,withindividualcomponents
shaded;(b)faceimagesofsixdi®erentsubjects;(c)-(g)caricaturesof
facesin(b)(semanticfacegraphswithindividualcomponentsshown
indi®erentshades)withdi®erentvaluesofexaggerationcoe±cients,
k
,
rangingfrom0
:
1to0
:
9...........................142
6.1Aprototypeofafaceidenti¯cationsystemwiththetrackingfunction...148
xvii
6.2Anexampleofmotiondetectioninavideoframe:(a)Acolorvideoframe;
(b)extractedregionswithsigni¯cantmotion;(c)detectedmovingskin
patchesshowninpseudocolor;(d)extractedfacecandidatesdescribed
byrectangles................................149
6.3Facetrackingresultsonasequenceof25videoframes.Theseimagesare
arrangedfromtoptobottomandfromlefttoright.Detectedfacesare
overlaidonthelighting-compensatedimages...............150
A.1Colorspaces:(a)
RGB
;(b)
YCbCr
.....................154
C.1ArchitectureofIPTLclasstemplates.....................162
xviii
Chapter1
Introduction
Inrecentyearsfacerecognitionhasreceivedsubstantialattentionfromresearchers
inbiometrics,patternrecognition,andcomputervisioncommunities(seesurveysin
[36],[37],[38]).Thiscommoninterestamongresearchersworkingindiverse¯eldsis
motivatedbyourremarkableabilitytorecognizepeople(althoughincaseofcertain
rarebraindisability,e.g.,prosopagnosiaorfaceblindness[39],thisrecognitionability
islost)andthefactthathumanactivityisaprimaryconcernbothineveryday
lifeandincyberspace.Besides,therearealargenumberofcommercial,security,
andforensicapplicationsrequiringtheuseoffacerecognitiontechnology.These
applications(seeFig.1.1)includeautomatedvideosurveillance(e.g.,superbowlface
scansandairportsecuritycheckpoints),accesscontrol(e.g.,topersonalcomputers
andprivatebuildings),mugshotidenti¯cation(e.g.,forissuingdriverlicenses),design
ofhumancomputerinterface(HCI)(e.g.,classifyingtheactivityofavehicledriver),
multimediacommunication(e.g.,generationofsyntheticfaces),andcontent-based
imagedatabasemanagement[40].Theseapplicationsinvolvelocating,tracking,and
1
recognizingasingle(ormultiple)humansubject(s)orface(s).
Facerecognitionisanimportantbiometricidenti¯cationtechnology.Facialscanis
ane®ectivebiometricattribute/indicator.Di®erentbiometricindicatorsaresuitedfor
di®erentkindsofidenti¯cationapplicationsduetotheirvariationsinintrusiveness,
accuracy,cost,and(sensing)e®ort[5](seeFig.1.2(a)).Amongthesixbiometric
indicatorsconsideredin[6],facialfeaturesscoredthehighestcompatibility,shown
inFig.1.2(b),inamachinereadabletraveldocuments(MRTD)systembasedona
numberofevaluationfactors,suchasenrollment,renewal,machinerequirements,and
publicperception[6].
1.1ChallengesinFaceRecognition
Humanscaneasilyrecognizeaknownfaceinvariousconditionsandrepresentations
(seeFig.1.3).Sucharemarkableabilityofhumanstorecognizefaceswithlarge
intra-subjectvariationshasinspiredvisionresearcherstodevelopautomatedsystems
forfacerecognitionbasedon2Dfaceimages.However,thecurrentstate-of-the-art
machinevisionsystemscanrecognizefacesonlyinaconstrainedenvironment.Note
thattherearetwotypesoffacecomparisonscenarios,called(i)face
veri¯cation(or
authentication)
and(ii)face
identi¯cation(orrecognition)
.AsshowninFig.1.4,face
veri¯cationinvolvesaone-to-onematchthatcomparesaqueryfaceimageagainst
atemplatefaceimagewhoseidentityisbeingclaimed,whilefaceidenti¯cationin-
volvesone-to-manymatchesthatcompareaqueryfaceimageagainstallthetemplate
imagesinafacedatabasetodeterminetheidentityofthequeryface.Themainchal-
2
(a)
(b)
Figure1.1.Applicationsusingfacerecognitiontechnology:(a)and(b)automated
videosurveillance(downloadedfromVisionics[1]andFaceSnap[2],respectively);
(c)and(d)accesscontrol(fromVisionics[1]andfromViisage[3],respectively);(e)
managementofphotodatabases(fromViisage[3]);(f)multimediacommunication
(fromEyematic[4]).
Imagesinthisdissertationarepresentedincolor
.
3
(c)
(d)
Figure1.1.(Cont'd).
4
(e)(f)
Figure1.1.(Cont'd).
(a)(b)
Figure1.2.Comparisonofvariousbiometricfeatures:(a)basedonzephyranalysis
(downloadedfrom[5]);(b)basedonMRTDcompatibility(from[6]).
5
Figure1.3.Intra-subjectvariationsinpose,illumination,expression,occlusion,
accessories(e.g.,glasses),color,andbrightness.
(a)(b)
Figure1.4.Facecomparison:(a)faceveri¯cation/authentication;(b)faceidenti¯-
cation/recognition.FaceimagesaretakenfromtheMSUfacedatabase[7].
lengeinvision-basedfacerecognitionisthepresenceofahighdegreeofvariabilityin
humanfaceimages.Therecanbepotentiallyverylargeintra-subjectvariations(due
to3Dheadpose,lighting,facialexpression,facialhair,andaging[41])andrather
smallinter-subjectvariations(duetothesimilarityofindividualappearances).Cur-
rentlyavailablevision-basedrecognitiontechniquescanbemainlycategorizedinto
twogroupsbasedonthefacerepresentationwhichtheyuse:(i)appearance-based
whichuseholistictexturefeatures,and(ii)geometry-basedwhichusegeometrical
featuresoftheface.Experimentalresultsshowthatappearance-basedmethodsgen-
erallyperformabetterrecognitiontaskthanthosebasedongeometry,becauseit
isdi±culttorobustlyextractgeometricalfeaturesespeciallyinfaceimagesoflow
6
resolutionsandofpoorquality(i.e.,toextractfeaturesunderuncertainty).However,
theappearance-basedrecognitiontechniqueshavetheirownlimitationsinrecognizing
humanfacesinimageswithwidevariationsin3Dheadposeandinillumination[38].
Hence,inordertoovercomevariationsinpose,alargenumberoffacerecognition
techniqueshavebeendevelopedtotakeintoaccountthe3Dfaceshape,extracted
eitherfromavideosequenceorrangedata.Asforovercomingthevariationsin
illumination,severalstudieshaveexploredfeaturessuchasedgemaps(e.g.,eigen-
hillsandeigenedgesin[42]),intensityderivatives,Gabor-¯lterresponses[43],and
theorientation¯eldsofintensitygradient[44].However,noneoftheseapproaches
bythemselvesleadtosatisfactoryrecognitionresults.Hence,theexplicit3Dface
modelcombinedwithitsre°ectancemodelisbelievedtobethebestrepresentation
ofhumanfacesfortheappearance-basedapproach[43].
1.2SemanticFacialComponents
Facerecognitiontechnologyprovidesusefultoolsforcontent-basedimageandvideo
retrievalbasedonasemantic(high-level)concept,i.e.,humanfaces.Isallfacepro-
cessingholistic[45]?Someapproaches,includingfeature-basedandappearance-based
[46]methods,emphasizethatinternalfacialfeatures(i.e.,purefaceregions)playthe
mostimportantroleinfacerecognition.Ontheotherhand,someappearance-based
methodssuggestthat
insomesituations
facerecognitionisbetterinterpretedas
headrecognition
[8],[31].Anexamplesupportingtheaboveargumentwasdemon-
stratedforClintonandGoreheads[8](SeeFig.1.5(a)).Whilethetwofacesin
7
(a)(b)
Figure1.5.Headrecognitionversusfacerecognition:(a)ClintonandGoreheads
withthesameinternalfacialfeatures,adaptedfrom[8];(b)twofacesofdi®erent
subjectswiththesameinternalfacialcomponentsshowtheimportantroleofhair
andfaceoutlinesinhumanfacerecognition.
Fig.1.5(a)haveidenticalinternalfeatures,wecanstilldistinguishClintonfromGore.
Wenoticethatinthis\example"
thehairstyleandthefaceoutlinearesigni¯cantly
di®erent
.Wereproducethisscenario,acrossgenders,inFig.1.5(b).Humanswill
usuallyidentifythesetwopersonswithdi®erentidentities.ThispromptedLiuet
al.[47]toemphasizethatthereisnouseoffacemasks(toremovethe\non-pure-
face"portion)intheirappearance-basedmethod.Asaresult,webelievethatthe
separationofexternalandinternalfacialfeatures/componentsishelpfulinassigning
weightsonexternalandinternalfacialfeaturesinthefacerecognitionprocess.
Modelingfacialcomponentsatthesemanticlevel(i.e.,eyebrows,eyes,nose,
mouth,faceoutline,ears,andthehairoutline)helpstoseparateexternalandin-
ternalfacialcomponents,andtounderstandhowtheseindividualcomponentscon-
tributetofacerecognition.Examplesofmodelingfacialcomponentscanbefound
inthefacesrepresentedincaricaturesandcartoons.However,thefactthathumans
8
canrecognizeknownfacesincaricaturedrawings(e.g.,facesshowninFig.1.6)and
cartoons(seeFig.1.7)withoutanydi±cultyhasnotbeenfullyexploredinresearch
studiesonfacerecognition[48],[49],[50],[51].Notethatsomeofthefacesshown
(a)(b)(c)(d)(e)(f)
Figure1.6.Caricaturesof(a)VincentVanGogh;(b)JimCarrey;(c)Arnold
Schwarzenegger;(d)Einstein;(e)G.W.Bush;and(f)BillGates.Imagesaredown-
loadedfrom[9],[10]and[10].Caricaturesrevealtheuseofcomponentweightsinface
identi¯cation.
(a)(b)(c)(d)
Figure1.7.Cartoonsrevealthathumanscaneasilyrecognizecharacterswhosefacial
componentsaredepictedbysimplelinestrokesandcolorcharacteristics:(a)and(b)
areframesadaptedfromthemoviePocahontas;(c)and(d)areframesextractedfrom
themovieLittleMermaidII.(DisneyEnterprises,Inc.)
inFig.1.6arerepresentedonlybystrokes(geometricalfeatures),whilesomeothers
havepartsoffacialfeaturesdramaticallyemphasizedwithsomedistortion.Cartoon
facesaredepictedbylinedrawingsandcolorwithoutshading.Peoplecaneasily
identifyfacesincaricatures(see,Fig.1.6)thatexaggeratesomeofthefacialcompo-
nents/landmarks.Besides,wecanalsoeasilyidentifyknownfacesmerelybasedon
somesalientfacialcomponents.Forexample,wecanquicklyrecognizeaknownface
9
withadistinctivechinnomatterwhetherthefaceappearsinacaricature(e.g.,Jim
CarreyshowninFig.1.6(b))orinarealphoto[52].Caricaturesrevealthatthere
arecertainfacialfeatureswhicharesalientforeachindividualandthatarelatively
easieridenti¯cationoffacescanoccurbyemphasizingdistinctivefacialcomponents
(usingweights)andtheircon¯guration.Besides,thespatialcon¯gurationoffacial
componentshasbeenshowntotakeamoreimportantroleinfacerecognitionthan
localtexturebyusinginvertedfaces[53]inwhichthe(upright)facerecognitionis
disrupted(seeFig.1.8).Therefore,wegroupthesesalientfacialcomponents[48]as
(a)(b)(c)
Figure1.8.Con¯gurationoffacialcomponents:(a)faceimage;(b)faceimagein(a)
withenlargedeyebrow-to-eyeandnose-to-mouthdistances;(c)invertedfaceofthe
imagein(b).Asmallchangeofcomponentcon¯gurationresultsinasigni¯cantly
di®erentfacialappearanceinanuprightfacein(b);however,thischangemaynotbe
perceivedinaninvertedfacein(c).
agraphandderive
componentweights
inourfacematchingalgorithmtoimprovethe
recognitionperformance.
Inaddition,humanscanrecognizefacesinthepresenceofocclusions,i.e.,face
recognitioncanbebasedona(selected)subsetoffacialcomponents.Thisexplains
10
themotivationforstudiesthatattempttorecognizefacesfromeyesonly[54].The
useofcomponentweightscanfacilitatefacerecognitionbasedonselectedfacialcom-
ponents.Furthermore,theshapeoffacialcomponents(seeFig.1.9(a))hasbeen
usedinphysiognomy(orfacereading,anancientartofdecipheringaperson'spast
andpersonalityfromhis/herface).Inlightofthisart,wedesignasemanticface
graphforfacerecognition(seeinChapter5),showninFig.1.9(b),inwhichtenfacial
componentsare¯lledwithdi®erentshadesinafrontalview.
(a)(b)
Figure1.9.Facialfeatures/components:(a)¯vekindsoffacialfeatures(i.e.,eye-
brows,eyes,nose,ears,andmouth)inafaceforreadingfacesinphysiognomy(down-
loadedfrom[11]);(b)afrontalsemanticfacegraph,whosenodesarefacialcompo-
nentsthatare¯lledwithdi®erentshades.
Foreachfacialcomponent,theissueofrepresentationalsoplaysanimportant
roleinfacerecognition.Ithasbeenbelievedthatlocalfacialtextureandshadingare
crucialforrecognition[52].However,someframesofacartoonvideo,asshowninFig.
11
1.7,revealthatlinedrawingsandcolorcharacteristics(shades)offacialcomponents
(e.g.,darkcolorsforeyebrowsandbothbrightanddarkcolorsforeyes)provide
su±cientinformationforhumanstorecognizethefacesofcharactersincartoons.
Peoplecanevenrecognizecartoonfaceswithouttheuseofshadinginformation,which
isratherunstableunderdi®erentlightingconditions.Consequently,webelievethat
curves(orsketches)andshadesoffacialcomponentsprovideapromisingsolution
totherepresentationoffacialcomponentsforrecognition.However,verylittlework
hasbeendoneinfacerecognitionbasedonfacialsketches[55],[56]and(computer-
generated[57])caricatures[58],[48],[50].
Insummary,externalandinternalfacialcomponents,anddistinctiveness,con¯g-
urationandlocaltextureoffacialcomponentsallcontributetotheprocessofface
recognition.Humanscan
seamlesslyblend
and
independentlyperform
appearance-
basedandgeometry-basedrecognitionapproachese±ciently.Therefore,webelieve
thatmerging[59],[60]theholistictexturefeaturesandthegeometricalfeatures(es-
peciallyatasemanticlevel)isapromisingmethodtorepresentfacesforrecognition.
Whilewefocusonthe3Dvariationsinfaces,weshouldalsotakethetemporal(aging)
factorintoconsiderationwhiledesigningfacerecognitionsystems[41].Inadditionto
largeintra-subjectvariations,anotherdi±cultyinrecognizingfacesliesinthesmall
inter-subjectvariations(showninFig.1.10).Di®erentpersonsmayhaveverysimilar
appearances.Identifyingpeoplewithverysimilarappearancesremainsachallenging
taskinautomaticfacerecognition.
12
(a)(b)
Figure1.10.Similarityoffrontalfacesbetween(a)twins(downloadedfrom[12]);
and(b)afatherandhisson(downloadedfrom[13]).
1.3FaceRecognitionSystems
Facerecognitionapplicationsinfactinvolveseveralimportantsteps,suchasface
detectionforlocatinghumanfaces,facetrackingforfollowingmovingsubjects,face
modelingforrepresentinghumanfaces,facecoding/compressionfore±cientlyarchiv-
ingandtransmittingfaces,andfacematchingforcomparingrepresentedfacesand
identifyingaquerysubject.Facedetectionisusuallyanimportant¯rststep.De-
tectingfacescanbeviewedasatwo-class(facevs.non-face)classi¯cationproblem,
whilerecognizingfacescanberegardedasamultiple-class(multiplesubjects)classi-
¯cationproblemwithinthefaceclass.Facedetectioninvolvescertainaspectsofface
recognitionmechanism,whilefacerecognitionemploystheresultsoffacedetection.
Wecanconsiderfacedetectionandrecognitionasthe¯rstandthesecondstagesin
asequentialclassi¯cationsystem.Thecrucialissuehereistodetermineanappro-
priatefeaturespacetorepresentahumanfaceinsuchaclassi¯cationsystem.We
believethataseamlesscombinationoffacedetection,facemodeling,andrecogni-
tionalgorithmshasthepotentialofachievinghighperformanceforfaceidenti¯cation
13
applications.
Withthisprinciple,weproposetwoautomatedrecognitionparadigms,shownin
Fig.1.11andFig.1.12,thatcancombinefacedetectionaswellas
tracking
(not
includedinthisthesis,butcanberealizedbasedonourcurrentwork),modeling,and
recognition.The¯rstparadigmrequiresbothvideosequencesand2.5D/3Dfacial
measurementsasitsinputinthelearning/enrollmentstage.Intherecognition/test
stage,however,faceimagesareextractedfromvideoinputonly.Facesareidenti¯ed
basedonanappearance-basedalgorithm.Thesecondparadigmrequiresonlyvideo
sequencesasitsinputinbothlearningandrecognitionstages.Itsfacerecognition
modulemakesuseofasemanticfacematchingalgorithmtocomparefacesbasedon
weightedfacialcomponents.
Bothparadigmscontainthreemajormodules:(i)facedetectionandfeatureex-
traction,(ii)facemodeling,and(iii)facerecognition.Thefacedetection/location
andfeatureextractionmoduleisabletolocatefacesinvideosequences.Themost
importantportionofthismoduleisafeatureextractionsub-modulethatextracts
geometricalfeatures(suchasfaceboundary,eyes,eyebrows,nose,andmouth),and
texture/colorfeatures(estimationoftheheadposeandilluminationisleftasafuture
researchdirection).Thefacemodelingmoduleemploystheseextractedfeaturesfor
modifyingthegeneric3Dfacemodelinthelearningandrecognitionstages.Inthis
thesis,wedescribetheimplementationofthefacemodelingmoduleinbothproposed
paradigmsforthefrontalviewonly.Theextensionofthefacemodelingmoduleto
non-frontalviewscanbeafutureresearchdirection.Therecognitionmodulemakes
useoffacialfeaturesextractedfromaninputimageandthelearned3Dmodelsto
14
verifythefacepresentinanimageintherecognitionstage.Thisthesishasdeveloped
arobustfacedetectionmodulewhichisusedtofacilitateapplicationssuchasface
trackingforsurveillance,andfacemodelingforidenti¯cation(aswellasveri¯cation).
Wewillbrie°ydiscussthetopicsoffacedetectionandrecognition,facemodelingas
wellascompression,andface-basedimageretrievalinthefollowingsections.
1.4FaceDetectionandRecognition
Humanactivityisamajorconcerninawidevarietyofapplicationssuchasvideo
surveillance,humancomputerinterface,facerecognition[37],[36],[38],andface
imagedatabasemanagement[40].Detectingfacesisacrucialstepandusuallythe
¯rstoneintheseidenti¯cationapplications.However,duetovariousheadposes,
illuminationconditions,occlusion,anddistancesbetweentehsensorandthesubject
(whichmayresultinablurredface),detectinghumanfacesisanextremelydi±cult
taskunderunconstrainedenvironments(seeimagesinFigs.1.13(a)and(b)).Most
facerecognitionalgorithmsassumethattheproblemoffacedetectionhasbeensolved,
thatis,thefacelocationisknown.Similarly,facetrackingalgorithms(e.g.,[61])
oftenassumetheinitialfacelocationisknown.Sincefacedetectioncanbeviewed
asatwo-class(facevs.non-face)classi¯cationproblem,sometechniquesdeveloped
forfacerecognition(e.g.,holistic/templateapproaches[21],[62],[63],[64],feature-
basedapproaches[65],andtheircombination[66])havebeenusedtodetectfaces.
However,thesedetectiontechniquesarecomputationallyverydemandingandcannot
handlelargevariationsinfaces.Inadditiontothefacelocation,afacedetection
15
Figure1.11.Systemdiagramofour3Dmodel-basedfacerecognitionsystemusingregisteredrangeandcolorimages.
16
Figure1.12.Systemdiagramofour3Dmodel-basedfacerecognitionsystemwithouttheuseofrangedata.
17
(a)
(b)
Figure1.13.Faceimagestakenunderunconstrainedenvironments:(a)acrowdof
people(downloadedfrom[14]);(b)aphototakenataswimmingpool.
18
algorithmcanalsoprovidegeometricalfacialfeaturesforfacerecognition.Merging
thegeometricalfeaturesandholistictexture(appearance-based)featuresisbelieved
tobeapromisingmethodofrepresentingfacesforrecognition[59],[60].Therefore,
webelievethataseamlesscombinationoffacedetectionandrecognitionalgorithms
hasthepotentialofprovidingahighperformancefaceidenti¯cationalgorithm.
Hence,wehaveproposedafacedetectionalgorithmforcolorimages,whichis
abletogenerategeometricalaswellastexturefeaturesforrecognition.Ourapproach
isbasedonmodelingskincolorandextractinggeometricalfacialfeatures.Theskin
colorisdetectedbyusingalightingcompensationtechniqueandanonlinearcolor
transformation.Thegeometricalfacialfeaturesareextractedfromeye,mouth,and
faceboundarymaps.Thedetectedfaces,includingtheextractedfacialfeatures,are
organizedasagraphformodelingandrecognitionprocesses.Ouralgorithmcandetect
facesunderdi®erentheadposes,illuminations,andexpressions(seeFig.1.14(a)),and
familyphotos(seeFig.1.14(b)).However,ourdetectionalgorithmisnotdesigned
fordetectingfacesingray-scaleimages,croppedfaceimages(seeFig.1.15(a))and
faceswearingmake-upormask(seeFigs.1.15(b)and(c)).
1.5FaceModelingforRecognition
Ourfacerecognitionsystemsarebasedon3Dfacemodels.3Dmodelsofhumanfaces
havebeenwidelyusedtofacilitateapplicationssuchasvideocompression/coding,
humanfacetracking,facialanimation,augmentedreality,recognitionoffacialex-
pression,andfacerecognition.Figure1.16showstwographicaluserinterfacesofa
19
(a)(b)
Figure1.14.Faceimagesforourdetectionalgorithm:(a)amontageimagecontaining
imagesadaptedfromMPEG7contentset[15];(b)afamilyphoto.
(a)(b)(c)
Figure1.15.Faceimagesnotsuitableforourdetectionalgorithm:(a)cropped
image(downloadedfrom[16]);(b)aperformerwearingmake-up(from[14]);(c)
peoplewearingfacemasks(from[14]).
20
commercialparametricfacemodelingsystem[17],FaceGenModeller,whichisbased
onfaceshapestatistics.Itcane±cientlycreateacharacterwithspeci¯edage,gen-
der,race,andcaricaturemorphing.Currenttrendinfacerecognitionistoemploy
3Dfacemodelexplicitly[67],becausesuchamodelprovidesapotentialsolution
toidentifyingfaceswithvariationsinillumination,3Dheadpose,andfacialexpres-
sion.Thesevariations,calledtheintra-subjectvariations,alsoincludechangesdue
toaging,facialhair,cosmetics,andfacialaccessories.Theseintra-subjectvariations
constitutetheprimarychallengesinthe¯eldoffacerecognition.Asobject-centered
representationsofhumanfaces,3Dfacemodelsnotonlycanaugmentrecognition
systemsthatutilizeviewer-centeredfacerepresentations(basedon2Dfaceimages),
butalsocanblendtogetherholisticapproachesandgeometry-basedapproachesfor
recognition.However,thethreestate-of-the-artfacerecognitionalgorithms[68],(1)
theprincipalcomponentanalysis(PCA)-basedalgorithm;(2)thelocalfeatureanal-
ysis(LFA)-basedalgorithm;and(3)thedynamic-link-architecture-basedalgorithm,
useonlyviewer-centeredrepresentationsofhumanfaces.A3Dmodel-basedmatch-
ingalgorithmislikelytoprovideapotentialsolutionforadvancingfacerecognition
technology.However,forfacerecognition,itismoreimportanttocapturefacial
distinctivenessofrecognition-orientedcomponentsthantogeneratearealisticface
model.Webrie°yintroduceourfacemodelingmethodsforrecognition(i.e.,face
alignment)andmodelcompressioninthefollowingsubsections.
21
(a)
(b)
Figure1.16.GraphicaluserinterfacesoftheFaceGenmodeller[17].A3Dfacemodel
shown(a)withtexturemapping;(b)withwireframeoverlaid.
22
1.5.1FaceAlignmentUsing2.5DSnakes
Inour¯rstrecognitionsystem(showninFig.1.11),wehaveproposedafacemodeling
methodwhichadaptsanexistinggenericfacemodel(aprioriknowledgeofahuman
face)toanindividual'sfacialmeasurements(i.e.,rangeandcolordata).Weuse
thefacemodelthatwascreatedforfacialanimationbyWaters[69]asourgeneric
facemodel.Waters'modelincludesdetailsoffacialfeaturesthatarecrucialforface
recognition.Ourmodelingprocessalignsthegenericmodelontoextractedfacial
features(regions),suchaseyes,mouth,andfaceboundary,inaglobal-to-localway,
sothatfacialcomponentsthatarecrucialforrecognitionare¯ttedtotheindividual's
facialgeometry.Ourglobalalignmentisbasedonthedetectedlocationsoffacial
components,whilethelocalalignmentutilizestwonewtechniqueswhichwehave
developed,
displacementpropagation
and
2.5Dactivecontours
,tore¯nelocalfacial
componentsandtosmoothenthefacemodel.Ourgoaloffacemodelingistogenerate
alearned3Dmodelofanindividualforverifyingthepresenceoftheindividualina
facedatabaseorinavideo.Theidenti¯cationprocessinvolves(i)themodi¯cation
ofthelearned3Dmodelbasedondi®erentheadposesandilluminationconditions
and(ii)thematchingbetween2Dprojectionsofthemodi¯ed3Dmodel,whosefacial
shapeisintegratedwithfacialtexture,andsensed2Dfacialappearance.
1.5.2ModelCompression
Requirementsofeasymanipulation,progressivetransmission,e®ectivevisualization
andeconomicalstoragefor3D(face)modelshaveresultedintheneedfor
model
23
compression
.Thecomplexityofanobjectmodeldependsnotonlyonobjectgeom-
etrybutalsoonthechoiceofitsrepresentation.The3Dobjectmodelsexploredin
computervisionandgraphicsresearchhavegraduallyevolvedfromsimplepolyhedra,
generatedinmechanicalComputerAidedDesign(CAD)systems,tocomplexfree-
formobjects,suchashumanfacescapturedfromlaserscanningsystems.Although
humanfaceshaveacomplexshape,modelingthemisusefulforemergingapplica-
tionssuchasvirtualmuseumsandmultimediaguidebooksforeducation[70],[71],
low-bandwidthtransmissionofhumanfaceimagesforteleconferencingandinteractive
TVsystems[72],virtualpeopleusedinentertainment[73],saleoffacialaccessories
ine-commerce,remotemedicaldiagnosis,androboticsandautomation[74].
Themajorreasonforustoadoptthetriangularmeshasourgenerichuman
facemodelisthatitissuitablefordescribingandsimplifyingthecomplexityoffacial
geometry.Inaddition,thereareanumberofgeometrycompressionmethodsavailable
forcompressingtriangularmeshes(e.g.,thetopologicalsurgery[75]andthemulti-
resolutionmeshsimpli¯cation[76]).Besidethesehelps,wecanfurtherobtaina
morecompactrepresentationofa3Dfacemodelbycarefullyselectingverticesofthe
triangularmeshforrepresentingfacialfeaturesthatareextractedforfacerecognition.
Ourproposedsemanticfacegraphusedinthesemanticrecognitionparadigm(see
Fig.1.12)issuchanexample.
24
1.5.3FaceAlignmentUsingInteractingSnakes
Forthesemanticrecognitionsystem(showninFig.1.12),wede¯nea
semanticface
graph
.Asemanticfacegraphisderivedfromageneric3Dfacemodelforidentifying
facesatthesemanticlevel.Thenodesofasemanticgraphrepresenthigh-levelfacial
components(e.g.,eyesandmouth),whoseboundariesaredescribedbyopen(or
closed)activecontours(orsnakes).Inourrecognitionsystem,facealignmentplays
acrucialroleinadaptingaprioriknowledgeoffacialtopology,encodedinsemantic
facegraph,ontothesensedfacialmeasurements(e.g.,faceimages).Thesemantic
facegraphis¯rstprojectedontoa2Dimage,coarselyalignedtotheoutputofthe
facedetectionmodule,andthen¯nelyadaptedtothefaceimagesusinginteracting
snakes.
Snakesareusefulmodelsforextractingtheshapeofdeformableobjects[77].
Hence,wemodelthecomponentboundariesofa2Dsemanticfacegraphasacollec-
tionofsnakes.Weproposeanapproachformanipulatingmultiplesnakesiteratively,
called
interactingsnakes
,thatminimizestheattractionenergyfunctionalsonboth
contoursandenclosedregionsofindividualsnakesandtherepulsionenergyfunction-
alsamongmultiplesnakesthatinteractwitheachother.Weevaluatetheinteracting
snakesthroughtwotypesofimplementations,explicit(parametricactivecontours)
andimplicit(geodesicactivecontours)curverepresentations,forfacealignment.
Oncethesemanticfacegraphhasbeenalignedtofaceimages,wecanderive
componentweightsbasedondistinctivenessandvisibilityofindividualcomponents.
Thealignedfacegraphcanalsobeeasilyusedtogeneratecartoonfacesandfacial
25
caricaturesbyexaggeratingthedistinctivenessoffacialcomponents.Afteralignment,
facialcomponentsaretransformedtoafeaturespacespannedbyFourierdescriptorsof
facialcomponentsforfacerecognition,called
semanticfacematching
.Thematching
algorithmcomputesthesimilaritybetweensemanticfacegraphsoffacetemplatesin
adatabaseandasemanticfacegraphthatisadaptedtoagivenfaceimage.The
semanticfacegraphallowsfacematchingbasedonselectedfacialcomponents,and
e®ective3Dmodelupdatingbasedon2Dfaceimages.Theresultsofourfacematching
demonstratethattheproposedfacemodelcanleadtoclassi¯cationandvisualization
(e.g.,thegenerationofcartoonfacesandfacialcaricatures)ofhumanfacesusingthe
derivedsemanticfacegraphs.
1.6FaceRetrieval
Today,peoplecanaccumulatealargenumberofimagesandvideoclips(digitalcon-
tent)becauseofthegrowingpopularityofdigitalimagingdevices,andbecauseof
thedecreasingcostofhigh-capacitydigitalstorage.Thissigni¯cantincreaseinthe
amountofdigitalcontentrequiresdatabasemanagementtoolsthatallowpeopleto
easilyarchiveandretrievecontentsfromtheirdigitalcollections.Sincehumansand
theiractivitiesaretypicallythesubjectofinterestinconsumers'imagesandvideos,
detectingpeopleandidentifyingthemwillhelptoautomateimageandvideoarchival
basedonahigh-levelsemanticconcept,i.e.,humanfaces.Forexample,wecandesign
asystemthatmanagesdigitalcontentofpersonalphotosandamateurvideosbased
ontheconceptofhumanfaces,e.g.,\retrieveallimagescontainingCarrie'sface."
26
Usingmerelylow-levelfeatures(e.g.,skincolororcolorhistograms)forretrievaland
browsingisneitherrobustnoracceptabletotheuser.Highlevelsemanticshaveto
beusedtomakesuchanimage/videomanagementsystemuseful.Fig.1.17showsa
graphicaluserinterfaceofafacialfeature-basedretrievalsystem[18].
Figure1.17.AfaceretrievalinterfaceoftheFACEitsystem[18]:thesystemgives
themostsimilarfaceinadatabasegivenaqueryfaceimage.
Insummary,theabilitytogrouplow-levelfeaturesasameaningfulsemanticentity
isacriticalissueintheretrievalofvisualcontent.Accuratelyande±cientlydetecting
humanfacesplaysacrucialroleinfacilitatingfaceidenti¯cationformanagingface
databases.Infacerecognitionalgorithms,thehigh-levelconcept{ahumanface{is
implicitlyexpressedbyfacerepresentationssuchaslocationsoffeaturepoints,surface
texture,2Dgraphswithfeaturenodes,3Dheadsurface,andcombinationsofthem.
Thefacerepresentationplaysanimportantroleintherecognitionprocessbecause
27
di®erentrepresentationsleadtodi®erentmatchingalgorithms.Wecandesigna
databasemanagementsystemthatutilizestheoutputsofourfacedetectionand
modelingmodulesasindicestosearchadatabasebasedonthesemanticconcepts,
suchas\¯ndalltheimagescontainingJohn'sfaces"and\searchfaceswhichhave
Vincent'seyes(orfaceshape).
1.7OutlineofDissertation
Thisdissertationisorganizedasfollows.Chapter2presentsabriefliteraturereview
onfacedetectionandrecognition,facemodeling(includingmodelcompression),and
faceretrieval.InChapter3,wepresentourfacedetectionalgorithmforcolorim-
ages.Chapter4discussesourrangedata-basedfacemodelingmethodforrecognition.
Chapter5describesthesemanticfacerecognitionsystem,includingfacealignment
usinginteractingsnakes,asemanticfacematchingalgorithm,andthegeneration
ofcartoonfacesandfacialcaricatures.Chapter6presentsconclusionsandfuture
directionsrelatedtothiswork.
1.8DissertationContributions
Themajorcontributionsofthisdissertationarecategorizedintothetopicsofface
detection,facemodeling,andfacerecognition.In
facedetection
,wehavedeveloped
anewfacedetectionalgorithmformultiplenon-pro¯le-viewfaceswithcomplexback-
groundincolorimages,basedonlocalizationofskin-tonecolorandfacialfeatures
28
suchaseyes,mouthandfaceboundary.Themainpropertiesofthisalgorithmsare
listedasfollows.
²
Lightingcompensation
:Thismethodcorrectsthecolorbiasandrecovers
theskin-tonecolorbyautomaticallyestimatingthereferencewhitepixelsina
colorimage,undertheassumptionthatanimageusuallycontains\realwhite"
(i.e.,whitereference)pixelsandthedominantbiascolorinanimagealways
appearsas\realwhite".
²
Non-linearcolortransformation
:Inliterature,thechrominancecompo-
nentsoftheskintonehavebeenassumedtobeindependentoftheluminance
componentoftheskintone.Wefoundthatthechromaofskintonedependson
theluma.Weovercomethedi±cultyofdetectingthelow-lumaandhigh-luma
skintonecolorsbyapplyinganonlineartransformtothe
YC
b
C
r
colorspace.
Thetransformationisbasedonthelinearly¯ttedboundariesofourtraining
skinclusterin
YC
b
and
YC
r
colorsubspaces.
²
Modelingaskin-tonecolorclassi¯erasanellipticalregion
:Asimple
classi¯erwhichconstructsanellipticaldecisionregioninthechromasubspace,
C
b
C
r
,hasbeendesigned,undertheassumptionoftheGaussiandistributionof
skintonecolor.
²
Constructionoffacialfeaturemapsforeyes,mouth,andfacebound-
ary
:Withtheuseofgray-scalemorphologicaloperators(dilationanderosion),
weconstructthesefeaturemapsbyintegratingtheluminanceandchrominance
informationoffacialfeatures.Forexample,eyeregionshavehigh
C
b
(di®erence
29
betweenblueandgreencolors)andlow
C
r
(di®erencebetweenredandgreen
colors)valuesinchrominancecomponents,andhavebrighteranddarkervalues
intheluminancecomponent.
²
Constructionofadiversedatabaseofcolorimagesforfacedetection
:
ThedatabaseincludesaMPEG7contentset,mug-shotstylewebphotos,family
photos,andnewsphotos.
In
facemodeling
,wehavedesignedtwomethodsforaligninga3Dgenericface
modelontofacialmeasurementscapturedinthefrontalview:oneusesfacialmea-
surementsofregisteredcolorandrangedata;theothermerelyusescolorimages.In
the¯rstmethod,wehavedevelopedtwotechniquesforfacealignment:
²
2.5Dsnake
:A2.5Dsnakeisdesignedtolocallyadaptacontourtoeachfacial
component.Thedesignofsnakeincludesaniterativedeformationformula,
placementofinitialcontours,andtheminimizationofenergyfunctional.We
reformulated2Dactivecontours(adynamicprogrammingapproach)for3D
contoursofeye,nose,mouth,andfaceboundaryregions.Wehaveconstructed
initialcontoursbasedontheoutputsoffacedetection(i.e.,locationsoftheface
andfacialcomponents).Weformenergymapsforindividualfacialcomponents
basedon2Dcolorimageand2.5Drangedata,hencethename2.5Dsnake.
²
Displacementpropagation
:Thistechniqueisdesignedtopropagatethe
displacementofagroupofverticesona3Dfacemodelfromcontourpointson
facialcomponentstootherpointsonnon-facialcomponents.Thepropagation
30
canbeappliedtoa3Dfacemodelwheneverafacialcomponentiscoarsely
relocatedoris¯nelydeformedbythe2.5Dsnake.
Inthesecondfacemodelingmethod,wedevelopedatechniqueforfacealignment:
²
Interactingsnakes
:Thesnakedeformationisformulatedbya¯nitedi®er-
enceapproach.Theinitialsnakesforfacialcomponentsareobtainedfromthe
2Dprojectionofthesemanticfacegraphonageneric3Dfacemodel.Wehave
designedthe
interactingsnakes
techniqueformanipulatingmultiplesnakesit-
erativelythatminimizestheattractionenergyfunctionalsonbothcontours
andenclosedregionsofindividualsnakesandminimizestherepulsionenergy
functionalsamongmultiplesnakes.
In
facerecognition
,wehaveproposedtwoparadigmsasshowninFigs.1.11and
1.12.
²
The¯rst(rangedata-based)recognitionparadigm
:Thisparadigmisde-
signedto
automate
and
augment
appearance-basedfacerecognitionapproaches
basedon3Dfacemodels.Inthissystem,wehaveintegratedourfacedetection
algorithm,facemodelingmethodusingthe2.5Dsnake,andanappearance-
basedrecognitionmethodusingthehierarchicaldiscriminantregression[78].
However,therecognitionmodulecanbereplacedwithotherappearance-based
algorithmssuchasPCA-basedandLDA-basedmethods.Thesystemcanlearn
a3Dfacemodelforanindividual,andgenerateanarbitrarynumberof2D
faceimagesunderdi®erentheadposesandilluminations(canbeextendedto
di®erentexpressions)fortraininganappearance-basedfaceclassi¯er.
31
²
Thesecond(semantic)recognitionparadigm
:Thisparadigmisdesigned
toautomatethefacerecognitionprocessat
asemanticlevel
basedonthedis-
tinctivenessandvisibilityoffacialcomponentsinagivenfaceimagecapturedin
nearfrontalviews.(Thisparadigmcanbeextendedtofaceimagestakeninnon-
frontalviews).Wehavedecomposedageneric3Dfacemodelintorecognition-
orientedfacialcomponentsandnon-facialcomponents,andformeda3Dseman-
ticfacegraphforrepresentingfacialtopologyandextractingfacialcomponents.
Inthisrecognitionsystem,wehaveintegratedourfacedetectionalgorithm,our
facemodelingmethodusinginteractingsnakes,andoursemanticfacematching
algorithm.Therecognitioncanbeachievedatasemanticlevel(e.g.,comparing
facesbasedoneyesandthefaceboundaryonly)duetothealignmentoffacial
components.Wehavealsointroducedcomponentweights,whichplayacrucial
roleinfacematching,toemphasizecomponent'sdistinctivenessandvisibility.
Thesystemcangeneratecartoonfacesfromalignedsemanticfacegraphsand
facialcaricaturesbasedonanaveragedfacegraphforfacevisualization.
32
Chapter2
LiteratureReview
We¯rstreviewthedevelopmentoffacedetectionandrecognitionapproaches,fol-
lowedbyareviewoffacemodelingandmodelcompressionmethods.Finally,we
willpresentonemajorapplicationoffacerecognitiontechnology,namely,facere-
trieval.Weprimarilyfocusonthemethodsthatemploythetask-speci¯ccognition
orbehaviorsspeci¯edbyhumans(i.e.,arti¯cialintelligencepursuits),althoughthere
aredevelopmentalapproachesforfacialprocessing(e.g.,autonomousmentaldevel-
opment[79]andincrementallearning[80]methods)thathaveemergedrecently.
2.1FaceDetection
Variousapproachestofacedetectionarediscussedin[19],[20],[81],[82],and[83].The
majorapproachesarelistedchronologicallyinTable2.1foracomparison.Forrecent
surveysonfacedetection,see[82]and[83].Theseapproachesutilizetechniquessuch
asprincipalcomponentanalysis(PCA),neuralnetworks,machinelearning,infor-
33
Table2.1
Summaryofvariousfacedetectionapproaches.
Authors
Year
Approach
Features
Used
Head
Pose
Test
Databases
Minimal
Face
Size
F¶eraud
etal.[19]
2001
Neuralnet-
works
Motion;
Color;
Texture
Frontal
topro-
¯le
Sussex;
CMU;Web
images
15
£
20
DeCarlo
etal.[61]
2000
Optical
°ow
Motion;
Edge;
Deformable
facemodel;
Texture
Frontal
to
pro¯le
Videos
NA
Maioetal.
[20]
2000
Facial
templates;
Hough
transform
Texture;
Directional
images
Frontal
Videoim-
ages
20
£
27
Abdel-
Mottaleb
etal.[84]
1999
Skin
model;
Feature
Color
Frontal
to
pro¯le
HHI
13
£
13
Garcia
etal.[21]
1999
Statistical
wavelet
analysis
Color;
Wavelet
coe±cients
Frontal
tonear
frontal
MPEG
videos
80
£
48
Wuetal.
[85]
1999
Fuzzycolor
models;
Template
matching
Color
Frontal
to
pro¯le
Stillcolor
images
20
£
24
Rowleyet
al.[24],
[23]
1998
Neuralnet-
works
Texture
(Upright)
frontal
FERET;
CMU;Web
images
20
£
20
Sungetal.
[25]
1998
Learning
Texture
Frontal
Video
images;
newspaper
scans
19
£
19
Colmenarez
etal.[86]
1997
Learning
Markovpro-
cesses
Frontal
FERET
11
£
11
Yowetal.
[26]
1997
Feature;
Belief
networks
Geometrical
facial
features
Frontal
to
pro¯le
CMU
60
£
60
Lewetal.
[27]
1996
Markov
random
¯eld;
DFFS[64]
Most
informative
pixel
Frontal
MIT;
CMU;
Leiden
23
£
32
34
mationtheory,geometricalmodeling,(deformable)templatematching,Houghtrans-
form,extractionofgeometricalfacialfeatures,motionextraction,andcoloranalysis.
TypicaldetectionoutputsareshowninFig.2.1.Intheseimages,adetectedface
isusuallyoverlaidwithgraphicalobjectssuchasarectangleoranellipseforaface,
andcirclesorcrossesforeyes.Theneuralnetwork-based[24],[23]andtheview-
based[25]approachesrequirealargenumberoffaceandnon-facetrainingexamples,
andaredesignedprimarilytolocatefrontalfacesingrayscaleimages.Itisdi±cult
toenumerate\non-face"examplesforinclusioninthetrainingdatabases.Schnei-
dermanandKanade[22]extendtheirlearning-basedapproachforthedetectionof
frontalfacestopro¯leviews.Afeature-basedapproachcombininggeometricalfa-
cialfeatureswithbeliefnetworks[26]providesfacedetectionfornon-frontalviews.
GeometricalfacialtemplatesandtheHoughtransformwereincorporatedtodetect
grayscalefrontalfacesinrealtimeapplications[20].FacedetectorsbasedonMarkov
random¯elds[27],[87]andMarkovchains[88]makeuseofthespatialarrangement
ofpixelgrayvalues.Modelbasedapproachesarewidelyusedintrackingfacesand
oftenassumethattheinitiallocationofafaceisknown.Forexample,assuming
thatseveralfacialfeaturesarelocatedinthe¯rstframeofavideosequence,a3D
deformablefacemodelwasusedtotrackhumanfaces[61].Motionandcolorarevery
usefulcuesforreducingsearchspaceinfacedetectionalgorithms.Motioninformation
isusuallycombinedwithotherinformation(e.g.,facemodelsandskincolor)forface
detectionandtracking[89].AmethodofcombiningaHiddenMarkovModel(HMM)
andmotionfortrackingwaspresentedin[86].Acombinationofmotionandcolor
¯lters,andaneuralnetworkmodelwasproposedin[19].
35
(a)(b)(c)(d)
Figure2.1.Outputsofseveralfacedetectionalgorithms;(a),(b)F¶eraudetal.[19];(c)Maioetal.[20];(d)Garciaetal.[21];
(e),(f)Schneidermanetal.[22];(g)Rowleyetal.[23];(h),(i)Rowleyetal.[24];(j)Sungetal.[25];(k)Yowetal.[26];(l)
Lewetal.[27].
36
(e)(f)(g)(h)
(i)(j)(k)(l)
Figure2.1.(Cont'd).
37
Categorizingfacedetectionmethodsbasedontheirrepresentationsoffacesreveals
thatdetectionalgorithmsusingholisticrepresentationshavetheadvantageof¯nding
smallfacesorfacesinpoor-qualityimages,whilethoseusinggeometricalfacialfea-
turesprovideagoodsolutionfordetectingfacesindi®erentposes.Acombinationof
holisticandfeature-basedmethods[59],[60]isapromisingapproachtofacedetection
aswellasfacerecognition.Motion[86],[19]andskin-tonecolor[19],[84],[90],[85],
[21]areusefulcuesforfacedetection.However,thecolor-basedapproachesfacedif-
¯cultiesinrobustlydetectingskincolorsinthepresenceofcomplexbackgroundand
variationsinlightingconditions.Twocolorspaces(
YC
b
C
r
and
HSV
)havebeenpro-
posedfordetectingtheskincolorpatchestocompensateforlightingvariations[21].
Weproposeafacedetectionalgorithmthatisabletohandleawiderangeofcolor
variationsinstaticimages,basedonalightingcompensationtechniqueinthe
RGB
colorspaceandanonlinearcolortransformationinthe
YC
b
C
r
colorspace.Ourap-
proachmodelsskincolorusingaparametricellipseinatwo-dimensionaltransformed
colorspaceandextractsfacialfeaturesbyconstructingfeaturemapsfortheeyes,
mouthandfaceboundaryfromcolorcomponentsinthe
YC
b
C
r
space.
2.2FaceRecognition
Thehumanfacehasbeenconsideredasthemostinformativeorganforcommunication
inoursociallives[49].Automaticallyrecognizingfacesbymachinescanfacilitatea
widevarietyofforensicandsecurityapplications.Therepresentationofhumanfaces
forrecognitioncanvaryfroma2Dimagetoa3Dsurface.Di®erentrepresentations
38
resultindi®erentrecognitionapproaches.Extensivereviewsofapproachestoface
recognitionwerepublishedin1995[37],1999[31],andin2000[38].Aworkshop
onfaceprocessingin1985[91]presentedstudiesoffacerecognitionmainlyfromthe
viewpointofcognitivepsychology.Studiesoffeature-basedfacerecognition,computer
caricatures,andtheuseoffacesurfacesinsimulationandanimationweresummarized
in1992[49].In1997,Uwechueetal.[92]gavedetailsoffacerecognitionbasedonhigh-
orderneuralnetworksusing2Dfacepatterns.In1998,lecturesonfacerecognition
using2Dfacepatternswerepresentedfromtheorytoapplications[36].In1999,
Hallinanetal.[93]describedfacerecognitionusingboththestatisticalmodelsfor
2Dfacepatternsandthe3Dfacesurfaces.In2000,Gongetal.[94]emphasized
thestatisticallearningmethodsinholisticrecognitionapproachesanddiscussedface
recognitionfromtheviewpointofdynamicvision.
Theabovestudiesshowthatthefacerecognitiontechniques,especiallyholistic
methodsbasedonthestatisticalpatterntheory,havegreatlyadvancedoverthepast
tenyears.Facerecognitionsystems(e.g.,FaceIt[1]andFaceSnap[2])arebeingused
invideosurveillanceandsecuritymonitoringapplications.However,morereliable
androbusttechniquesforfacerecognitionaswellasdetectionarerequiredforseveral
applications.Exceptfortherecognitionapplicationsbasedonstaticfrontalimages
thataretakenunderwell-controlledenvironments(e.g.,indexingandsearchinglarge
imagedatabaseofdriversforissuingdrivinglicenses),themainchallengeinface
recognitionistobeabletodealwiththehighdegreeofvariabilityinhumanface
images.Thesourcesofvariationsincludeinter-subjectvariations(distinctivenessof
individualappearance)andintra-subjectvariations(in3Dpose,facialexpression,
39
facialhair,lighting,andaging).Somevariationsarenotremovable,whileothers
canbecompensatedforrecognition.Personswhohavesimilarfaceappearances,e.g.
twins,andanindividualwhocouldhavedi®erentappearancesduetocosmetics,or
otherchangesinfacialhairandglassesareverydi±culttorecognize.Variations
duetodi®erentposes,illuminations,andfacialexpressionsare
relativelyeasy
to
handle.Currentlyavailablealgorithmsforfacerecognitionconcentrateonrecognizing
facesunderthosevariationswhichcansomehowbecompensatedfor.Becausefacial
variationsduetoposecausealargeamountofappearancechange,moreandmore
systemsaretakingadvantageof3Dfacegeometryforrecognition.
Theperformanceofarecognitionalgorithmdependsonthefacedatabasesit
isevaluatedon.Severalfacedatabases,suchasMIT[95],Yale[96],Purdue[97],
andOlivetti[98]databasesarepublicallyavailableforresearchers.Figure2.2shows
someexamplesoffaceimagesfromtheFERET[28],MIT[29],andXM2VTS[30]
databases.AccordingtoPhillips[68],[28],theFERETevaluationoffacerecognition
algorithmsidenti¯esthreestate-of-the-arttechniques:(i)theprincipalcomponent
analysis(PCA)-basedapproach[99],[100],[29];(ii)theelasticbunchgraphicmatch-
ing(EBGM)-basedparadigm[32];and(iii)thelocalfeatureanalysis(LFA)-based
approach[34],[101].TheinternalrepresentationsofPCA-based,EBGM-based,and
LFA-basedrecognitionapproachesareshowninFigs.2.3,2.4,and2.5,respectively.
Torepresentandmatchfaces,thePCA-basedapproachmakesuseofasetoforthonor-
malbasisimages;theEBGM-basedapproachconstructsafacebunchgraph,whose
nodesareassociatedwithasetofwaveletcoe±cients(calledjets);theLFA-based
approachuseslocalizedkernels,whichareconstructedfromPCA-basedeigenvectors,
40
(a)
(b)
(c)
Figure2.2.Examplesoffaceimagesareselectedfrom(a)theFERETdatabase[28];
(b)theMITdatabase[29];(c)theXM2VTSdatabase[30].
41
fortopographicfacialfeatures(e.g.,eyebrows,cheek,mouth,etc.)
MeanMEF1MEF2MEF3MEF4MEF5MEF6MEF7MEF8
(a)
MeanMDF1MDF2MDF3MDF4MDF5MDF6MDF7MDF8
(b)
Figure2.3.InternalrepresentationsofthePCA-basedapproachandtheLDA-based
approach(fromWengandSwets[31]).Theaverage(mean)imagesareshowninthe
¯rstcolumn.MostExpressiveFeatures(MEF)andMostDiscriminatingFeatures
(MDF)areshownin(a)and(b),respectively.
ThePCA-basedalgorithmprovidesacompactbutnon-localrepresentationof
faceimages.Basedontheappearanceofanimageataspeci¯cview,thePCA
algorithmworksatthepixellevel.Hence,thealgorithmcanberegardedas\picture"
recognition,inotherwords,itisnotexplicitlyusinganyfacialfeatures.TheEBGM-
basedalgorithmconstructslocalfeatures(extractedusingGaborwavelets)andglobal
faceshape(representedasagraph),andsothisapproachismuchcloserto\face"
recognition.However,theEBGMalgorithmispose-dependent,anditrequiresinitial
graphsfordi®erentposesduringitstrainingstage.TheLFA-basedalgorithmis
derivedfromthePCA-basedmethod;itisalsocalledakernelPCAmethod.Inthis
approach,however,thechoiceofkernelfunctionsforlocalfacialfeatures(e.g.,eyes,
mouth,andnose)andtheselectionoflocationsofthesefeaturesstillremainsanopen
42
(a)(b)(c)
(d)(e)
Figure2.4.InternalrepresentationsoftheEBGM-basedapproach(fromWiskottet
al.[32]):(a)agraphisoverlaidonafaceimage;(b)areconstructionoftheimage
fromthegraph;(c)areconstructionoftheimagefromafacebunchgraphusingthe
best¯ttingjetateachnode.Imagesaredownloadedfrom[33];(d)abunchgraph
whosenodesareassociatedwithabunchofjets[33];(e)analternativeinterpretation
oftheconceptofabunchgraph[33].
question.
Inadditiontothesethreeapproaches,wecategorizefacerecognitionalgorithmson
thebasisofpose-dependencyandmatchingfeatures(seeFig.2.6).Inpose-dependent
algorithms,afaceisrepresentedbyasetofviewer-centeredimages.Asmallnumber
of2Dimages(appearances)ofahumanfaceatdi®erentposesarestoredasarepre-
sentativesetoftheface,whilethe3Dfaceshapeisimplicitlyrepresentedintheset.
43
(a)(b)
Figure2.5.InternalrepresentationsoftheLFA-basedapproach(fromPenevand
Atick[34]).(a)Anaveragefaceimageismarkedwith¯velocalizedfeatures;(b)¯ve
topographickernelsassociatedwiththe¯velocalizedfeaturesareshowninthetop
row,andthecorrespondingresidualcorrelationsareshowninthebottomrow.
Therepresentativesetcanbeobtainedfromeitherdigitalcamerasorextractedfrom
videos.Ontheotherhand,inpose-invariantapproaches,afaceisrepresentedbya
3Dfacemodel.The3Dfaceshapeofanindividualisexplicitlyrepresented,while
the2Dimagesareimplicitlyencodedinthisfacemodel.The3Dfacemodelscanbe
constructedbyusingeither3Ddigitizersorrangesensors,orbymodifyingageneric
facemodelusingavideosequenceorstillfaceimagesoffrontalandpro¯leviews.
Thepose-dependentalgorithmscanbefurtherdividedintothreeclasses:
appearance-based(holistic)[29],[78]feature-based(analytic)[102],[103]andhy-
brid(whichcombinesholisticandanalyticmethods)[60],[99],[32],[34]approaches.
Theappearance-basedmethodsaresensitivetointra-subjectvariations,especially
tochangesinhairstyle,becausetheyarebasedonglobalinformationinanimage.
However,thefeature-basedmethodssu®erfromthedi±cultyofdetectinglocal¯du-
cial\points".Thehybridapproacheswereproposedtoaccommodatebothglobaland
localfaceshapeinformation.Forexample,LFA-basedmethods,eigen-templatemeth-
44
Figure2.6.Abreakdownoffacerecognitionalgorithmsbasedonthepose-
dependency,facerepresentation,andfeaturesusedinmatching.
ods,andshape-and-shape-free[104]methodsbelongtothehybridapproachwhichis
derivedfromthePCAmethodology.TheEBGM-basedmethodsbelongtothehybrid
approachthatisbasedon2Dfacegraphsandwavelettransformsateachfeaturenode
ofthegraphs.Althoughtheyareinthehybridapproachcategory,theeigen-template
matchingandEBGM-basedmethodsaremuchclosertofeature-basedapproaches.
Inthepose-invariantalgorithms,3Dfacemodelsareutilizedtoreducethevaria-
tionsinposeandillumination.Gordonetal.[105]proposedanidenti¯cationsystem
basedon3Dfacerecognition.The3DmodelusedbyGordonetal.isrepresented
byanumberof3Dpointsassociatedwiththeircorrespondingtexturefeatures.This
methodrequiresanaccurateestimateofthefacepose.Lengagneetal.[106]proposed
a3Dfacereconstructionschemeusingapairofstereoimagesforrecognitionandmod-
45
eling.However,theydidnotimplementedtherecognitionmodule.Aticketal.[107]
proposedareconstructionmethodof3DfacesurfacesbasedontheKarhonen-Loeve
(KL)transformandtheshape-from-shadingapproach.Theydiscussedthepossibility
ofusing
eigenheadsurfaces
infacerecognitionapplications.Yanetal.[108]proposed
a3Dreconstructionmethodtoimprovetheperformanceoffacerecognitionbymak-
ingAticketal.'sreconstructionmethodrotation-invariant.Zhaoetal.[109]proposed
amethodtoadapta3Dmodelfromagenericrangemaptotheshapeobtainedfrom
shadingforenhancingfacerecognitionperformanceindi®erentlightingandviewing
conditions.
Basedonourbriefreview,webelievethatthecurrenttrendistouse3Dface
shapeexplicitlyforrecognition.Inordertoe±cientlystoreanindividual'sface,
oneapproachistoadapta3Dfacemodel[72]totheindividual.Thereisstilla
considerabledebateonwhethertheinternalrecognitionmechanismofahumanbrain
involvesexplicit3Dmodelsornot[49],[110].However,thereisenoughevidenceto
supportthefactthathumansuseinformationabout3Dstructureofobjects(e.g.,
3Dgeometryofaface)forrecognition.Closingoureyesandimaginingaface(ora
chair)caneasilyverifythishypothesis,sincethestructureofaface(orachair)can
appearinourmindwithouttheuseofeyes.Moreover,theuseofa3Dfacemodel
canseparatebothgeometricalandtexturefeaturesforfacialanalysis,andcanalso
blendbothofthemforrecognitionaswellasvisualization[67].Ourproposedsystems
belongtothisemergingtrend.
46
2.3FaceModeling
Facemodelingplaysacrucialroleinapplicationssuchashumanheadtracking,facial
animation,videocompression/coding,facialexpressionrecognition,andfacerecog-
nition.Researchersincomputergraphicshavebeeninterestedinmodelinghuman
facesforfacialanimation.Applicationssuchasvirtualrealityandaugmentedreality
[74]requiremodelingfacesforhumansimulationandcommunication.Inapplications
basedonfacerecognition,modelinghumanfacescanprovideanexplicitrepresenta-
tionofafacethatalignsfacialshapeandtexturefeaturestogetherforfacematching
atdi®erentposesandindi®erentilluminationconditions.
2.3.1GenericFaceModels
We¯rstreviewthreemajorapproachestomodelinghumanfacesandthenpointout
anadvancedmodelingapproachthatmakesuseofthe
apriori
knowledgeoffacial
geometry.DeCarloetal.[111]usetheanthropometricmeasurementstogeneratea
generalfacemodel(seeFig.2.7).Thisapproachstartswithmanually-constructed
B-splinesurfacesandthenappliessurface¯ttingandconstraintoptimizationtothese
surfaces.Itiscomputationallyintensiveduetoitsoptimizationmechanism.Inthe
secondapproach,facialmeasurementsaredirectlyacquiredfrom3Ddigitizersor
structuredlightrangesensors.3Dmodelsareobtainedafterapostprocessing,tri-
angularization,ontheseshapemeasurements.Thethirdapproach,inwhichmodels
arereconstructedfromphotographs,onlyrequireslow-costandpassiveinputdevices
(videocameras).Somecomputervisiontechniquesforreconstructing3Ddatacan
47
(a)(b)
Figure2.7.Facemodelingusinganthropometricmeasurements(downloaded
from[35]):(a)anthropometricmeasurements;(b)aB-splinefacemodel.
beusedforfacemodeling.Forinstance,Lengagneetal.[106]andChenetal.[112]
builtfacemodelsfromapairofstereoimages.Aticketal.[107]andYanetal.
[108]reconstructed3DfacesurfacesbasedontheKarhonen-Loeve(KL)transform
andtheshape-from-shadingtechnique.Zhaoetal.[109]madeuseofasymmet-
ricshape-from-shadingtechniquetobuilda3Dfacemodelforrecognition.There
areothermethodswhichcombinebothshape-from-stereo(whichextractslow-spatial
frequencycomponentsof3Dshape)andshape-from-shading(extractinghigh-spatial
frequencycomponents)toreconstruct3Dfaces[113],[114],[115].See[116]foraddi-
tionalmethodstoobtainfacialsurfacedata.However,currentlyitisstilldi±cultto
extractsu±cientinformationaboutthefacialgeometryonlyfrom2Dimages.This
di±cultyisthereasonwhyGuenteretal.[117]utilizealargenumberof¯ducial
pointstocapture3Dfacegeometryforphotorealisticanimation.Eventhoughwe
canobtaindense3Dfacialmeasurementsfromhigh-cost3Ddigitizers,ittakestoo
muchtimeanditisexpensivetoscanalargenumberofhumansubjects.
48
Anadvancedmodelingapproachwhichincorporates
apriori
knowledgeoffa-
cialgeometryhasbeenproposedfore±cientlybuildingfacemodels.Wecallthe
modelrepresentingthegeneralfacialgeometryasagenericfacemodel.Waters'face
model[69],showninFig.2.8(a),isawell-knowninstanceofpolygonalfacialsurfaces.
Figure2.8(b)showssomeothergenericfacemodels.TheoneusedbyBlanzandVet-
(a)(b)
Figure2.8.Genericfacemodels:(a)Water'sanimationmodel;(b)anthropometric
measurements;(b)sixkindsoffacemodelsforrepresentinggeneralfacialgeometry.
terisastatistics-basedfacemodelwhichisrepresentedbytheprincipalcomponents
ofshapeandtexturedata.Reindersetal.[72]usedafairly
coarse
wire-framemodel,
comparedtoWaters'model,todomodeladaptationforimagecoding.Yinetal.
[118]proposedaMPEG4facemodelingmethodthatuses¯ducialpointsextracted
fromtwofaceimagesatfrontalandpro¯leviews.Theirfeatureextractionissimply
basedontheresultsofintensitythresholdingandedgedetection.Similarly,Leeet
al.[119]haveproposedamethodthatmodi¯esagenericmodelusingeithertwoor-
thogonalpictures(frontalandpro¯leviews)orrangedata,foranimation.Similarly,
49
forfacialanimation,Lengagneetal.[120]andFua[121]usebundle-adjustmentand
least-squares¯ttingto¯tacomplexanimationmodeltouncalibratedvideos.This
algorithmmakesuseofstereodata,silhouetteedges,and2Dfeaturepoints.Five
manually-selectedfeaturespointsandinitialvaluesofcamerapositionsareessential
fortheconvergenceofthismethod.Ahlberg[122]adaptsa3Dwireframemodel
(CANDIDE-3[123])toa2Dvideoimage.Thetwomodelingmethodsproposedin
thisthesisfollowthemodelingapproachusingagenericfacemodel;bothofourmeth-
odsmakeuseofagenericfacemodel(Waters'facemodel)as
apriori
knowledgeof
facialgeometryandemploy(i)displacementpropagationand2.5Dsnakesinthe¯rst
methodand(ii)interactingsnakesandsemanticfacegraphsinthesecondmethod
foradaptingrecognition-orientatedfeaturestoanindividual'sgeometry.
2.3.2SnakesforFaceAlignment
Asacomputationalbridgebetweenthehigh-levelaprioriknowledgeofobjectshape
andthelow-levelimagedata,snakes(oractivecontours)areusefulmodelsforextract-
ingtheshapeofdeformableobjects.Similartoothertemplate-basedapproachessuch
asHoughtransformandactiveshapemodels,activecontourshavebeenemployed
todetectobjectboundary,trackobjects,reconstruct3Dobjects(stereosnakesand
inter-framesnakes),andmatch/identifyshape.Snakesselfconvergeinaniterative
way,anddeformeitherwithorwithouttopologicalconstraints.
Researchonactivecontoursfocusesonissuesrelatedtorepresentation(e.g.,para-
metriccurves,splines,Fourierseries,andimplicitlevel-setfunctions),energyfunc-
50
tionalstominimize,implementationmethods(e.g.,classical¯nitedi®erencemodels,
dynamicprogramming[124],andFourierspectralmethods),convergenceratesand
conditions,andtheirrelationshiptostatisticaltheory[125](e.g.,theBayesianesti-
mation).Classicalsnakes[77],[126]arerepresentedbyparametriccurvesandarede-
formedby¯nitedi®erencemethodsbasedonedgeenergies.Inapplications,di®erent
typesofedgeenergiesincludingimagegradients,gradientvector°ows[127],distance
maps,andballoonforcehavebeenproposed.Ontheotherhand,combinedwith
level-setmethodsandthecurveevolutiontheory,activecontourshaveemergedasa
powerfultool,calledgeodesicactivecontours(GAC)[128],toextractdeformableob-
jectswithunknowngeometrictopology.However,intheGACapproach,thecontours
areimplicitlyrepresentedaslevel-setfunctionsandareclosedcurves.Inadditionto
theedgeenergy,regionenergyhasbeenintroducedtoimprovethesegmentationre-
sultsforhomogeneousobjectsinboththeparametricandtheGACapproaches(e.g.,
regionandedge[129],GACwithoutedge[130],statisticalregionsnake[131],region
competition[132],andactiveregionmodel[133]).Recently,multipleactivecontours
[134],[135]wereproposedtoextract/partitionmultiplehomogeneousregionsthatdo
notoverlapwitheachotherinanimage.
Inour¯rstalignmentmethod,wehavereformulated2Dactivecontours(ady-
namicprogrammingapproach)in3Dcoordinatesforenergiesderivedfrom2.5Drange
and2Dcolordata.Inoursecondalignmentmethod,wemakeuseofmultiple2D
snakes(a¯nitedi®erenceapproach)thatinteractwitheachotherinordertoadapt
facialcomponents.
51
2.3.33DModelCompression
Amongvariousrepresentationsof3-Dobjects,surfacemodelscanexplicitlyrepresent
shapeinformationandcane®ectivelyprovideavisualizationoftheseobjects.The
polygonalmodelusingtriangularmeshesisthemostprevalenttypeofsurfacerep-
resentationsforfree-formobjectssuchashumanfaces.Thereasonisthatthemesh
modelexplicitlydescribestheconnectivityofsurfaces,enablesmeshsimpli¯cation,
andissuitableforfree-formobjects[136].Thepolygonizationofanobjectsurfaceap-
proximatesthesurfacebyalargenumberoftriangles(facets),eachofwhichcontains
primaryinformationaboutvertexpositionsaswellasvertexassociations(indices),
andauxiliaryinformationregardingfacetpropertiessuchascolor,texture,specu-
larity,re°ectivity,orientation,andtransparency.Sinceweuseatriangularmeshto
representagenericfacemodelandanadaptedmodel,modelcompressionispreferred
whene±cienttransmission,visualization,andstorageisrequired.
In1995,theconceptofgeometriccompressionwas¯rstintroducedbyDeer-
ing[137],whoproposedatechniqueforlossycompressionof3-Dgeometricdata.
Deering'stechniquefocusesmainlyonthecompressionofvertexpositionsandfacet
propertiesof3-Dtriangledata.Taubin[75]proposed
topologicalsurgery
whichfurther
contributedconnectivityencoding(compressionofassociationinformation)togeo-
metriccompression.Lounsberyetal.[76]performedgeometriccompressionthrough
multiresolutionanalysisforparticularmesheswithsubdivisionconnectivity.Apply-
ingremeshingalgorithmstoarbitrarymeshes,Ecketal.[138]extendedLounsbery's
workonmeshsimpli¯cation.Typicalcompressionratiosinthislineofdevelopment
52
arelistedinTable2.2.Allofthesecompressionmethodsfocusonmodelrepresen-
Table2.2
Geometriccompressionefficiency.
Method
Geometric
Compression
LossMeasure
Compressedfeature
Ratio(GCR)
Geometric
Compression[137]
6{10
slightlosses
Positions,normals,
colors
Topological
Surgery[75]
20{100
noloss
Connectivity;
12{30
N/A
Positions,facet
properties;
20{100
N/A
ASCII-¯lesizes
Remeshing[138]
54{1.2
Remeshing&com-
pressiontolerances
Levelofdetail
(facets)
tationusingtriangularmeshes.However,formorecomplex3Dshapes,thesurface
representationusingtriangularmeshesusuallyresultsinalargenumberoftriangu-
larfacets,becauseeachtriangularfacetisexplicitlydescribed.Wehavedeveloped
anovelcompressionapproachforfree-formsurfacesusing3Dwaveletsandlattice
vectorquantization[139].Inourapproach,surfacesareimplicitlyrepresentedin-
sideavolumeinthesamewayasedgesina2Dimage.Afurtherimprovementin
ourapproachcanbeachievedbymakinguseofintegerwavelettransformation[140],
[141].
53
2.4FaceRetrieval
Facerecognitiontechnologyprovidesausefultoolforcontent-basedimageandvideo
retrievalusingtheconceptofhumanfaces.Basedonfacedetectionandidenti¯cation
technology,wecandesignasystemforconsumerphotomanagement(orforweb
graphicsearch)thatuseshumanfacesforindexingandretrievingimagecontentand
generatesannotation(textualdescriptions)fortheimagecontentautomatically.
Traditionaltext-basedretrievalsystemsfordigitallibrariescannotful¯llare-
trievalofvisualcontentsuchashumanfaces,eyeshape,andcarsinimageorvideo
databases.Hence,manyresearchershavebeendevelopingmultimediaretrievaltech-
niquesbasedonautomaticallyextractingsalientfeaturesfromthevisualcontent(see
[40]foranextensivereview).Wellknownsystemsforcontent-basedimageandvideo
retrievalareQBIC[142],Photobook[143],CONIVAS[144],FourEyes[145],Virage
[146],ViBE[147],VideoQ[148],Visualseek[149],Netra[150],MARS[151],PicSOM
[152],ImageScape[153],etc.Inthesesystems,retrievalisperformedbycomparing
asetoflow-levelfeaturesofaqueryimageorvideoclipwithfeaturesstoredinthe
databaseandthenbypresentingtheuserwiththecontentthathasthemostsimilar
features.However,usersnormallyqueryanimageorvideodatabasebasedonseman-
ticsratherthanlow-levelfeatures.Forexample,atypicalquerymightbespeci¯ed
as\retrieveimagesof¯reworks"ratherthan\retrieveimagesthathavelargedark
regionsandcolorfulcurvesoverthedarkregions".
Sincethecommonlyusedfeaturesareusuallyasetofunorganizedlow-levelat-
tributes(suchascolor,texture,geometricalshape,layout,andmotion),grouping
54
low-levelfeaturescanprovidemeaningfulhigh-levelsemanticsforhumanconsumers.
Therehasbeensomeworkdoneonautomaticallyclassifyingimagesintosemantic
categories[154],suchasindoors/outdoorsandcity/landscapeimages.Asforthe
semanticconceptoffaces,thegenericfacialtopology(e.g.,ourproposedgenericse-
manticfacegraph)isausefulstructureforrepresentingthe
face
inasearchengine.
Wehavedesignedagraphicaluserinterfaceforfaceeditingusingourfacedetection
algorithm.Combinedwithoursemanticfacematchingalgorithm,wecanbuildaface
retrievalsystem.
2.5Summary
Wehavebrie°ydescribedthedevelopmentoffacedetection,facerecognition,face
modelingandmodelcompressioninthischapter.Wehavesummarizedtheper-
formanceofcurrentlyavailablefacedetectionsystemsinTable2.3.Notethatthe
performanceofadetectionsystemdependsonseveralfactorssuchasfacedatabases
onwhichthesystemisevaluated,systemarchitecture,distancemetric,andalgorith-
micparameters.Theperformanceisevaluatedbasedonthedetectionrate,thefalse
positiverate(falseacceptancerate),anddatabases.InTable2.3,wedonotinclude
thefalseacceptanceratebecausethefalsepositiveratehasnotbeencompletelyre-
portedinliterature.WereferthereadertotheFERETevaluation[68],[28]forthe
performanceofvariousfacerecognitionsystems.
Facedetectionandfacerecognitionarecloselyrelatedtoeachotherinthesense
ofcategorizingfaces.Overthepasttenyears,basedonthestatisticalpatterntheory,
55
Table2.3
Summaryofperformanceofvariousfacedetectionapproaches.
Authors
Year
Head
Pose
Test
Databases
DetectionRate
F¶eraudetal.
[19]
2001
Frontal
to
pro¯le
Sussex;
CMUtest1;
Webimages
100%forSussex;
81%
»
86%forCMUtest1;
74
:
7%
»
80
:
1%forWeb
images.
Maioetal.
[20]
2000
Frontal
Staticimages
89
:
53%
»
91
:
34%
Schneiderman
etal.[22]
2000
Frontal
to
pro¯le
CMU;Web
images
75
:
24%
»
92
:
7%
Garciaetal.
[21]
1999
Frontal
tonear
frontal
MPEGvideos
93
:
27%
Rowleyetal.
[24],[23]
1998
(Upright)
frontal
CMU;
FERET;
Webimages
86%[24];79
:
6%[23]forro-
tatedfaces
Yowetal.
[26]
1997
Frontal
to
pro¯le
CMU
84%
»
92%
Lewetal.[27]
1996
Frontal
MIT;CMU;
Leiden
87%
»
95%
theappearance-based(holistic)approachhasgreatlyadvancedthe¯eldoffacerecog-
nition.Bycategorizingfacedetectionmethodsbasedontheirrepresentationsofthe
face,weobservethatdetection/recognitionalgorithmsusingholisticrepresentations
havetheadvantageof¯nding/identifyingsmallfacesorfacesinpoor-qualityimages
(i.e.detection/recognitionunderuncertainty),whilethoseusinggeometricalfacial
featuresprovideagoodsolutionfordetecting/recognizingfacesindi®erentposesand
expressions.Theinternalrepresentationofahumanfacesubstantiallya®ectstheper-
formanceanddesignofadetectionorrecognitionsystem.Aseamlesscombinationof
56
holistic2Dandgeometrical3Dfeaturesprovidesapromisingapproachtorepresent
facesforfacedetectionaswellasfacerecognition.Modelinghumanfacein3Dspace
hasbeenshowntobeusefulforfacerecognition.However,theimportantaspect
offacemodelingishowto
e±cientlyencode
the3Dfacialgeometryandtextureas
compactfeaturesforfacerecognition.
57
Chapter3
FaceDetection
Wewill¯rstdescribeanoverviewofourproposedfacedetectionalgorithmandthen
givedetailsofthealgorithm.Wewilldemonstratetheperformanceandexperimental
resultsonseveralimagedatabases.
3.1FaceDetectionAlgorithm
Theuseofcolorinformationcansimplifythetaskoffacelocalizationincomplex
environments[19],[84],[90],[85].Therefore,weuseskincolordetectionasthe¯rst
stepindetectingfaces.Anoverviewofourfacedetectionalgorithmisdepictedin
Fig.3.1,whichcontainstwomajormodules:(i)facelocalizationfor¯ndingface
candidates;and(ii)facialfeaturedetectionforverifyingdetectedfacecandidates.
Thefacelocalizationmodulecombinestheinformationextractedfromtheluminance
andthechrominancecomponentsofcolorimagesandsomeheuristicsaboutface
shape(e.g.,facesizesrangingfrom13
£
13pixelstoaboutthreefourthsoftheimage
58
size)togeneratepotential
facecandidates
,withintheentireimage.Thealgorithm
¯rstestimatesandcorrectsthecolorbiasbasedonanovellightingcompensation
technique.Thecorrectedred,green,andbluecolorcomponentsare¯rstconverted
tothe
YC
b
C
r
colorspaceandthennonlinearlytransformedinthiscolorspace(see
formulaeinAppendixA).Theskin-tonepixelsaredetectedusinganellipticalskin
modelinthetransformedspace.Theparametricellipsecorrespondstocontoursof
constantMahalanobisdistanceundertheassumptionoftheGaussiandistributionof
skintonecolor.Thedetectedskin-tonepixelsareiterativelysegmentedusinglocal
colorvarianceintoconnectedcomponentswhicharethengroupedintofacecandidates
basedonboththespatialarrangementofthesecomponents(describedinAppendix
B)andthesimilarityoftheircolor[84].Figure3.1showstheinputcolorimage,color
compensatedimage,skinregions,groupedskinregions,andfacecandidatesobtained
fromthefacelocalizationmodule.Eachgroupedskinregionisassignedapseudo
colorandeachfacecandidateisrepresentedbyarectangle.Becausemultipleface
candidates(boundingrectangles)usuallyoverlap,theycanbefusedbasedonthe
percentageofoverlappingareas.However,inspiteofthispostprocessingthereare
stillsomefalsepositivesamongfacecandidates.
Itisinevitablethatdetectedskin-toneregionswillincludesomenon-faceregions
whosecolorissimilartotheskin-tone.Thefacialfeaturedetectionmodulerejects
facecandidateregionsthatdonotcontainanyfacialfeaturessuchaseyes,mouth,
andfaceboundary.Thismodulecandetectmultipleeyeandmouthcandidates.A
triangleisconstructedfromtwoeyecandidatesandonemouthcandidate,andthe
best-¯ttingenclosingellipseofthetriangleisconstructedtoapproximatetheface
59
Figure3.1.Facedetectionalgorithm.Thefacelocalizationmodule¯ndsfacecandi-
dates,whichareveri¯edbythedetectionmodulebasedonfacialfeatures.
60
boundary.Afacescoreiscomputedforeachsetofeyes,mouthandtheellipse.
Figure3.1showsadetectedfaceandtheenclosingellipsewithitsassociatedeye-
mouthtrianglewhichhasthehighestscorethatexceedsathreshold.Thesedetected
facialfeaturesaregroupedintoastructuredfacialdescriptorintheformofa2D
graphforfacedescription.Thesedescriptorscanbetheinputtosubsequentmodules
suchasfacemodelingandrecognition.Wenowdescribeindetailtheindividual
componentsofthefacedetectionalgorithm.
3.2LightingCompensationandSkinTone
Detection
Theappearanceoftheskin-tonecolorcanchangeduetodi®erentlightingconditions.
Weintroducealightingcompensationtechniquethatuses\referencewhite"tonor-
malizethecolorappearance.Weregardpixelswiththetop5%oftheluma(nonlinear
gamma-correctedluminance)valuesasthereferencewhiteifthenumberofthesepix-
elsissu±cientlylarge(
>
100).Thered,green,andbluecomponentsofacolorimage
areadjustedsothatthesereference-whitepixelsarescaledtothegraylevelof255.
Thecolorcomponentsareunalteredifasu±cientnumberofreference-whitepixels
isnotdetected.Thisassumptionisreasonablenotonlybecauseanimageusually
contains\realwhite"(i.e.,whitereferencein[155])pixelsinsomeregionsofinterest
(suchaseyeregions),butalsobecausethedominantbiascoloralwaysappearsin
the\realwhite".Figure3.2demonstratesanexampleofourlightingcompensation
61
(a)(b)
(c)(d)
Figure3.2.Skindetection:(a)ayellow-biasedfaceimage;(b)alightingcompensated
image;(c)skinregionsof(a)showninwhite;(d)skinregionsof(b).
method.NotethattheyellowbiascolorinFig.3.2(a)hasbeenremoved,asshownin
Fig.3.2(b).Thee®ectoflightingcompensationondetectedskinregionscanbeseen
bycomparingFigs.3.2(c)and3.2(d).Withlightingcompensation,ouralgorithm
detectsfewernon-faceareasandmoreskin-tonefacialareas.Notethatthevaria-
tionsinskincoloramongdi®erentracialgroups,re°ectioncharacteristicsofhuman
skinanditssurroundingobjects(includingclothing),andcameracharacteristicswill
alla®ecttheappearanceofskincolorandhencetheperformanceofanautomatic
facedetectionalgorithm.Therefore,ifmodelsofthelightingsourceandcamerasare
available,additionallightingcorrectionshouldbemadetoremovecolorbias.
Modelingskincolorrequireschoosinganappropriatecolorspaceandidentifying
aclusterassociatedwithskincolorinthisspace.Ithasbeenobservedthatthe
62
normalizedred-green(
r
-
g
)space[156]isnotthebestchoiceforfacedetection[157],
[158].BasedonTerrillonetal.'s[157]comparisonofninedi®erentcolorspacesfor
facedetection,thetint-saturation-luma(TSL)spaceprovidesthebestresultsfor
twokindsofGaussiandensitymodels(unimodalandmixtureofGaussiandensities).
Weadoptthe
YC
b
C
r
spacesinceitisperceptuallyuniform[155],iswidelyusedin
videocompressionstandards(e.g.,MPEGandJPEG)[21],anditissimilartothe
TSLspaceintermsoftheseparationofluminanceandchrominanceaswellasthe
compactnessoftheskincluster.Manyresearchstudiesassumethatthechrominance
componentsoftheskin-tonecolorareindependentoftheluminancecomponent[159],
[160],[158],[90].However,inpractice,theskin-tonecolorisnonlinearlydependent
onluminance.Inordertodemonstratethelumadependencyofskin-tonecolor,we
manuallycollectedtrainingsamplesofskinpatches(853
;
571pixels)from9subjects
(137images)intheHeinrich-Hertz-Institute(HHI)imagedatabase[15].Thesepixels
formanelongatedclusterthatshrinksathighandlowlumainthe
YC
b
C
r
space,
showninFig.3.3(a).Detectingskintonebasedontheclusteroftrainingsamplesin
the
C
b
-
C
r
subspace,showninFig.3.3(b),resultsinmanyfalsepositives.Ifwebase
thedetectionontheclusterinthe(
C
b
=Y
)-(
C
r
=Y
)subspace,showninFig.3.3(c),then
manyfalsenegativesresult.Thedependencyofskintonecoloronlumaisalsopresent
inthenormalized
rgY
spaceinFig.3.4(a),theperceptuallyuniform
CIExyY
space
inFig.3.4(c),andthe
HSV
spacesinFig.3.4(e).The3Dclustershapechangesat
di®erentlumavalues,althoughitlookscompactinthe2Dprojectionsubspaces,in
Figs.3.4(b),3.4(d)and3.4(f).
Todealwiththeskin-tonecolordependenceonluminance,wenonlinearlytrans-
63
formthe
YC
b
C
r
colorspacetomaketheskinclusterluma-independent.Thisisdone
by¯ttingapiecewiselinearboundarytotheskincluster(seeFig.3.5).Thedetails
ofthemodelandthetransformationaredescribedinAppendixA.Thetransformed
space,showninFig.3.6(a),enablesarobustdetectionofdarkandlightskintone
colors.Figure3.6(b)showstheprojectionofthe3Dskinclusterinthetransformed
C
b
-
C
r
colorsubspace,onwhichtheellipticalmodelofskincolorisoverlaid.Figure3.7
showsexamplesofdetectionusingthenonlineartransformation.Moreskin-tonepix-
elswithlowandhighlumaaredetectedinthistransformedsubspacethaninthe
C
b
C
r
subspace.
64
(a)
(b)(c)
Figure3.3.The
YC
b
C
r
colorspace(bluedotsrepresentthereproduciblecolorona
monitor)andtheskintonemodel(reddotsrepresentskincolorsamples).(a)The
YC
b
C
r
space;(b)a2Dprojectioninthe
C
b
-
C
r
subspace;(c)a2Dprojectioninthe
(
C
b
=Y
)-(
C
r
=Y
)subspace.
65
(a)(b)
(c)(d)
(e)(f)
Figure3.4.Thedependencyofskintonecoloronluma.Theskintonecluster(red
dots)isshownin(a)the
rgY
,(c)the
CIExyY
,and(e)the
HSV
colorspaces;the
2Dprojectionoftheclusterisshownin(b)the
r
¡
g
,(d)the
x
¡
y
,and(f)
S
¡
H
colorsubspaces,wherebluedotsrepresentthereproduciblecoloronamonitor.For
abetterpresentationofclustershape,wenormalizetheluma
Y
inthe
rgY
andthe
CIExyY
by255,andswapthehueandsaturationcoordinatesinthe
HSV
space.
Theskintoneclusterislesscompactatlowsaturationvaluesin(e)and(f).
66
(a)(b)
Figure3.5.2Dprojectionsofthe3Dskintoneclusterin(a)the
Y
-
C
b
subspace;(b)
the
Y
-
C
r
subspace.Reddotsindicatetheskincluster.Threebluedashedcurves,
oneforclustercenterandtwoforboundaries,indicatethe¯ttedmodels.
(a)(b)
Figure3.6.Thenonlineartransformationofthe
YC
b
C
r
colorspace.(a)Thetrans-
formed
YC
b
C
r
colorspace;(b)a2Dprojectionof(a)inthe
C
b
-
C
r
subspace,inwhich
theellipticalskinmodelisoverlaidontheskincluster.
67
(a)(b)(c)
(d)(e)(f)
Figure3.7.Nonlinearcolortransform.Sixdetectionexamples,withandwithoutthetransformareshown.Foreachexample,
theimagesshowninthe¯rstcolumnareskinregionsanddetectionswithoutthetransform,whilethoseinthesecondcolumn
areresultswiththetransform.
68
3.3LocalizationofFacialFeatures
Amongthevariousfacialfeatures,eyes,mouth,andfaceboundaryarethemost
prominentfeaturesforrecognition[103]andforestimationof3Dheadpose[161],
[162].Mostapproachesforeye[163],[164],[165],[166],[167],mouth[165],[168],
faceboundary[165],andface[20]localizationaretemplatebased.However,our
approachisabletodirectlylocateeyes,mouth,andfaceboundarybasedontheir
featuremapsderivedfromthethelumaandthechromaofanimage,calledtheeye
map,themouthmapandthefaceboundarymap,respectively.Forcomputingthe
eyemapandthemouthmap,weconsideronlytheareacoveredbya
facemask
that
isbuiltbyenclosingthegroupedskin-toneregionswithapseudoconvexhull,which
isconstructedbyconnectingtheboundarypointsofskin-toneregionsinhorizontal
andverticaldirections.Figure3.8showsanexampleofthefacemask.
(a)(b)(c)(d)
Figure3.8.Constructionofthefacemask.(a)Facecandidates;(b)oneoftheface
candidates;(c)groupedskinareas;(d)thefacemask.
69
3.3.1EyeMap
We¯rstbuildtwoseparateeyemaps,onefromthechrominancecomponentsand
theotherfromtheluminancecomponentofthecolorimage.Thesetwomapsare
thencombinedintoasingleeyemap.Theeyemapfromthechromaisbasedon
theobservationthathigh
C
b
andlow
C
r
valuesarefoundaroundtheeyes.Itis
constructedfrominformationcontainedin
C
b
,theinverse(negative)of
C
r
,andthe
ratio
C
b
=C
r
,asdescribedinEq.(3.1).
EyeMapC
=
1
3
f
(
C
2
b
)+(
~
C
r
)
2
+(
C
b
=C
r
)
g
;
(3.1)
where
C
2
b
,(
~
C
r
)
2
,and
C
b
=C
r
allarenormalizedtotherange[0
;
255]and
~
Cr
isthe
negativeof
C
r
(i.e.,255
¡
C
r
).Anexampleoftheeyemapfromthechromaisshown
inFig.3.9(a).
Theeyesusuallycontainbothdarkandbrightpixelsinthelumacomponent.
Basedonthisobservation,grayscalemorphologicaloperators(e.g.,dilationandero-
sion)[169]canbedesignedtoemphasizebrighteranddarkerpixelsintheluma
componentaroundeyeregions.Theseoperationshavebeenusedtoconstructfeature
vectorsforfaceimagesatmultiplescalesforfrontalfaceauthentication[66].We
usegrayscaledilationanderosionwithahemisphericstructuringelementatasingle
estimatedscaletoconstructtheeyemapfromtheluma,asdescribedinEq.(3.2).
EyeMapL
=
Y
(
x;y
)
©
g
¾
(
x;y
)
Y
(
x;y
)
ª
g
¾
(
x;y
)+1
;
(3.2)
wherethegrayscaledilation
©
anderosion
ª
operations[169]onafunction
f
:
F½
R
2
¡!
R
usingastructuringfunction
g
:
G½
R
2
¡!
R
arede¯nedasfollows.
70
(a)
(b)
(c)
Figure3.9.Constructionofeyemaps:(a)fromchroma;(b)fromluma;(c)the
combinedeyemap.
71
(
f
©
g
¾
)(
x;y
)=
Max
f
f
(
x
¡
c;y
¡
r
)+
g
(
c;r
)
g
;
(
x
¡
c;y
¡
r
)
2F
;
(
c;r
)
2G
;
(3.3)
(
f
ª
g
¾
)(
x;y
)=
Min
f
f
(
x
¡
c;y
¡
r
)+
g
(
c;r
)
g
;
(
x
¡
c;y
¡
r
)
2F
;
(
c;r
)
2G
;
(3.4)
g
¾
(
x;y
)=
(
j
¾
j¢
³
¯
¯
1
¡
(
R
(
x;y
)
=¾
)
2
¯
¯
1
=
2
¡
1
´
;
R
·j
¾
j
;
¡1
;
R>
j
¾
j
;
(3.5)
R
(
x;y
)=
p
x
2
+
y
2
;
(3.6)
where
¾
isascaleparameter,whichwillbedescribedlaterinEq.(3.11).Anexample
ofahemisphericstructuringelementisshowninFig.3.10.Theconstructionofthe
Figure3.10.Anexampleofahemisphericstructuringelementforgrayscalemorpho-
logicaldilationanderosionwith
¾
=1.
eyemapfromthelumaisillustratedinFig.3.9(b).Notethatbeforeperformingthe
grayscaledilationanderosionoperations,we¯llthebackgroundofthefacemask
withthemeanvalueofthelumainthefacemask(skinregions)inordertosmooth
thenoisyboundaryofdetectedskinareas.
72
Theeyemapfromthechromaisenhancedbyhistogramequalization,andthen
combinedwiththeeyemapfromthelumabyanAND(multiplication)operationin
Eq.(3.7).
EyeMap
=(
EyeMapC
)
AND
(
EyeMapL
)
:
(3.7)
Theresultingeyemapisdilated,masked,andnormalizedtobrightentheeyesand
suppressotherfacialareas,ascanbeseeninFig.3.9(c).Thelocationsoftheeye
candidatesareinitiallyestimatedfromthepyramiddecompositionoftheeyemap,
andthenre¯nedusingiterativethresholdingandbinarymorphologicalclosingonthis
eyemap.
3.3.2MouthMap
Thecolorofmouthregioncontainsmoreredcomponentcomparedtothebluecompo-
nentthanotherfacialregions.Hence,thechrominancecomponent
C
r
,proportional
to(
red
¡
Y
),isgreaterthan
C
b
,proportionalto(
blue
¡
Y
),nearthemouthareas.
Wefurthernoticethatthemouthhasarelativelylowresponseinthe
C
r
=C
b
feature,
butithasahighresponsein
C
2
r
.Weconstructthemouthmapasfollows:
MouthMap
=
C
2
r
¢
¡
C
2
r
¡
´
¢
C
r
=C
b
¢
2
;(3.8)
´
=0
:
95
¢
1
n
P
(
x;y
)
2FG
C
r
(
x;y
)
2
1
n
P
(
x;y
)
2FG
C
r
(
x;y
)
=C
b
(
x;y
)
;
(3.9)
whereboth
C
2
r
and
C
r
=C
b
arenormalizedtotherange[0
;
255],and
n
isthenumber
ofpixelswithinthefacemask,
FG
.Theparameter
´
isestimatedastheratioofthe
73
average
C
2
r
totheaverage
C
r
=C
b
.Figure3.11showsthemajorstepsincomputing
themouthmapofthesubjectinFig.3.9.Notethatafterthemouthmapisdilated,
masked,andnormalized,itisdramaticallybrighternearthemouthareasthanat
otherfacialareas.
Figure3.11.Constructionofthemouthmap.
3.3.3EyeandMouthCandidates
Weforman
eye-mouthtriangle
forallpossiblecombinationsoftwoeyecandidates
andonemouthcandidatewithinafacecandidate.Wethenverifyeacheye-mouth
trianglebychecking(i)lumavariationsandaveragegradientorientationsofeyeand
mouthblobs;(ii)geometryandorientationconstraintsofthetriangle;and(iii)the
presenceofafaceboundaryaroundthetriangle.Aweightiscomputedforeach
veri¯edeye-mouthtriangle.Thetrianglewiththehighestweightthatexceedsa
thresholdisselected.WediscussthedetectionoffaceboundaryinSection3.3.4,and
theselectionoftheweightandthethresholdinSection3.3.5.
Notethattheeyeandmouthmapsarecomputedwithintheentireareasofthe
facecandidate,whichisboundedbyarectangle.Thesearchfortheeyesandthe
74
mouthisperformedwithinthefacemask.Theeyeandmouthcandidatesarelocated
byusing(i)apyramiddecompositionoftheeye/mouthmapsand(ii)aniterative
thresholdingandbinarymorphologicalclosingontheenhancedeyeandmouthmaps.
Thenumberofpyramidlevels,
L
,iscomputedfromthesizeofthefacecandidate,as
de¯nedinEqs.(3.10)and(3.11).
L
=
Max
fd
log
2
(2
¾
)
e
;
b
log
2
(
Min
(
W;H
)
=F
c
)
cg
;(3.10)
¾
=
b
p
W
¢
H=
(2
¢
F
e
)
c
;
(3.11)
where
W
and
H
representthewidthandheightofthefacecandidate;
F
c
£
F
c
isthe
minimumexpectedsizeofafacecandidate;
¾
isaspreadfactorselectedtoprevent
thealgorithmfromremovingsmalleyesandmouthsinthemorphologicaloperations;
and
F
e
isthemaximalratioofanaveragefacesizetotheaverageeyesize.Inour
implementation,
F
c
is7pixels,and
F
e
is12pixels.
Thecoarselocationsofeyeandmouthcandidatesobtainedfromthepyramidde-
compositionarere¯nedbycheckingtheexistenceofeyes/mouthblobswhichareob-
tainedafteriterativelythresholdingand(morphologically)closingtheeyeandmouth
maps.Theiterativethresholdingstartswithaninitialthresholdvalue,reducesthe
thresholdstepbystep,andstopswheneitherthethresholdfallsbelowastopping
valueorwhenthenumberoffeaturecandidatesreachespre-determinedupperbounds,
N
eye
fortheeyesand
N
mth
forthemouth.Thethresholdvaluesareautomatically
computedasfollows.
Th
=
®
n
X
(
x;y
)
2FG
Map
(
x;y
)+(1
¡
®
)
¢
Max
(
x;y
)
2FG
Map
(
x;y
)
;
(3.12)
75
where
Map
(
x;y
)iseithertheeyeorthemouthmap;theparameter
®
isequalto
0
:
5fortheinitialthresholdvalue,andisequalto0
:
8forthestoppingthreshold.
Theuseofupperboundsonthenumberofeyeandmouthcandidatescanprevent
thealgorithmfromspendingtoomuchtimeinsearchingforfacialfeatures.Inour
implementation,themaximumnumberofeyecandidates,
N
eye
,is8andthemaximum
numberofmouthcandidates,
N
mth
,is5.
3.3.4FaceBoundaryMap
Basedonthelocationsofeyes/mouthcandidates,ouralgorithm¯rstveri¯eswhether
theaverageorientationoflumagradientsaroundeacheyematchestheinterocular
direction,andthenconstructsafaceboundarymapfromtheluma.Finally,itutilizes
theHoughtransformtoextractthebest-¯ttingellipse.The¯ttedellipseisusedfor
computingtheeye-mouthtriangleweight.Figure3.12showstheboundarymapthat
isconstructedfromboththemagnitudeandtheorientationcomponentsoftheluma
gradientwithintheregionsthathavepositiveorientationsofthegradientorientations
(i.e.,havecounterclock-wisegradientorientations).Wehavemodi¯edCannyedge
detection[170]algorithmtocomputethegradientofthelumaasfollows.Thegradient
ofalumasubimage,
S
(
x;y
),whichisslightlylargerthanthefacecandidateinsize
isestimatedby
r
S
(
x;y
)=(
G
x
;G
y
)=(
D
¾
(
x
)
~
S
(
x;y
)
;D
¾
(
y
)
~
S
(
x;y
))
;
(3.13)
76
Figure3.12.Computationoffaceboundaryandtheeye-mouthtriangle.
77
where
D
¾
(
x
)isthederivativeoftheGaussianwithzeromeanandvariance
¾
2
,and
~
istheconvolutionoperator.UnliketheCannyedgedetector,ouredgedetection
requiresonlyasinglestandarddeviation
¾
(aspreadfactor)fortheGaussianthatis
estimatedfromthesizeoftheeye-mouthtriangle.
¾
=
µ
¡
ws
2
8ln(
wh
)
¶
1
=
2
;
ws
=
Max
(
dist
io
;dist
em
)
;
(3.14)
where
ws
isthewindowsizeforaGaussian,whichisthemaximumvalueofthe
interoculardistance(
dist
io
)andthedistancebetweentheinterocularmidpointand
themouth(
dist
em
);
wh
=0
:
1isthedesiredvalueoftheGaussiandistributionatthe
borderofthewindow.InFig.3.12,themagnitudesandorientationsofallgradients
havebeensquaredandscaledbetween0and255.Fig.3.12showsthatthegradient
orientationprovidesmoreinformationtodetectfaceboundariesthanthegradient
magnitude.So,anedgedetectionalgorithmisappliedtothegradientorientation
andtheresultingedgemapisthresholdedtoobtainamaskforcomputingtheface
boundary.Thegradientmagnitudeandthemagnitudeofthegradientorientation
aremasked,added,andscaledintotheinterval[0
;
1]toconstructthefaceboundary
map.Thecenterofaface,indicatedasawhiterectangleinthefaceboundarymap
inFig.3.12,isestimatedfromthe¯rst-ordermomentofthefaceboundarymap.
TheHoughtransformisusedto¯tanellipticalshapetothefaceboundarymap.
Anellipseinaplanehas¯veparameters:anorientationangle,twocoordinatesofthe
78
center,andlengthsofmajorandminoraxes.Sinceweknowthelocationsofeyesand
mouth,theorientationoftheellipsecanbeestimatedfromthedirectionofavector
thatstartsfromthemidpointbetweentheeyestowardsthemouth.Thelocationof
theellipsecenterisestimatedfromthefaceboundarymap.Hence,weneedonlya
two-dimensionalaccumulatorforestimatingtheellipseforboundingtheface.The
accumulatorisupdatedbyperturbingtheestimatedcenterbyafewpixelsforamore
accuratelocalizationoftheellipse.
3.3.5WeightSelectionforaFaceCandidate
Foreachfaceintheimage,ouralgorithmcandetectseveraleye-mouth-trianglecandi-
datesthatareconstructedfromeyeandmouthcandidates.Eachcandidateisassigned
aweightwhichiscomputedfromtheeyeandmouthmaps,themaximumaccumula-
torcountintheHoughtransformforellipse¯tting,andfaceorientationthatfavors
verticalfacesandsymmetricfacialgeometry,asdescribedinEqs.(3.15)-(3.19).The
eye-mouthtrianglewiththehighestweight(facescore)thatisaboveathresholdis
retained.InEq.(3.15),thetriangleweight,
tw
(
i;j;k
),forthe
i
-thandthe
j
-theye
candidatesandthe
k
-thmouthcandidateistheproductoftheeye-mouthweight,
emw
(
i;j;k
),theface-orientationweight,
ow
(
i;j;k
),andboundaryquality,
q
(
i;j;k
).
Theeye-mouthweightistheaverageoftheeye-pairweight,
ew
(
i;j
),andthemouth
weight,
mw
(
k
),asdescribedinEq.(3.16).
79
tw
(
i;j;k
)=
emw
(
i;j;k
)
¢
ow
(
i;j;k
)
¢
q
(
i;j;k
);(3.15)
emw
(
i;j;k
)=
1
2
(
ew
(
i;j
)+
mw
(
k
));(3.16)
ew
(
i;j
)=
EyeMap
(
x
i
;y
i
)+
EyeMap
(
x
j
;y
j
)
2
¢
EyeMap
(
x
m
;y
m
)
;
i>j
;
i;j
2
[1
;N
eye
];(3.17)
mw
(
k
)=
MouthMap
(
x
k
;y
k
)
MouthMap
(
x
m
;y
m
)
;
k
2
[1
;N
mth
];(3.18)
ow
(
i;j;k
)=
2
Y
r
=1
e
¡
3(1
¡
cos
2
(
µ
r
(
i;j;k
)))
;
cos
(
µ
r
(
i;j;k
))=
~u
r
¢
~v
r
k
~v
r
k
;
k
~v
r
k
=1
:
(3.19)
Eq.(3.17)describestheeye-pairweightwhichisthenormalizedaverageoftheeye
mapvaluearoundthetwoeyes,where
EyeMap
(
x
i
;y
i
)istheeyemapvalueforthe
i
-theyecandidate(associatedwithaneyeblobandacorrespondingpixelinthe
lowestleveloftheimagepyramid).
EyeMap
(
x
m
;y
m
)istheeyemapvalueforthe
mostsigni¯canteyecandidate(havingthehighestresponsewithintheeyemap).The
mouthweight,
mw
(
k
)inEq.(3.18),isobtainedbynormalizingthemouthmapvalue
atthe
k
-thmouthcandidate(i.e.,amouthblob),
MouthMap
(
x
k
;y
k
),bythemouth
mapvalueatthemostsigni¯cantmouthcandidate,
MouthMap
(
x
m
;y
m
).Theface-
orientationweight,describedinEq.(3.19),istheproductoftwoattenuationterms,
eachofwhichisanexponentialfunctionofaprojection(
cosµ
r
)ofavector(
~v
r
)alonga
particulardirection(
~u
r
),where
r
=1
;
2.AscanbeseeninFig.3.13,onetermfavors
asymmetricface,anditisaprojection(
cosµ
1
)ofthevector
~v
1
(fromthemidpointof
thetwoeyestothemouth)alongavector(
~u
1
)thatisperpendiculartotheinterocular
80
segment.Theothertermfavorsanuprightface,andisaprojectionofavector
~v
2
(fromthemouthtothemidpointofthetwoeyes)alongtheverticalaxis(
~u
2
)ofthe
imageplane.Theexponentialfunction,showninFig.3.14,isdesignedsuchthatthe
attenuationhasthemaximalvalueof1when
µ
1
=
µ
2
=0
±
(i.e.,wheneyesandmouth
formaletter\T"orequivalentlythefaceisupright),anditdecreasestobelow0
:
5
at
µ
1
=
µ
2
=25
±
.Thequalityoffaceboundary,
q
(
i;j;k
),canbedirectlyobtained
fromthevotesreceivedbythebestellipticalfaceboundaryintheHoughtransform.
Figure3.13.Geometryofaneye-mouthtriangle,where
~v
1
=
¡
~v
2
;unitvectors
~u
1
and
~u
2
areperpendiculartotheinterocularsegmentandthehorizontalaxis,respectively.
Figure3.14.Attenuationterm,
e
¡
3(1
¡
cos
2
(
µ
r
(
i;j;k
)))
,plottedasafunctionoftheangle
µ
r
(indegrees)hasamaximalvalueof1at
µ
r
=0
±
,andavalueof0.5at
µ
r
=25
±
.
81
Thepose-orientedthresholdforthefacescoreisempiricallydeterminedandusedfor
removingfalsepositives(0
:
16fornear-frontalviewsand0
:
13forhalf-pro¯leviews).
Thefacepose(frontalvs.pro¯le)isestimatedbycomparingthedistancesfromeach
ofthetwoeyestothemajoraxisofthe¯ttedellipse.
3.4ExperimentalResults
Wehaveevaluatedouralgorithmonseveralfaceimagedatabases,includingfamily
andnewsphotocollections.Facedatabasesdesignedforfacerecognition,includ-
ingtheFERETfacedatabase[28],usuallycontaingrayscalemugshot-styleimages,
therefore,inouropinion,arenotsuitableforevaluatingfacedetectionalgorithms.
Mostofthecommonlyuseddatabasesforfacedetection,includingtheCarnegieMel-
lonUniversity(CMU)database,containgrayscaleimagesonly.Therefore,wehave
constructedourdatabasesforfacedetectionfromMPEG7videos,theWorldWide
Web,andpersonalphotocollections.Thesecolorimageshavebeentakentakenun-
dervaryinglightingconditionsandwithcomplexbackgrounds.Further,theseimages
havesubstantialvariabilityinqualityandtheycontainmultiplefaceswithvariations
incolor,position,scale,orientation,3Dpose,andfacialexpression.
Ouralgorithmcandetectmultiplefacesofdi®erentsizeswithawiderangeof
facialvariationsinanimage.Further,thealgorithmcandetectbothdarkskin-tones
andbrightskin-tonesbecauseofthenonlineartransformationofthe
C
b
¡
C
r
color
space.Allthealgorithmicparametersinourfacedetectorhavebeenempiricallyde-
termined;sameparametervalueshavebeenusedforallthetestimages.Figure
82
(a)(b)
(c)(d)
(e)(f)
Figure3.15.Facedetectionexamplescontainingdarkskin-tonefaces.Eachexample
containsaninputimage,groupedskinregionsshowninpseudocolor,andalighting-
compensatedimageoverlaidwithdetectedfaceandfacialfeatures.
3.15demonstratesthatouralgorithmcansuccessfullydetectdarkskinfaces.Figure
3.16showstheresultsforsubjectswithsomefacialvariations(e.g.,closedeyesor
openmouth).Figure3.17showsdetectedfacesforsubjectswhoarewearingglasses.
Theeyeglassescanbreakupthedetectedskintonecomponentsofafaceintosmaller
components,andcausere°ectionsaroundtheeyes.Figure3.18showsthatthepro-
posedalgorithmisnotsensitivetothepresenceoffacialhair(moustacheandbeard).
Figure3.19demonstratesthatouralgorithmcandetectnon-frontalfacesaslongas
theeyesandmoutharevisibleinhalf-pro¯leviews.
Asummaryofthedetectionresults(includingthenumberoffalsepositives,de-
83
(a)(b)(c)(d)(e)
Figure3.16.Facedetectionresultsonclosed-eyeoropen-mouthfaces.Eachexample
containsanoriginalimage(top)andalighting-compensatedimage(bottom)overlaid
withfacedetectionresults.
(a)(b)(c)(d)(e)
Figure3.17.Facedetectionresultsinthepresenceofeyeglasses.Eachexample
containsanoriginalimage(top)andalighting-compensatedimage(bottom)overlaid
withfacedetectionresults.
tectionrates,andaverageCPUtimeforprocessinganimage)ontheHHIMPEG7
imagedatabase[15]andtheChampiondatabase[171]arepresentedinTables3.1and
3.2,respectively.Notethatthedetectionratedependsonthedatabase.TheHHI
imagedatabasecontains206images,eachofsize640
£
480pixels.Subjectsinthe
HHIimagedatabasebelongtoseveralracialgroups.Lightingconditions(including
overheadlightsandsidelights)changefromoneimagetoanother.Further,these
imagescontainfrontal,near-frontal,half-pro¯le,andpro¯lefaceviewsofdi®erent
sizes.Adetectedfaceisa
correct
detectionifthedetectedlocationsoftheeyes,
84
(a)(b)(c)(d)(e)
Figure3.18.Facedetectionresultsforsubjectswithfacialhair.Eachexample
containsanoriginalimage(top)andalighting-compensatedimage(bottom)overlaid
withfacedetectionresults.
themouth,andtheellipseboundingahumanfacearefoundwithasmallamount
oftolerance,otherwiseitiscalleda
falsepositive
.Thedetectionrateiscomputed
bytheratioofthenumberofcorrectdetectionsinagallerytothatofallhuman
facesinthegallery.Figure3.20(a)showsasubsetoftheHHIimages.Thedetec-
tionresultsofouralgorithmareshowninthreestages.Inthe¯rststage,weshow
theskin-toneregions(Fig.3.20(b))usingpseudo-color;di®erentcolorscorrespond
todi®erentskin-tonegroups.Inthesecondstage,wefuseboundingrectanglesthat
havesigni¯cantoverlappingareaswithneighboringrectangles(Fig.3.20(c)).Each
boundingrectangleindicatesafacecandidate.Inthethirdstage,welocallydetect
facialfeaturesforeachfacecandidate.Figure3.20(d)showsthe¯naldetectionre-
sultsafterthesethreestages.Thedetectedfacesaredepictedbyyellow-blueellipses,
andthedetectedfacialfeatures(eyesandmouth)areconnectedbyatriangle.The
detectionratesandthenumberoffalsepositivesfordi®erentposesaresummarized
inTable3.1.Thedetectionrateafterthe¯rsttwostagesisabout97%forallposes.
Afterthethirdstage,thedetectionratedecreasesto89
:
40%forfrontalfaces,andto
85
(a)(b)(c)(d)(e)
(f)(g)(h)(i)(j)
Figure3.19.Facedetectionresultsonhalf-pro¯lefaces.Eachexamplecontainsan
originalimage(top)andalighting-compensatedimage(bottom)overlaidwithface
detectionresults.
90
:
74%fornear-frontalfaces,andto74
:
67%forhalf-pro¯lefaces.Thereasonforthis
decreaseindetectionrateistheremovalofthosefacesinwhichtheeyes/mouthare
notvisible.However,wecanseethatthenumberoffalsepositivesisdramatically
reducedfrom9
;
406aftertheskingroupingstagetojust27afterthefeaturedetection
stageforthewholedatabasecontaining206images.
TheChampiondatabasewascollectedfromtheInternet,andcontains227
com-
pressed
imageswhichareapproximately150
£
220pixelsinsize.Becausemostofthe
imagesinthisdatabasearecapturedinfrontalandnear-frontalviews,wepresenta
singledetectionrateforallposesinTable3.2.Thedetectionrateforthe¯rsttwo
stagesisabout99
:
12%.Afterthethirdstage,thedetectionratedecreasesto91
:
63%.
86
Thenumberoffalsepositivesisalsodramaticallyreducedfrom5
;
582to14.We
presentfacedetectionresultsonasubsetoftheChampiondatabaseinFig.3.21.
Figure3.22showsthedetectionresultsonacollectionoffamilyphotos(totalof55
images).Figure3.23showsresultsonasubsetofnewsphotos(totalof327images)
downloadedfromtheYahoonewssite[172].Asexpected,detectingfacesinfamily
groupandnewspicturesismorechallenging,butouralgorithmisabletoperform
quitewellontheseimages.Detectionrateonthecollectionof382familyandnews
photos(1
:
79facesperimage)is80
:
35%,andthefalsepositiverate(theratioofthe
numberoffalsepositivestothenumberoftruefaces)is10
:
41%.Moreresultsare
availableathttp://www.cse.msu.edu/
»
hsureinl/facloc/.
87
Table3.1
DetectionresultsontheHHIimagedatabase(Imagesize
640
£
480
)on
aPCwith1.7GHzCPU.FP:FalsePositives,DR:DetectionRate.
HeadPose
Frontal
Near-
Frontal
Half-
Pro¯le
Pro¯le
Total
No.ofimages
66
54
75
11
206
Stage1:Groupedskinregions
No.ofFP
3145
2203
3781
277
9406
DR(%)
95.45
98.15
96.00
100
96.60
Time(sec):average
§
s.d.
1.56
§
0.45
Stage2:Rectanglemerge
No.ofFP
468
287
582
39
1376
DR(%)
95.45
98.15
96.00
100
96.60
Time(sec):average
§
s.d.
0.18
§
0.23
Stage3:Facialfeaturedetection
No.ofFP
4
6
14
3
27
DR(%)
89.40
90.74
74.67
18.18
80.58
Time(sec):average
§
s.d.
22.97
§
17.35
Table3.2
DetectionresultsontheChampiondatabase(Imagesize
»
150
£
220
)
onaPCwith860MHzCPU.FP:FalsePositives,DR:DetectionRate.
Stage
1
2
3
No.ofimages
227
No.ofFP
5582
382
14
DR(%)
99.12
99.12
91.63
Time(sec):average
§
s.d.
0
:
080
§
0
:
036
0
:
012
§
0
:
020
5
:
780
§
4
:
980
88
(a)(b)(c)(d)
Figure3.20.FacedetectionresultsonasubsetoftheHHIdatabase:(a)input
images;(b)groupedskinregions;(c)facecandidates;(d)detectedfacesareoverlaid
onthelighting-compensatedimages.
89
(a)(b)(c)(d)
Figure3.21.FacedetectionresultsonasubsetoftheChampiondatabase:(a)input
images;(b)groupedskinregions;(c)facecandidates;(d)detectedfacesareoverlaid
onthelighting-compensatedimages.
90
Figure3.22.Facedetectionresultsonasubsetofelevenfamilyphotos.Eachim-
agecontainsmultiplehumanfaces.Thedetectedfacesareoverlaidonthecolor-
compensatedimages.Falsenegativesareduetoextremelightingconditionsand
shadows.Noticethedi®erencebetweentheinputandcolor-compensatedimagesin
termsofcolorbalance.Thebiascolorintheoriginalimageshasbeencompensated
intheresultantimages.
91
Figure3.22.(Cont'd).
92
Figure3.22.(Cont'd).
93
Figure3.23.Facedetectionresultsonasubsetof24newsphotos.Thedetectedfaces
areoverlaidonthecolor-compensatedimages.Falsenegativesareduetoextreme
lightingconditions,shadows,andlowimagequality(i.e.,highcompressionrate).
94
3.5Summary
Wehavepresentedafacedetectionalgorithmforcolorimagesusingaskin-tonecolor
modelandfacialfeatures.Ourmethod¯rstcorrectsthecolorbiasbyalighting
compensationtechniquethatautomaticallyestimatesthereferencewhitepixels.We
overcomethedi±cultyofdetectingthelow-lumaandhigh-lumaskintonesbyap-
plyinganonlineartransformtothe
YC
b
C
r
colorspace.Ourmethoddetectsskin
regionsovertheentireimage,andthengeneratesfacecandidatesbasedonthespatial
arrangementoftheseskinpatches.Itthenconstructseye,mouth,andboundary
mapsfordetectingtheeyes,mouth,andfaceboundary,respectively.Thefacecan-
didatesarefurtherveri¯edbythepresenceofthesefacialfeatures.Detectionresults
onseveralphotocollectionshavebeendemonstrated.Ourgoalistodesignasystem
thatdetectsfacesandfacialfeatures,allowsuserstoeditdetectedfaces(viatheuser
interfaceshowninFig.3.24),andusesthesedetectedfacialfeaturesasindicesfor
identi¯cationandforretrievalfromimageandvideodatabases.
95
(a)
(b)
Figure3.24.Graphicaluserinterface(GUI)forfaceediting:(a)detectionmode;(b)
editingmode.
96
Chapter4
FaceModeling
We¯rstintroduceanoverviewofourmodelingmethod[173],anddescribethegeneric
facemodelandfacialmeasurements.Thenwepresentanapproachforadaptingthe
genericmodeltothefacialmeasurements.Finally,anadapted3Dfacemodelofan
individualistexture-mappedandreproducedatdi®erentviewpointsforvisualization
andrecognition.
4.1ModelingMethod
Fore±ciency,weconstructa3Dmodelofahumanfacefrom
apriori
knowledge(a
genericfacemodel)ofthegeometryofthehumanface.Thegenericfacemodelisa
triangularmesh,whoseverticescanpreciselyspecifyfacialfeaturesthatarecrucialfor
recognition,suchaseyebrows,eyes,nose,mouth,andfaceboundary.Wecallthese
featuresrecognition-orientedfeatures.Thelocationsandassociatedpropertiesof
theserecognition-orientedfeaturesareextractedfromcolortextureandrangedata(or
97
Figure4.1.Thesystemoverviewoftheproposedmodelingmethodbasedona3D
genericfacemodel.
disparitymaps)obtainedforanindividual.Thegenericfacemodelismodi¯edsothat
theserecognition-orientedfeaturesare¯ttedtotheindividual'sfacialgeometry.The
modelingprocessalignsandadaptsthegenericfacemodeltothefacialmeasurements
inaglobal-to-localfashion.Theoverviewofourfacemodelingmethodisgivenin
Fig.4.1.Theinputtothemodelingalgorithmisthegenericfacemodelandthe
facialmeasurements.Themodelingmethodcontainstwomajormodules:(i)global
alignmentand(ii)localadaptation.Theglobalalignmentmodulechangesthesizeof
thegenericfacemodel,andalignsthescaledgenericmodelaccordingtothe3Dhead
pose.Thelocaladaptationmodulere¯nesthefacialfeaturesofthegloballyaligned
genericfacemodeliterativelyandlocally.Wedonotextractisosurfacesdirectlyfrom
facialmeasurementsbecausefacialmeasurementsareoftennoisy(e.g.,neartheears
98
andnoseinfrontalviews),andbecausetheextractionistime-consumingandusually
generatestrianglesofthesamesizeinthemesh.Hence,inourmodelconstruction,the
desiredrecognition-orientedfacialfeaturescanbespeci¯edandgraduallymodi¯ed
inthe3Dgenericfacemodel.Themodelingalgorithmgeneratesanadapted/learned
3Dfacemodelwithalignedfacialtexture.The2Dprojectionsofthetexture-mapped
3Dmodelarefurtherusedforfaceveri¯cationandrecognition.
4.2GenericFaceModel
WechooseWaters'animationmodel[69],whichcontains256verticesand441facets
foronehalfoftheface,becausethismodelcapturesmostofthefacialfeaturesthatare
neededforfacerecognition(aswellasanimation),andbecausetriangularmeshesare
suitableforfree-formsurfaceslikefaces[136].Figure4.2showsthefrontalandoneside
viewofthemodel,andfacialfeaturessuchaseyes,nose,mouth,faceboundary,and
chin.Thereareopeningsatboththeeyesandthemouth,whichcanbemanipulated.
ThePhong-shadedappearanceofthismodelisshownforthreedi®erentviewsin
Fig.4.3.
99
(a)(b)(c)
Figure4.2.3Dtriangular-meshmodelanditsfeaturecomponents:(a)thefrontal
view;(b)asideview;(c)featurecomponents.
Figure4.3.Phong-shaded3Dmodelshownatthreeviewpoints.Illuminationisin
frontofthefacemodel.
100
4.3FacialMeasurements
Facialmeasurementsshouldincludeinformationaboutfaceshapeandfacialtexture.
3Dshapeinformationcanbederivedfromastereopair,acollectionofframesina
videosequence,orshapefromshading.Itcanalsobeobtaineddirectlyfromrange
data.Weusetherangedatabaseofhumanfaces[174],whichwasacquiredusinga
MinoltaVivid700digitizer.Thedigitizergeneratesaregistered200
£
200rangemap
anda400
£
400colorimageforeachacquisition.Figure4.4showsacolorimage
andarangemapofafrontalview,andthetexture-mappedappearancefromthree
di®erentviews.Thelocationsoffaceandfacialfeaturessuchaseyesandmouthin
thecolortextureimagecanbedetectedbythefacedetectionalgorithmdescribedin
Chapter3[175](seeFig.4.5(a)).Thecornersofeyes,mouth,andnosecanbeeasily
obtainedbasedonthelocationsofdetectedeyesandmouth.Figure4.5(b)showsthe
detectedfeaturepoints.
101
(a)(b)
(c)(d)(e)
Figure4.4.Facialmeasurementsofahumanface:(a)colorimage;(b)rangemap;
andtherangemapwithtexturemappedfor(c)aleftview;(d)apro¯leview;(e)a
rightview.
(a)(b)
Figure4.5.Facialfeaturesoverlaidonthecolorimage,(a)obtainedfromface
detection;(b)generatedforfacemodeling.
102
4.4ModelConstruction
Ourfacemodelingprocessconsistsof
globalalignment
and
localadaptation
.Global
alignment¯rstbringsthegenericmodelandfacialmeasurementsintothesameco-
ordinatesystem.Basedonthe3Dheadposeandthefacesize,thegenericmodelis
thenscaled,rotated,andtranslatedto¯tthefacialmeasurements.Figure4.6shows
theglobalalignmentresultsintwodi®erentmodes.Localadaptationconsistsof
local
(a)(b)
Figure4.6.Globalalignmentofthegenericmodel(inred)tothefacialmeasurements
(inblue):thetargetmeshisplottedin(a)forahiddenlineremovalmodeforaside
view;(b)forasee-throughmodeforapro¯leview.
alignment
and
localfeaturere¯nement
.Localalignmentinvolvesscalingandtrans-
latingmodelfeatures,suchaseyes,nose,mouth,chinandfaceboundaryto¯tthe
extractedfacialfeatures.Localfeaturere¯nementmakesuseoftwonewtechniques{
displacementpropagation
and
2.5Dactivecontours
{tosmooththefacemodelandto
re¯nelocalfeatures.Thelocalalignmentandthelocalre¯nementofeachfeature
103
(showninFig.4.2(c))arefollowedbydisplacement(ofmodelvertices)propagation,
inordertoblendfeaturesinthefacemodel.
Displacementpropagationinsideatriangularmeshmimicsthetransmissionof
messagepacketsincomputernetworks.Let
N
i
bethenumberofverticesthatare
connectedtoavertex
V
i
,
J
i
bethesetofalltheindicesofverticesthatareconnected
tothevertex
V
i
,
w
i
bethesumofweights(eachofwhichistheEuclideandistance
betweentwovertices)onalltheverticesthatareconnectedtothevertex
V
i
,and
d
ij
betheEuclideandistancebetweenthevertex
V
i
andavertex
V
j
.Let¢
V
j
bethe
displacementofvertex
V
j
,and
®
bethedecayfactor,whichcanbedeterminedby
thefacesizeandthesizeoftheactivefacialfeatureineachcoordinate.Eq.(4.1)
computesthecontributionofvertex
V
j
tothedisplacementofvertex
V
i
.
¢
V
ij
=
(
¢
V
j
¢
w
i
¡
d
ij
w
i
¢
(
N
i
¡
1)
¢
e
¡
®d
ij
;N
i
>
1
;w
i
=
P
j
2
J
i
d
ij
¢
V
j
¢
e
¡
®d
ij
;N
i
=1
;j
2
J
i
:
(4.1)
Inotherwords,¢
V
ij
iscomputedastheproductofthedisplacement,theweight,and
Figure4.7.Displacementpropagation.
104
afeature-dependentdecayfactor.Figure4.7depictsasmallportionofatriangular
meshnetworkaroundthevertex
V
i
.Themeshnetworkillustratesthedisplacement,
¢
V
ij
1
,contributedbyavertex
V
j
1
(inblue),andthedisplacement,¢
V
ij
2
,contributed
byavertex
V
j
2
(inred).Inthiscase,thevertex
V
i
hassixneighboringvertices,i.e.,
N
i
is6.Thetotaldisplacement¢
V
i
of
V
i
canbeobtainedbysummingupallthe
displacementscontributedbyitsneighboringverticesasfollows.
¢
V
i
=
X
j
2
J
i
¢
V
ij
:
Thedisplacementwilldecayduringpropagationanditwillcontinueforfewiterations.
Thenumberofiterationsisdeterminedbythenumberofedgeconnectionsfromthe
currentfeaturetothenearestneighboringfeature.Infutureimplementations,we
willincludethesymmetricpropertyofafaceandfacialtopologyincomputingthis
displacement.Figure4.8showstheresultsoflocalalignmentforthefrontalview
afterthreeiterationsofdisplacementpropagation.
(a)(b)(c)(d)
Figure4.8.Localfeaturealignmentanddisplacementpropagationshownforthe
frontalview:(a)theinputgenericmodel;themodeladaptedto(b)thelefteye;(c)
thenose;(d)mouthandchin.
105
Localfeaturere¯nementfollowslocalalignmenttofurtheradaptthealignedface
modeltoanindividualfacebyusing2.5Dactivecontours(snakes).WemodifyAmini
etal.'s[124]2Dsnakesforour3Dactivecontoursonboundariesoffacialfeatures.
Theactivecontoursareusefulfordetectingirregularshapesbyminimizingthe(total)
energyoftheshapecontour.Thetotalenergy,
E
total
,consistsoftheinternalenergy
E
int
(controllingthegeometryofthecontour)andexternalenergy
E
ext
(controlling
thedesiredshape).Wereformulatetheenergyforour3Dsnakeasfollows.Assume
thatanactivecontourincludesasetofNvertices:
f
v
1
;
¢¢¢
;v
i
¡
1
;v
i
;v
i
+1
;
¢¢¢
;v
N
g
.
ThetotalenergycanbecomputedbyEq.(4.2).
E
total
=
N
X
i
=1
[
E
int
(
v
i
)+
E
ext
(
v
i
)]
:
(4.2)
TheinternalenergyislistedinEq.(4.3).
E
int
(
v
i
)=
¡
®
i
j
v
i
¡
v
i
¡
1
j
2
+
¯
i
j
v
i
+1
¡
2
v
i
+
v
i
¡
1
j
2
¢
=
2
;
(4.3)
where
®
i
controlsthedistancebetweenvertices,and
¯
i
controlsthesmoothnessof
thecontours.Thenormterm
j¢j
inEq.(4.3)isdeterminedbyparameterized3Dco-
ordinates,notmerely2Dcoordinates.Therefore,wecallthesecontours
2.5Dsnakes
.
Theinitialcontoursneededfor¯ttingthesnakesarecrucial.Fortunately,theycan
beobtainedfromourgenericfacemodel.Anotherimportantpointfor¯ttingsnakes
106
isto¯ndappropriateexternalenergymapsthatcontainlocalmaximum/minimum
attheboundariesoffacialfeatures.Forthefaceboundaryandthenose,theexternal
energyiscomputedbythemaximummagnitudeofverticalandhorizontalgradients
fromrangemaps.Thesetwofacialfeatureshavesteeperbordersthanothers.For
featuressuchaseyesandthemouth,theexternalenergyisobtainedbyaproduct
ofthemagnitudeoftheluminancegradientandthesquaredluminance.Figure4.9
(a)(b)
(c)(d)
Figure4.9.Localfeaturere¯nement:initial(inblue)andre¯ned(inred)contours
overlaidontheenergymapsfor(a)thefaceboundary;(b)thenose;(c)thelefteye;
and(d)themouth.
107
showstheresultsoflocalre¯nementforthefaceboundary,thenose,thelefteye,and
themouth.
Althoughourdisplacementpropagationsmoothesnon-featureskinregionsinthe
localadaptation,theseskinregionscanbefurtherupdatedifadenserangemapis
available.However,basedonourexperiments,we¯ndthattheupdateofnon-feature
skinregionsdoesnotmakeasigni¯cantdi®erenceexceptincheekregionsbecausethe
displacementpropagationalreadysmoothestheskinregionssurroundingeachfacial
feature.Figure4.10showstheoverlayofthe¯naladaptedfacemodelinredand
thetargetfacialmeasurementsinblue.ForacomparisonwithFig.4.4,Fig.4.11
(a)(b)
Figure4.10.Theadaptedmodel(inred)overlappingthetargetmeasurements(in
blue),plotted(a)in3D;(b)withcoloredfacetsatapro¯leview.
showsthetexture-mappedfacemodel.Thetexture-mappedmodelisvisuallysimilar
totheoriginalface.Wefurtheruseafacerecognitionalgorithm[78]todemonstrate
theuseof3Dmodel.Thetrainingdatabasecontains(i)504imagescapturedfrom
28subjectsand(ii)15imagesofonesubjectgeneratedfromour3Dfacemodel,
108
(a)(b)
(d)(e)(f)
Figure4.11.TextureMapping.(a)Thetexture-mappedinputrangeimage.The
texture-mappedadaptedmeshmodelshownfor(b)afrontalview;(d)aleftview;
(e)apro¯leview;(f)arightview.
109
whichareshowninthetoprowinFig.4.12.Allthe10testimagesofthesubject
showninthebottomrowinFig.4.12werecorrectlymatchedtoourfacemodel.This
preliminarymatchingexperimentshowsthattheproposed3Dfacemodelisquite
usefulforrecognizingfacesatnon-frontalviewsbasedonthefacialappearance.
Figure4.12.Facematching:thetoprowshowsthe15trainingimagesgenerated
fromthe3Dmodel;thebottomrowshows10testimagesofthesubjectcaptured
fromaCCDcamera.
4.5Summary
Facerepresentationplaysacrucialroleinfacerecognitionsystems.Forfacerecog-
nition,werepresentahumanfaceasa3Dfacemodelthatislearnedbyadapting
ageneric3Dfacemodeltoinputfacialmeasurementsinaglobal-to-localfashion.
Basedonthefacialmeasurements,ourmodelconstructionmethod¯rstalignsthe
genericmodelglobally,andthenalignsandre¯neseachfacialfeaturelocallyusing
displacement(ofmodelvertices)propagationandactivecontoursassociatedwithfa-
cialfeatures.The¯naltexturemappedmodelisvisuallysimilartotheoriginalface.
Initialmatchingexperimentsbasedonthe3Dfacemodelshowencouragingresults
forappearance-basedrecognition.
110
Chapter5
SemanticFaceRecognition
Inthischapter,wewilldescribesemanticfacematching(seeFig.1.6inChapter1)
basedoncolorinputimagesandageneric3Dfacemodel.Wewillgivethedetailsof(i)
thefacemodelingfromasingleview(i.e.,thefrontalview),calledfacealignment,and
(ii)recognitionmoduleinthesemanticfacematchingalgorithm.Section5.1describes
theconceptofsemanticfacialcomponents,thesemanticfacegraph,thegeneric3D
facemodel,andinteractingsnakes(multiplesnakesthatinteractwitheachother).
Section5.2describesthecoarsealignmentbetweenthesemanticgraphandtheinput
imagebasedontheresultsoffacedetection.Section5.3presentstheprocessof¯ne
alignmentofthesemanticgraphusinginteractingsnakes.Weexplainhowtocompute
thematchingscoresforgraphalignment,andthenshowtheresultantfacialsketches
andcartoonfaces.Section5.4describesasemanticfacematchingmethodforrecog-
nizingfaces,theuseofcomponentweightsbasedonalignmentscores,andthecost
functionforfaceidenti¯cation.Thenwegivethealgorithmoftheproposedsemantic
facematching.Weillustratethegeneratedcartoonfacesfromalignedsemanticface
111
graphs.Wedemonstratetheexperimentresultsonfacematchingbasedonasubset
oftheMPEG7contentset[15]andMichiganStateUniversity(MSU)facedatabase.
Section5.5describesthegenerationoffacialcaricatures,anddiscussesthee®ectsof
caricatureonfacerecognition.AsummaryisgiveninSection5.6.
5.1SemanticFaceGraphasMultipleSnakes
Asemanticfacegraphprovidesahigh-leveldescriptionofthehumanface.Aseman-
ticgraphprojectedontoafrontalviewforfacerecognitionisshowninFig.5.1.The
nodesofthegraphrepresentsemanticfacialcomponents(e.g.,eyes,mouth,andhair),
eachofwhichisconstructedfromasubsetofverticesofthe3Dgenericfacemodeland
isenclosedbyparametriccurves.Asemanticgraphisrepresentedina3Dspaceand
iscomparedwithothersuchgraphsina2Dprojectionspace.Therefore,the2Dap-
pearanceofthesemanticgraphlooksdi®erentatdi®erentviewpointsduetothee®ect
ofperspectiveprojectionofthefacialsurface.WeadoptWaters'animationmodel
[69],[176]asthegenericfacemodelbecauseitcontainsalltheinternalfacialcom-
ponents,faceoutline,andmusclemodelsformimickingfacialexpressions.However,
Waters'modeldoesnotincludesomeoftheexternalfacialfeatures,suchasearsand
hair.Thehairstyleandthefaceoutlineplayacrucialroleinfacerecognition.Hence,
wehavecreatedexternalfacialcomponentssuchastheearandthehaircontours
forthefrontalviewofWaters'model.Wehierarchicallydecomposetheverticesof
themeshmodelintothreelevels:(i)verticesattheboundariesoffacialcomponents,
(ii)verticesconstructingfacialcomponents,and(iii)verticesbelongingtofacialskin
112
(a)(b)(c)
Figure5.1.Semanticfacegraphisshowninafrontalview,whosenodesare(a)
indicatedbytext;(b)depictedbypolynomialcurves;(c)¯lledwithdi®erentshades.
Theedgesofthesemanticgraphareimplicitlystoredina3Dgenericfacemodeland
arehiddenhere.
regions.Theverticesatthetoplevelarelabelledwithfacialcomponentssuchasthe
faceoutline,eyebrows,eyes,nose,andmouth(seeFig.5.2).Let
T
0
denotethesetof
allsemanticfacialcomponents,whicharenodesofthegenericsemanticgraph,
G
0
.
Thatis
T
0
=
ff
lefteyebrow
g
,
f
righteyebrows
g
,
f
lefteye
g
,...,
f
hairboundary
gg
.Let
T
beasubsetof
T
0
,thatis
T
½
2
T
0
.Let
M
bethenumberoffacialcomponents
in
T
.Forexample,
T
canbespeci¯edas
ff
lefteye
g
;
f
righteye
gg
;
f
mouth
gg
,where
M
is3.Letthesemanticgraphprojectedona2Dimage,representedbytheset
T
,be
G
.Thecoordinatesofcomponentboundaryof
G
canberepresentedbya
pairofsequences
x
i
(
n
)and
y
i
(
n
),where
n
=0
;
1
;:::;N
i
¡
1and
i
=1
;:::;M
,for
component
i
with
N
i
vertices.The1DFouriertransform,
a
i
(
k
),ofthecomplexsignal
u
i
(
n
)=
x
i
(
n
)+
jy
i
(
n
)(where
j
=
p
¡
1)iscomputedby
a
i
(
k
)=
Ff
u
i
(
n
)
g
=
N
i
¡
1
X
n
=0
u
i
(
n
)
¢
e
¡
j
2
¼kn=N
i
;
(5.1)
113
(a)(b)(c)
Figure5.2.3Dgenericfacemodel:(a)Waters'triangular-meshmodelshowninthe
sideview;(b)modelin(a)overlaidwithfacialcurvesincludinghairandearsata
sideview;(c)modelin(b)showninthefrontalview.
forfacialcomponent
i
withacloseboundarysuchaseyesandmouth,andwithend-
vertexpaddingforthosehavingopenboundarysuchasearsandhaircomponents.
Theadvantageofusingsemanticgraphdescriptorsforfacematchingisthatthesede-
scriptorscanseamlesslyencodegeometricrelationships(scaling,rotation,translation,
andshearing)amongfacialcomponentsinacompactformatinthespatialfrequency
domain,becausetheverticesofallthefacialcomponentsarespeci¯edinthesame
coordinatesystemwiththeoriginaroundthenose(seeFig.5.2).Thereconstruction
ofsemanticfacegraphsfromsemanticgraphdescriptorsisobtainedby
~
u
i
(
n
)=
F
¡
1
f
a
i
(
k
)
g
=
L
i
¡
1
X
k
=0
a
i
(
k
)
¢
e
j
2
¼kn=N
i
;
(5.2)
where
L
i
(
<N
i
)isthenumberoffrequencycomponentsusedforthe
i
th
facecom-
ponent.Figure5.3showsthereconstructedsemanticfacegraphsatdi®erentlevels
114
ofFourierseriestruncation.Inaddition,thecoordinatesofcomponentboundary
(a)(b)(c)(d)(e)
(f)(g)(h)(i)(j)
Figure5.3.SemanticfacegraphsforthefrontalviewarereconstructedusingFourier
descriptorswithspatialfrequencycoe±cientsincreasingfrom(a)10%to(j)100%at
incrementsof10%.
of
G
canalsoberepresentedbyparametriccurves,i.e.,
c
(
s
)=(
x
(
s
)
;y
(
s
)),where
s
2
[0
;
1],forexplicitcurvedeformationorforgeneratinglevel-setfunctionsforim-
plicitcurveevolution.Therefore,thecomponentboundariesofasemanticfacegraph
areassociatedwithacollectionofactivecontours(snakes).
5.2CoarseAlignmentofSemanticFaceGraph
Ourfacerecognitionsystemcontainsfourmajormodules:facedetection,poseesti-
mation,facealignment,andfacematching.Thefacedetectionmodule¯ndslocations
offaceandfacialfeaturesinacolorimageusingthealgorithmin[175].Figures5.4(a)
to5.4(d)showinputcolorimagesandtheresultsoffacedetection.Currently,weas-
115
sumethatthefaceimageshavebeencapturedatnearfrontalviews(i.e.,allofinternal
andexternalfacialcomponentsarevisible).Thefacealignmentmodulemakesuseof
thefacedetectionresultstoalignasemanticfacegraphontotheinputimage.The
facealignmentcanbedecomposedintothecoarseandthe¯nealignmentmodules.
Inthecoarsealignment,asemanticfacegraphatanestimatedposeisalignedwith
(a)(b)(c)(d)
Figure5.4.Facedetectionresults:(a)and(c)areinputfaceimagesofsize640
£
480
fromtheMPEG7contentset;(b)and(d)aredetectedfaces,eachofwhichisdescribed
byanovalandatriangle.
afaceimagethroughthe
globalandlocal
geometrictransformation(scaling,rotation,
andtranslation),basedonthedetectedlocationsoffaceandfacialcomponents.Sec-
tion5.3willdescribeindetailthe¯nealignment,inwhichthesemanticfacegraph
is
locally
deformedto¯tthefaceimage.
Coarsealignmentinvolvesarigid3Dtransformationoftheentiresemanticgraph.
Theparametersusedinthetransformation(scaling,rotation,andtranslation)are
estimatedfromtheoutputsofthefacedetectionalgorithm.Besidestheuseofface
detectionresults,wefurtheremploytheedgesandcolorcharacteristicsoffacialcom-
ponentstolocallyre¯netherotation,translation,andscalingparametersforindivid-
ualcomponents.Thisparameterre¯nementisachievedbymaximizinga
semantic
facialscore
(SFS)throughasmallamountofperturbationsoftheparameters.The
semanticfacescoretakesintoaccountthe¯tnessofcomponentboundaryandofcom-
116
ponentcolor.Thesemanticfacialscoreoftheset
T
onafaceimage
I
(
u;v
),
SFS
T
,
isde¯nedbypriorweightsonfacialcomponentsandcomponentmatchingscoresas
follows:
SFS
T
=
P
N
¡
1
i
=0
wt
(
i
)
¢
MS
(
i
)
P
N
¡
1
i
=0
wt
(
i
)
¡
½
¢
SD
(
MS
(
i
))
;
(5.3)
where
N
isthenumberofsemanticcomponents,
wt
(
i
)and
MS
(
i
)are,respectively,
theaprioriweightandthematchingscoreofcomponent
i
,
½
isaconstantusedto
penalizethecomponentswithhighstandarddeviationsofthematchingscores,and
SD
(
x
)standsforstandarddeviationof
x
.
Thematchingscoreforthe
i
th
facialcomponentiscomputedbasedonthecoher-
enceoftheboundaryandthecoherenceofcolorcontent(representedbyacomponent
map)by
MS
(
i
)=
1
M
i
M
i
¡
1
X
j
=0
Ã
1
A
i
A
i
¡
1
X
k
=0
e
(
u
k
;v
k
)
!
¢
¯
¯
cos
(
µ
G
i
(
u
j
;v
j
)
¡
µ
(
u
j
;v
j
))
¯
¯
+
f
(
u
j
;v
j
)
2
;
(5.4)
where
M
i
and
A
i
are,respectively,thenumberofpixelsalongthecurveofcomponent
i
andthoseofpixelscoveredbythecomponent
i
,
µ
G
i
and
µ
i
arethenormaldirection
ofcomponentcurve
i
inasemanticgraph
G
andthegradientorientationoftheimage
I
,
f
istheedgemagnitudeoftheimage
I
,and
e
(
u
k
;v
k
)isthefacialcomponentmap
oftheimage
I
atpixel
k
.Thegradientsarecomputedasfollows:
117
f
(
u
j
;v
j
)=
S
X
s
=0
jr
G
¾
s
(
u
j
;v
j
)
~
Y
(
u
j
;v
j
)
j
(5.5)
µ
(
u
j
;v
j
)=
S
X
s
=0
arg(
r
G
¾
s
(
u
j
;v
j
)
~
Y
(
u
j
;v
j
))
;
(5.6)
where
Y
isthelumaofthecolorimage
I
,and
G
¾
s
istheGaussianfunctionwithzero
meanandstandarddeviation
¾
s
.Thelargeststandarddeviation
¾
S
islimitedbythe
distancebetweeneyesandeyebrowswhere
S
=4,and
r
and
~
arethegradientand
convolutionoperators.Thegradientmagnitude,gradientorientation,eyemap[175]
andcoarsealignmentresultsforthesubjectinFig.5.4(a)areshowninFig.5.5.
Theeyemapisanaverageofasymmetrymap[177]andaneyeenergymap(willbe
explainedinSection5.3.1).Furthermore,weconstructashadowmapofafaceimage
inordertolocateeyebrow,nostril,andmouthlines,basedontheaveragevalueof
luminanceintensityonafacialskinregion(i.e.,rectanglesshowninFigs.5.6(a)and
5.6(c)).Thesefeaturelines,shownasdarklinesinFigs.5.7(c),areusedtoadjust
correspondingfacialcomponentsofasemanticgraph.Fig.5.7shows¯veexamples
ofcoarsealignment.
5.3FineAlignmentofSemanticFaceGraphvia
InteractingSnakes
Finealignmentemploysactivecontourstolocallyre¯nefacialcomponentsofase-
manticfacegraphthatisdrawnfroma3Dgenericfacemodel.The2Dprojectionof
118
(a)(b)(c)
(d)(e)
Figure5.5.Boundarymapandeyecomponentmapforcoarsealignment:(a)and
(b)aregradientmagnitudeandorientation,respectively,obtainedfrommulti-scale
Gaussian-blurrededgeresponse;(c)aneyemapextractedfromafaceimageshown
inFig.5.4(c);(d)asemanticfacegraphoverlaidona3Dplotoftheeyemap;(e)
imageoverlaidwithacoarselyalignedfacegraph.
asemanticfacegraphproducesacollectionofcomponentboundaries,eachofwhich
isdescribedbyaclosed(oropen)activecontour.Thecollectionoftheseactivecon-
tours,called
interactingsnakes
,interactwitheachotherthrougharepulsionenergy
inordertoalignthegeneralfacialtopologyontothesensedfaceimagesinaniterative
fashion.Wehavestudiedtwocompetingimplementationsofactivecontoursforthe
deformationofinteractingsnakes:(i)explicit(orparametric)and(ii)implicitcontour
119
(a)(b)(c)(d)
Figure5.6.Shadowmaps:(a)and(c)arelumacomponentsoffaceimagesinFigs.
5.4(a)and5.4(c),overlaidwithrectangleswithinwhichtheaveragevaluesofskin
intensityiscalculated;(b)and(d)areshadowmapswherebrightpixelsindicatethe
regionsthataredarkerthanaverageskinintensity.
representations.Theexplicitcontourrepresentationhastheadvantageofmaintain-
ingthegeometrictopology.Theimplicitcontourrepresentationrequirestopological
constraintsontheimplicitfunction.
5.3.1InteractingSnakesandEnergyFunctional
Activecontourshavebeensuccessfullyusedtoimposehigh-levelgeometricalcon-
straintsonlow-levelfeaturesthatareextractedfromimages.Activecontoursare
iterativelydeformedbasedontheinitialcon¯gurationofthecontoursandtheenergy
functionalthatistobeminimized.Theinitialcon¯gurationofinteractingsnakesis
obtainedfromthecoarsely-alignedsemanticfacegraph,andisshowninFig.5.8(c).
Currently,thereareeightsnakesinteractingwitheachother.Thesesnakesdescribe
thehairoutline,faceoutline,eyebrows,eyes,nose,andmouthofaface;theyare
denotedas
V
(
s
)=
S
N
j
=1
f
v
i
(
s
)
g
,where
N
(=8)isthenumberofsnakes,and
v
i
(
s
)is
the
i
th
snakewiththeparameter
s
2
[0
;
1].
Theenergiesusedforminimizationincludetheinternalenergyofacontour(i.e.,
smoothnessandsti®nessenergies),andtheexternalenergy(i.e.,theinverseofedge
120
(a)(b)(c)(d)
Figure5.7.Coarsealignment:(a)inputfaceimagesofsize640
£
480fromthe
MPEG7contentset(¯rstthreerows),andofsize256
£
384fromtheMSUdatabase
(thefourthrow);(b)detectedfaces;(c)locationsofeyebrow,nostril,andmouthlines
usingshadowmaps;(d)faceimagesoverlaidwithcoarselyalignedfacegraphs.
121
(a)(b)(c)
Figure5.8.Interactingsnakes:(a)faceregionextractedfromafaceimageshown
inFig.5.4(a);(b)imagein(a)overlaidwitha(projected)semanticfacegraph;(c)
theinitialcon¯gurationofinteractingsnakesobtainedfromthesemanticfacegraph
shownin(b).
strength)extractedfromanimage.Inadditiontominimizingtheinternalenergyof
anindividualcurve,interactingsnakesminimizetheattractionenergyonboththe
contoursandenclosedregionsofindividualsnakes,andtherepulsionenergyamong
multiplesnakes.Theenergyfunctionalusedbyinteractingsnakesisdescribedin
Eq.(5.7).
E
isnake
=
N
X
i
=1
2
6
4
Z
1
0
E
internal
(
v
i
(
s
))+
E
repulsion
(
v
i
(
s
))
|
{z
}
E
prior
+
E
attraction
(
v
i
(
s
))
|
{z
}
E
observation
ds
3
5
;
(5.7)
where
i
istheindexoftheinteractingsnake.The¯rsttwoenergytermsarebasedon
thepriorknowledgeofsnake'sshapeandsnakes'con¯guration(i.e.,facialtopology)
whilethethirdenergytermisbasedonthesensedimage(i.e.,observedpixelvalues).
122
IntheBaysianframework,givenanimage
I
,minimizingtheenergyofinteracting
snakesisequivalenttomaximizingaposterioriprobability
p
(
V
j
I
)ofinteractingsnakes
V
(
s
)witha0
=
1lossfunction:
p
(
V
j
I
)=
p
(
I
j
V
)
¢
p
(
V
)
p
(
I
)
;
(5.8)
where
p
(
I
j
V
)
»
e
¡
E
obersvation
,
p
(
V
)
»
e
¡
E
prior
,
p
(
V
)isthepriorprobabilityofsnakes'
structureand
p
(
I
j
V
)istheconditionalprobabilityoftheimagepotentialofinter-
actingsnakes.Fromcalculusofvariations,weknowthatinteractingsnakeswhich
minimizetheenergyfunctioninEq.(5.7)mustsatisfythefollowingEuler-Lagrange
equation:
N
X
i
=1
2
4
®v
00
i
(
s
)
¡
¯v
(4)
i
(
s
)
|
{z
}
InternalForce
¡r
E
repulsion
(
v
i
(
s
))
|
{z
}
RepulsionForce
¡r
E
attraction
(
v
i
(
s
))
|
{z
}
AttractionForce
3
5
=0
;
(5.9)
where
®
and
¯
arecoe±cientsforadjustingthesecond-andthefourth-orderderiva-
tivesofacontour,respectively.Repulsionforce¯eldisconstructedbasedonthe
gradientsofdistancemapamongtheinteractingsnakesasfollows:
¡r
E
repulsion
(
v
i
(
s
))=
r
0
B
@
2
4
EDT
(
N
[
j
=1
;j
6
=
i
v
j
(
s
))
3
5
2
1
C
A
;
(5.10)
where
EDT
isasignedEuclideanDistanceTransform[178].Figure5.9showthe
repulsionforce¯eldsforthehairoutlineandthefaceoutline.Theuseoftherepulsion
forcecanpreventdi®erentactivecontoursfromconvergingtothesamelocationsof
123
minimumenergy.Theattractionforce¯eldconsistsoftwokindsof¯eldsinEq.
(a)(b)(c)
Figure5.9.Repulsionforce:(a)interactingsnakeswithindexnumbersmarked;(b)
therepulsionforcecomputedforthehairoutline;(c)therepulsionforcecomputed
forthefaceoutline.
(5.11):oneisobtainedfromedgestrength,calledgradientvector¯eld(GVF)[127],
andtheotherfromaregionpressure¯eld(RPF)[133].
¡r
E
image
(
v
i
(
s
))=
GVF
+
RPF
=
GVF
+
½
¢
~
N
(
v
i
(
s
))
¢
µ
1
¡
j
E
comp
i
(
v
i
(
s
))
¡
¹
j
k¾
¶
;
(5.11)
where
~
N
(
v
i
(
s
))isthenormalvectoronthe
i
th
contour
v
i
(
s
);
E
comp
i
isthecomponent
energyofthe
i
th
component;
¹
,
¾
arethemeanandthestandarddeviationofregion
energyoveraseedregionofthe
i
th
component;
k
isaconstantthatconstrainsthe
energyvariationofacomponent.TheadvantageofusingGVFforsnakedeformation
isthatitsrangeofin°uenceislargerthanthatobtainedfromgradients,andcan
attractsnakestoaconcaveshape.AGVFisconstructedfromanedgemapbyan
iterativeprocess.However,theconstructionofGVFisverysensitivetonoiseinthe
124
edgemap;henceitrequiresacleanedgemapasaninput.Therefore,wecompute
aGVFbyusingthreeedgemapsobtainedfromlumaandchromacomponentsof
acolorimage,andbychoosingastheedgepixelsthetop
p
%(=15%)ofedge
pixelpopulationoverafaceregion,asshowninFig.5.10(a).Figure5.10(b)is
theedgemapforconstructingitsGVFthatisshowninFig.5.10(c).Theregion
(a)(b)(c)
Figure5.10.Gradientvector¯eld:(a)faceregionofinterestextractedfroma640x480
image;(b)thresholdedgradientmapbasedonthepopulationofedgepixelsshown
asdarkpixels;(c)gradientvector¯eld.
pressure¯eldisavailableonlyforahomogeneousregionintheimage.However,
wecanconstructcomponentenergymapsthatrevealthecolorpropertyoffacial
componentssuchaseyeswithbright-and-darkpixelsandmouthwithredlips.Then
aregionpressure¯eldcanbecalculatedbasedonthecomponentenergymapand
onthemeanandstandarddeviationoftheenergyoverseedregions(notethatwe
knowtheapproximatelocationsofeyesandmouth).Letacolorimagehavecolor
componentsintheRGBspacedenotedas(
R;G;B
),andthoseinYCbCrspaceas
(
Y;Cb;Cr
).Aneyecomponentenergyforacolorimageiscomputedasfollows:
125
E
comp
eye
=
E
msat
+
E
csh
+
E
cdif
;
(5.12)
E
msat
=[
µ
(
R
¡
K
3
)
2
+(
G
¡
K
3
)
2
+(
B
¡
K
3
)
2
¡
(
R
+
G
+
B
¡
K
)
2
3
¶
0
:
5
]
;
(5.13)
E
csh
=[[
Cr
¡
K=
2]
2
¡
[
Cb
¡
K=
2]
2
]
;
(5.14)
E
cdif
=[[
Cr
]
¡
[
Cb
]]
;
(5.15)
where
E
msat
isthemodi¯edsaturation(thatisthedistanceintheplanebetween
apoint(
R;G;B
)and(
K=
3
;K=
3
;K=
3))where
R
+
G
+
B
=
K
,
E
csh
ischroma
shift,
E
cdif
ischromadi®erence,
K
=256isthenumberofgrayscalesforeachcolor
component,and[
x
]indicatesafunctionthatnormalizes
x
intotheinterval[0
;
1].The
eyecomponentenergiesforsubjectsinFig.5.11(a)isshowninFig.5.11(b).The
(a)(b)(c)(d)(e)
Figure5.11.Componentenergy(darkerpixelshavestrongerenergy):(a)facere-
gionofinterest;(b)eyecomponentenergy;(c)mouthcomponentenergy;(d)nose
boundaryenergy;(e)noseboundaryenergyshownasa3Dmeshsurface.
mouthcomponentenergyiscomputedas
E
comp
mouth
=[
¡
[
Cb
]
¡
[
Cr
]].Figure5.11(c)
126
showsexamplesofmouthenergies.Forthenosecomponent,itsGVFisusuallyweak,
anditisdi±culttoconstructanenergymapfornose.Hence,forthenose,weutilize
TsaiandShah'sshape-from-shading(SFS)algorithm[179]togenerateaboundary
energyforaugmentingtheGVFforthenosecomponent.Theilluminationdirection
usedintheSFSalgorithmisestimatedfromtheaveragegradient¯eldsofaface
image[180]withinafacialregion.Figures5.11(d)and5.11(e)showexamplesofnose
boundaryenergiesina2Dgrayscaleimageanda3Dmeshplot,respectively.
5.3.2ParametricActiveContours
Onceweobtaintheattractionforce,wecanmakeuseoftheimplicit¯nitedi®erential
method[77],[127]andtheiterativelyupdatedrepulsionforcetodeformthesnakes.
Thestoppingcriteriaisbasedontheiterativemovementofeachsnake.Figure5.12(a)
showstheinitialinteractingsnakes,Fig.5.12(b)showssnakedeformationwithoutthe
eyebrowsnakes,andFig.5.12(c)shows¯nelyalignedsnakes.Componentmatching
scoresinEq.(5.4)arethenupdatedbasedonthelineandregionintegralsofboundary
andcomponentenergies,respectively.Wediscussanotherapproachfordeformingthe
interactingsnakesbasedongeodesicactivecontoursandlevel-setfunctionsinSection
5.3.3.
5.3.3GeodesicActiveContours
Asimplicitcontours,geodesicsnakes[181],whichemploylevel-setsfunctions[182]
aredesignedforextractingcomplexgeometry.Weinitializealevel-setfunctionusing
127
(a)(b)(c)
Figure5.12.Finealignment:(a)snakedeformationshownevery¯veiterations;(b)
alignedsnakes(currentlysixsnakes|hairstyle,face-border,eyes,andmouth|are
interacting);(c)gradientvector¯eldoverlaidwiththealignedsnakes.
signedEuclideandistancesfrominteractingsnakeswithpositivevaluesinsidefacial
componentssuchashair,eyebrows,eyes,nose,mouth,andanadditionalneckcom-
ponent,
+
i
,where
i
isaninteger,
i
2
[1
;
8];andwithnegativevaluesoverthefacial
skinandbackgroundregions,
¡
j
,where
j
iseither1or2.Di®erentshadesare¯lled
incomponentregions,
+
i
and
¡
j
,toforma
cartoonface
,asshowninFig.5.13(c).
Becausefacialcomponentshavedi®erentregioncharacteristics,wemodi¯edChanet
al.'sapproach[130]totakemultipleregionsandedgesintoaccount.Theevolution
stepforthelevel-setsfunction,©,isdescribedasfollows:
128
@
©
@t
=
r
©
·
¹
1
µ
div
(
g
r
©
jr
©
j
)
¡
¹
2
r
¡
®g
¶
¡
X
i
j
I
¡
c
i
j
2
+
X
j
j
I
¡
c
j
j
2
#
;
(5.16)
g
=(1
¡
g
0
max(
g
0
)
)
2
;g
0
=log(1+
jr
I
j
2
)
2
(5.17)
r
=
(
1
=dtdt
6
=0
MAXDIST
dt
=0
(5.18)
where
¹
1
isaconstant,
¹
2
and
®
areconstantsintheintervalbetween0and1,
I
istheimagecolorcomponent,
c
i
and
c
j
aretheaveragecolorcomponentsoffacial
component
i
overregion
+
i
andcomponent
j
over
¡
j
,respectively,
r
isthecom-
ponentrepulsion,
dt
istheabsoluteEuclideandistancemapofthefacegraph,and
MAXDISTisthemaximumdistanceintheimage.Wefurtherpreservefacialtopology
usingtopologicalnumbersandthenarrowbandimplementationoflevel-setfunctions
[183].ThepreliminaryresultsareshowninFig.5.13withevolutiondetailsandin
Fig.5.14withouttheevolutiondetails.
Thefacialdistinctivenessofindividualscanbeseenfromthechangesamongthe
generic,the¯ne¯tted,and¯nedeformedfacetemplates,showninFigs.5.13(a),
5.13(d),and5.13(e).Comparingthetwoapproachesfordeforminginteracting
snakes,webelievethatthe¯rstapproach,parametricactivecontours,isbettersuited
tothedeformationofsemanticfacegraphs.
129
(a)(b)
(c)(d)(e)
Figure5.13.Finealignmentwithevolutionsteps:(a)afaceimage;(b)theface
in(a)overlaidwithacoarselyalignedfacegraph;(c)initialinteractingsnakeswith
di®erentshadesinfacialcomponents(cartoonface);(d)curveevolutionshownevery
¯veiterations(totally55iterations);(e)analignedcartoonface.
5.4SemanticFaceMatching
Wehavedevelopedamethodtoautomaticallyderivesemanticcomponentweightsfor
facialcomponentsbasedoncoarselyalignedand¯nelydeformedfacegraphs.These
componentweightsareusedtoemphasizesalientfacialfeaturesforrecognition(i.e.,
forcomputingamatchingcostforafacecomparisonusingsemanticfacegraphs.The
alignedfacegraphcanalsobeusedforgeneratingfacialcaricatures.
130
(a)
(b)(c)(d)(e)(f)
Figure5.14.Finealignmentusinggeodesicactivecontours:(a)agenericcartoon
faceconstructedfrominteractingsnakes;(b)to(f)for¯vedi®erentsubjects.For
eachsubject,theimageinthe¯rstrowisthecapturedfaceimage;thesecondrow
showssemanticfacegraphsobtainedaftercoarsealignment,andoverlaidonthecolor
image;thethirdrowshowssemanticfacegraphswithindividualcomponentsshown
indi®erentshadesofgray;thelastrowshowsfacegraphswithindividualcomponents
after¯nealignment.
131
5.4.1ComponentWeightsandMatchingCost
Afterthetwophasesoffacealignment,wecanautomaticallyderiveaweight(called
semanticcomponentweight
)foreachfacialcomponent
i
forasubject
P
with
N
p
trainingfaceimagesby
scw
P
(
i
)=
(
1+
e
¡
2
¾
2
d
(
i
)
=d
2
(
i
)
N
p
>
1
;
1+
e
¡
1
=d
2
(
i
)
N
p
=1
;
(5.19)
d
(
i
)=
1
N
P
N
P
X
k
=1
SFD
i
(
G
0
;
G
P
k
)
¢
MS
P
k
(
i
)
;
(5.20)
¾
d
(
i
)=
SD
k
£
SFD
i
(
G
0
;
G
P
k
)
¢
MS
P
k
(
i
)
¤
;
(5.21)
where
SFD
meanssemanticfacialdistance,
MS
isthematchingscore,
SD
stands
forstandarddeviation,
G
0
and
G
P
k
arethecoarselyalignedand¯nelydeformed
semanticfacegraphs,respectively.Thesemanticcomponentweightstakevalues
between1and2.Thesemanticfacialdistanceoffacialcomponent
i
betweentwo
graphsisde¯nedasfollows
SFD
i
(
G
0
;
G
P
k
)=
Dist
(
SGD
G
0
i
;SGD
G
P
k
i
)
=
"
1
L
i
L
i
X
k
=0
¯
¯
¯
a
G
0
i
(
k
)
¡
a
G
P
k
i
(
k
)
¯
¯
¯
2
#
0
:
5
;
(5.22)
where
SGD
standsforsemanticgraphdescriptors.Thedistinctivenessofafacial
componentisevaluatedbythesemanticfacialdistance
SFD
betweenthegeneric
semanticfacegraphandthealigned/matchedsemanticgraph.Thevisibilityofa
facialcomponent(duetoheadpose,illumination,andfacialshadow)isestimated
132
bythereliabilityofcomponentmatching/alignment(i.e.,matchingscoresforfacial
components).Finally,the2Dsemanticfacegraphofsubject
P
canbelearnedfrom
N
p
imagesundersimilarposeby
G
P
=
[
i
F
¡
1
(
1
N
P
N
P
X
k
=1
SGD
G
P
k
i
)
:
(5.23)
Thematchingcostbetweenthesubject
P
andthe
k
-thfaceimageofsubject
Q
can
becalculatedas
C
(
P;Q
k
)=
M
X
i
=1
½
scw
P
(
i
)
¢
scw
Q
k
(
i
)
¢
SFD
i
(
G
P
;
G
Q
k
)
¾
;
(5.24)
where
M
isthenumberoffacialcomponents.Facematchingisaccomplishedby
minimizingthematchingcost.
5.4.2FaceMatchingAlgorithm
Thesystemdiagramofourproposedsemanticfacerecognitionmethodwasillustrated
inFig.1.6(inChapter1).Figure5.15describesthesemanticfacematchingalgo-
rithmforidentifyingfaceswithnorejection.Theinputsofthealgorithmaretraining
imagesof
M
knownsubjectsintheenrollmentphaseandonequeryfaceimageofan
unknownsubjectintherecognitionphase.Thequeryinputcanbeeasilygeneralized
toeithermultipleimagesofanunknownsubjectormultipleimagesofmultipleun-
knownsubjects.Eachknownsubject,
P
j
,canhave
N
j
(
¸
1)trainingimages.The
outputofthealgorithmistheidentityoftheunknownqueryfaceimage(s)among
M
knownsubjects(arejectionoptioncanbeincludedbyprovidingathresholdonthe
133
matchingcostinthealgorithm).Thealgorithmusesourfacedetectionmethodto
locatefacesandfacialfeaturesinalltheimages,andthecoarseand¯nealignment
methodstoextractsemanticfacialfeaturesforfacematching.Finally,itcomputesa
matchingcostforeachcomparisonbasedonselectedfacialcomponents,thederived
componentweights(distinctiveness),andmatchingscore(visibility).
Figure5.15.Asemanticfacematchingalgorithm.
INPUT:-
N
j
trainingfaceimagesforthesubject
P
j
,
j
=1
;:::;M
-onequeryfaceimageforunknownsubject
Q
Step1:Detectfacesforalltheimagesusingthemethodin[175]
¡!
Generatelocationsoffaceandfacialfeatures
Step2:Formasetoffacialcomponents,
T
,forrecognitionbyassigningprior
componentweights
Step3:Coarselyalignagenericsemanticfacegraphtoeachimagebasedon
T
¡!
ObtaincomponentmatchingscoresforeachgraphinEq.(5.4)
Step4:Deformacoarsely-alignedfacegraph
¡!
Updatecomponentmatchingscoresbasedonintegralsof
componentenergies
Step5:Computesemanticfacialdescriptors
SGD
foreachgraph
usingthe1-DFouriertransforminEq.(5.1).
Step6:ComputesemanticcomponentweightsforeachgraphinEqs.(5.19)-(5.21)
Step7:Integrateallthefacegraphsofsubject
P
j
inEq.(5.23),
resultinginMtemplatefacegraphs
Step8:ComputeMmatchingcosts,
C
(
P
j
;Q
k
),between
P
j
and
Q
k
inEq.(5.24),
where
k
=1,
j
=1
;:::;M
Step9:Subject
P
J
withtheminimummatchingcosthasthebestmatchedface
totheunknownsubject
Q
k
.
OUTPUT:
Q
=
P
J
5.4.3FaceMatching
Wehaveconstructedasmallfacedatabaseoftensubjects(tenimagespersubject)
atnearfrontalviewswithsmallamountsofvariationsinfacialexpression,faceorien-
134
tation,facesize,andlightingconditions,duringdi®erentimagecapturesessionsover
aperiodoftwomonths.Figure5.16shows¯veimagesofonesubject,whileFig.5.17
showsoneimageeachoftensubjects.
Figure5.16.Fivecolorimages(256
£
384)ofasubject.
(a)(b)(c)(d)(e)
(f)(g)(h)(i)(j)
Figure5.17.Faceimagesoftensubjects.
Weemploy5imageseachfor10subjectsfortrainingthesemanticfacegraphs.
Withre-substitutionandleave-one-outtests,themisclassi¯cationratesareshownin
Table5.1usingdi®erentsetsoffacialcomponentsandsemanticgraphdescriptors
withthenumberoffrequencycomponentstruncatedatthreelevels.Externalfacial
135
Table5.1
Errorratesona50-imagedatabase.
ComponentSet
T
1
T
2
T
3
T
4
FaceGraph
P(%)
RS
LOO
RS
LOO
RS
LOO
RS
LOO
100%
0%
6%
0%
6%
12%
24%
16%
30%
50%
0%
6%
0%
6%
12%
24%
16%
30%
30%
0%
6%
0%
12%
16%
24%
18%
34%
P:%offrequencycomponents,
T
1
:Allcomponents,
T
2
:Externalcomponents,
T
3
:
Internalcomponents,
T
4
:EyesandEyebrows,RS:Re-substitution,LOO:Leave-one-
out.
Table5.2
Dimensionsofthesemanticgraphdescriptorsforindividualfacial
components.
P(%)
100%
50%
30%
Dimension
N
i
L
i
L
i
Eyebrow
12
5
3
Eye
13
7
3
Nose
34
13
7
mouth
14
7
3
Faceoutline
36
17
11
Ear
11
5
3
Hair
19
9
5
P:%offrequencycomponents,
N
i
:thedimensionofsemanticgraphdescriptors,
L
i
:
thedimensionoftruncateddescriptors.
136
(a)(b)(c)(d)
Figure5.18.Examplesofmisclassi¯cation:(a)inputtestimage;(b)semanticface
graphoftheimagein(a);(c)facegraphofthemisclassi¯edsubject;(d)facegraphof
thegenuinesubjectobtainedfromtheotherimagesofthesubjectinthedatabase(i.e.,
withouttheinputtestimagein(a)).Eachrowshowsoneexampleofmisclassi¯cation.
componentsincludefaceoutline,ears,andhairstyle,whileinternalcomponentsare
eyebrows,eyes,nose,andmouth.Wecanseethattheexternalfacialcomponents
playanimportantroleinrecognition,andtheFourierdescriptorsprovidecompact
featuresforclassi¯cationbecausethedimensionalityofourfeaturespaceislower(see
Table5.2)comparedtothoseusedineigen-subspacemethods.Figure5.18showsthe
threeexamplesofmisclassi¯cationinaleave-one-outtestforthefacialcomponent
set
T
1
usingallthefrequencycomponents.Thefalsematchingmayresultfromthe
137
similarcon¯gurationoffacialcomponents,thebiasedaveragefacialtopologyofthe
genericfacemodel,andcoarseheadpose.Figures5.19,5.20,and5.21showthe
reconstructedsemanticfacegraphs,
G
P
inEq.(5.23),(comparethemwith
G
0
in
Fig.5.1(c))atthreelevelsofdetails,respectively.Eachcoarsealignmentand¯ne
(a)(b)(c)(d)(e)
(f)(g)(h)(i)(j)
Figure5.19.CartoonfacesreconstructedfromFourierdescriptorsusingallthefre-
quencycomponents:(a)to(j)aretenaveragecartoonfacesfortendi®erentsubjects
basedon¯veimagesforeachsubject.Individualcomponentsareshownindi®erent
shadesin(a)to(e).
alignmentonanimageofsize640
£
480takes10secwithCimplementationand
460sec.withMATLABimplementation,repsectively,whileeachfacecomparison
takes0
:
0029secwithMatlabimplementationona1.7GHzCPU.Weareconducting
othercross-validationtestsforclassi¯cation,andareintheprocessofperforming
recognitionongallery(containingknownsubjects)andprobe(containingunknown
subject)databases.Althoughthealignmentiso®-linecurrently,thereislargeroom
toenhancetheperformanceofalignmentimplementationtomakeitoperateinreal-
138
(a)(b)(c)(d)(e)
(f)(g)(h)(i)(j)
Figure5.20.CartoonfacesreconstructedfromFourierdescriptorsusingonly50%of
thefrequencycomponents:(a)to(j)aretenaveragecartoonfacesfortendi®erent
subjectsbasedon¯veimagesforeachsubject.Individualcomponentsareshownin
di®erentshadesin(a)to(e).
(a)(b)(c)(d)(e)
(f)(g)(h)(i)(j)
Figure5.21.CartoonfacesreconstructedfromFourierdescriptorsusingonly30%of
thefrequencycomponents:(a)to(j)aretenaveragecartoonfacesfortendi®erent
subjectsbasedon¯veimagesforeachsubject.Individualcomponentsareshownin
di®erentshadesin(a)to(e).
139
time.
5.5FacialCaricaturesforRecognitionandVisual-
ization
Facialcaricaturesaregeneratedbasedonexaggerationofanindividual'sfacialdis-
tinctivenessfromtheaveragefacialtopology.Let
G
crc
P
representthefacegraphsof
caricaturesforthesubject
P
,and
G
0
bethefacegraphoftheaveragefacialtopology.
Caricaturesaregeneratedviathespeci¯cationofanexaggerationcoe±cient,
k
i
,in
Eq.(5.25):
G
crc
P
=
[
i
F
¡
1
n
SGD
G
P
i
+
k
i
¢
³
SGD
G
P
i
¡
SGD
G
0
i
´o
:
(5.25)
Currently,weusethesamevalueofthecoe±cientforallthecomponents,i.e.,
k
i
=
k
.
Figure5.22showsfacialcaricaturesgeneratedwithrespecttotheaveragefacialtopol-
ogyobtainedfromthe3Dgenericfacemodel.InFig.5.23,facialcaricaturesareop-
timizedinthesensethattheaveragefacialtopologyisobtainedfromthemeanfacial
topologyoftrainingimages(totalof50imagesfortensubjects).Wecanseethatitis
easier
forahumantorecognizeaknownfacebasedontheexaggeratedfaces.Weplan
toquantitativelyevaluatethee®ectofexaggerationofsalientfacialfeaturesonthe
performanceofafacerecognitionsystem.Furthermore,thisframeworkofcaricature
generationcanbeeasilyemployedasanalternativetomethodsofvisualizinghigh
dimensionaldata,e.g.,Cherno®faces[184].
140
(a)
(b)(c)(d)(e)(f)(g)
Figure5.22.Facialcaricaturesgeneratedbasedonageneric3Dfacemodel:(a)a
prototypeofthesemanticfacegraph,
G
0
,obtainedfromageneric3Dfacemodel,
withindividualcomponentsshaded;(b)faceimagesofsixdi®erentsubjects;(c)-(g)
caricaturesoffacesin(b)(semanticfacegraphswithindividualcomponentsshown
indi®erentshades)withdi®erentvaluesofexaggerationcoe±cients,
k
,rangingfrom
0
:
1to0
:
9.
141
(a)
(b)(c)(d)(e)(f)(g)
Figure5.23.Facialcaricaturesgeneratedbasedontheaveragefaceof50faces(5
foreachsubject):(a)aprototypeofthesemanticfacegraph,
G
0
,obtainedfromthe
meanfaceofthedatabase,withindividualcomponentsshaded;(b)faceimagesof
sixdi®erentsubjects;(c)-(g)caricaturesoffacesin(b)(semanticfacegraphswith
individualcomponentsshownindi®erentshades)withdi®erentvaluesofexaggeration
coe±cients,
k
,rangingfrom0
:
1to0
:
9.
142
5.6Summary
Forovercomingvariationsinpose,illumination,andexpression,weproposesemantic
facegraphsthatareextractedfromasubsetofverticesofa3Dfacemodel,andaligned
toanimageforfacerecognition.Wehavepresentedaframeworkforsemanticface
recognition,whichisdesignedtoautomaticallyderiveweightsforfacialcomponents
basedontheirdistinctivenessandvisibility,andtoperformfacematchingbasedon
visiblefacialcomponents.Facealignmentisacrucialmoduleforfacematching,
andweimplementitinacoarse-to-¯nefashion.Wehaveshownexamplesofcoarse
alignment,andhaveinvestigatedtwodeformationapproachesfor¯nealignmentof
semanticfacegraphsusinginteractingsnakes.Experimentalresultsshowthata
successfulinteractionamongmultiplesnakesassociatedwithfacialcomponentsmakes
thesemanticfacegraphausefulmodeltorepresentfaces(e.g.,cartoonfacesand
caricatures)forrecognition.
Ourautomaticschemeforaligningfacesusesinteractingsnakesforvariousfacial
components,includingthehairoutline,faceoutline,eyes,nose,andmouth.We
arecurrentlyaddingsnakesforeyebrowstocompletelyautomatethewholeprocess
offacealignment.Weplantotesttheproposedsemanticfacematchingalgorithm
onstandardfacedatabases.Wealsoplantoimplementaposeestimationmodule
basedonthealignmentresultsinordertoconstructanautomatedpose-invariantface
recognitionsystem.
143
Chapter6
ConclusionsandFutureDirections
Wewillgiveconclusionsanddescribefutureresearchdirectionsinthefollowingtwo
sections,respectively.
6.1Conclusions
Facedetectionaswellasrecognitionarechallengingproblemsandthereisstillalotof
workthatneedstobedoneinthisarea.Overthepasttenyears,facerecognitionhas
receivedsubstantialattentionfromresearchersinbiometrics,patternrecognition,
computervision,andcognitivepsychologycommunities.Thiscommoninterestin
facialrecognitiontechnologyamongresearchersworkingindiverse¯eldsismotivated
bothbyourremarkableabilitytorecognizepeopleandbytheincreasedattention
beingdevotedtosecurityapplications.Applicationsoffacerecognitioncanbefound
insecurity,tracking,multimedia,andentertainmentdomains.Wehaveproposedtwo
paradigmstoadvancefacerecognitiontechnology.Threemajortasksinvolvedin
144
suchvision-basedsystemsare(i)detectionofhumanfaces,(ii)constructionofface
models/representationsforrecognition,and(iii)identi¯cationofhumanfaces.
Detectionofhumanfacesisthe¯rststepinourproposedsystem.Itisalsothe
initialstepinotherapplicationssuchasvideosurveillance,designofhumancomputer
interface,facerecognition,andfacedatabasemanagement.Wehaveproposedaface
detectionalgorithmforcolorimagesinthepresenceofvariouslightingconditions
aswellascomplexbackgrounds.Ourdetectionmethod¯rstcorrectsthecolorbias
byalightingcompensationtechniquethatautomaticallyestimatesthestatisticsof
referencewhiteforcolorcorrection.Weovercamethedi±cultyofdetectingthelow-
lumaandhigh-lumaskintonesbyapplyinganonlineartransformationtothe
YCbCr
colorspace.Ourmethoddetectsskinregionsovertheentireimage,andthengenerates
facecandidatesbasedonthespatialarrangementoftheseskinpatches.Next,the
algorithmconstructseye,mouth,andfaceboundarymapsforverifyingeachface
candidate.Experimentalresultshavedemonstratedsuccessfuldetectionofmultiple
facesofdi®erentsize,color,position,scale,orientation,3Dpose,andexpressionin
severalphotocollections.
Constructionoffacemodelsiscloselycoupledwithrecognitionofhumanfaces,
becausethechoiceofinternalrepresentationsofhumanfacesgreatlya®ectsthedesign
ofthefacematchingorclassi¯cationalgorithm.3Dfacemodelscanhelpaugmenting
thetrainingfacedatabasesusedbytheappearance-basedfacerecognitionapproaches
toallowforrecognitionunderilluminationandheadposevariations.Forrecognition,
Wehavedesignedtwomethodsformodelinghumanfacesbasedonageneric3Dface
model.Onerequiresindividualfacialmeasurementsofshapeandtexture(i.e.,color
145
imageswithregisteredrangedata)capturedinthefrontalview;theothertakesonly
colorimagesasitsfacialmeasurements.Bothmodelingmethodsadaptfacialfeatures
ofagenericmodeltothoseextractedfromanindividual'sfacialmeasurementsina
global-to-localfashion.The¯rstmethodalignsthemodelglobally,usesthe2.5D
activecontourstore¯nefeatureboundaries,andpropagatesdisplacementsofmodel
verticesiterativelytosmoothnon-featureareas.Theresultingfacemodelisvisually
similartothetrueface.Theresulting3Dmodelhasbeenshowntobequiteusefulfor
recognizingnon-frontalviewsbasedonanappearance-basedrecognitionalgorithm.
Thesecondmodelingmethodalignssemanticfacialcomponents,e.g.,eyes,mouth,
nose,andthefaceoutline,ofthegenericsemanticfacegraphontothoseinacolorface
image.Thenodesofasemanticfacegraph,derivedfromageneric3Dfacemodel,
representhigh-levelfacialcomponents,andareconnectedbytriangularmeshes.The
semanticfacegraphis¯rstcoarselyalignedtothelocationsofdetectedfaceandfacial
components,andthen¯nelyadaptedtothefaceimageusinginteractingsnakes,
eachofwhichdescribesasemanticcomponent.Asuccessfulinteractionofthese
multiplesnakesresultsinappropriatecomponentweightsbasedondistinctiveness
andvisibilityofindividualcomponents.Alignedfacialcomponentsaretransformed
toafeaturespacespannedbyFourierdescriptorsforsemanticfacematching.The
semanticfacegraphallowsfacematchingbasedonselectedfacialcomponents,and
updatingofa3Dfacemodelbasedon2Dimages.Theresultsoffacematching
demonstratetheclassi¯cationandvisualization(e.g.,thegenerationofcartoonfaces
andfacialcaricatures)ofhumanfacesusingthederivedsemanticfacegraphs.
146
6.2FutureDirections
Basedonthetworecognitionparadigmsproposedandimplementedinthisthesis,
wecanextendourworkonfacedetection,modelingandrecognitioninthefollowing
manner:
6.2.1FaceDetection&Tracking
Thefacedetectionmodulecanbefurtherimprovedby
²
Optimizingtheimplementationforreal-timeapplications;
²
Combiningtheglobal(appearance-based)approachandamodi¯edversionof
ouranalytic(feature-based)approachfordetectingfacesinpro¯leviews,in
blurredimages,andinimagescapturedatalongdistance;
²
Fusingahead(orbody)detectoringrayscaleimagesandourskin¯lterincolor
imagesforlocatingnon-skin-tonefaces(e.g.,facesingray-scaleimagesorfaces
takenunderextremelightingconditions).
Inordertomakethefacedetectionmoduleusefulforfacetracking,weneedtoinclude
motiondetectionandpredictionsubmodulesasfollows.
²
Parametricfacedescriptors
:Faceellipsesandeye-mouthtrianglesareuseful
measurementsthatcanbeusedforthemotionpredictionofhumanfaces.We
arecurrentlydevelopingatrackingsystemthatcombinestemporalandshape
(derivedfromourfacedetectionmethod)information.
147
²
Afacetrackingandrecognitionprototype
:Aprototypeofarecognition
systemwithtrackingmodulesisshowninFig.6.1.Thedetectionandtracking
Figure6.1.Aprototypeofafaceidenti¯cationsystemwiththetrackingfunction.
modulesinclude(i)amotion¯lteriftemporalinformationisavailable,(ii)a
humanbodydetectorandanalysisofhumangait,and(iii)amotionpredictor
offaceandthehumanbody.
²
Preliminarytrackingresults
:Anexampleofdetectionofmotionandskin
colorisshowninFigure6.2(see[185]formoredetails).Thepreliminaryresults
ofo®-linefacetrackingbasedonthedetectionofinterframedi®erence,skin
color,andfacialfeaturesareshowninFig.6.3,whichcontainsasequence
of25videoframes.Theseimagesarelighting-compensatedandoverlaidwith
detectedfaces.TheimagesequenceshowstwosubjectsenteringthePRIPLab
148
(a)(b)(c)(d)
Figure6.2.Anexampleofmotiondetectioninavideoframe:(a)Acolorvideoframe;
(b)extractedregionswithsigni¯cantmotion;(c)detectedmovingskinpatchesshown
inpseudocolor;(d)extractedfacecandidatesdescribedbyrectangles.
intheEngineeringbuildingatMichiganStateUniversitythroughtwodi®erent
doors.Facesofdi®erentsizesandposesaresuccessfullytrackedundervarious
lightingconditions.
6.2.2FaceModeling
Wehavedevelopedtwofacemodelingmethodsforrange(withregisteredcolor)data
andforcolordatainafrontalview.Onceweconstructaposeestimator,wecan
modifytheproposedmethodsoffacealignmentfornon-frontalviews.Thisextension
ofmodelingincludesthefollowingtasks:
²
Completeheadandearmeshmodels
:Weneedmodelpolygonsfor
hair/headportionandearsinordertogeneratehairandearoutlinesinnon-
frontalviews.
²
Poseandilluminationestimation
:Wecandesignaheadposeestimator
andanilluminationestimatorforfacesinfrontalandnon-frontalviewsbased
onthelocationsoffaceandfacialcomponents,andshadows/shadingsonthe
face.
149
Figure6.3.Facetrackingresultsonasequenceof25videoframes.Theseimagesarearrangedfromtoptobottomandfrom
lefttoright.Detectedfacesareoverlaidonthelighting-compensatedimages.
150
²
Non-frontaltrainingviews
:Accordingtotheestimatedheadpose,wecan
rotatethegenericfacemodelandgeneratetheboundarycurvesofthesemantic
componentsforfacealignmentattheestimatedpose.
6.2.3Facematching
Wehavedesignedasemanticfacematchingalgorithmbasedonthecomponent
weightsderivedfromdistinctivenessandvisibilityofindividualfacialcomponents.
Currently,thesemanticgraphdescriptors,
SGD
i
inSection5.4.1,usedforcompar-
ingthedi®erencebetweenfacialcomponentscontainonlytheshapeinformation(i.e.,
componentcontours).Wecanimprovetheperformanceofthealgorithmbyincluding
thefollowingproperties:
²
Textureinformation
:Associateasemanticgraphdescriptorwithasetof
textureinformation(e.g.,waveletcoe±cients,photometricsketches[55],and
normalizedcolorvalues)foreachfacialcomponent.Thesemanticfacematching
algorithmwillcomparefacesbasedonboththeshapeandtextureinformation.
²
Scalability
:Evaluatethematchingalgorithmonseveralpublicdomainface
databases.
²
Caricaturee®ectsonrecognition
:Exploreotherweightingfunctionsonthe
distinctivenessofindividualfacialcomponentsbasedonthevisualizedfacial
caricatureandtherecognitionperformance.
²
Facialstatistics
:Analyzefaceshape,race,sex,andage,andconstructother
151
semanticparametersforfacerecognition,basedonalargefacedatabase.
152
Appendices
AppendixA
TransformationofColorSpace
Inthisappendix,wewillgivethedetailedformulaeoftwotypesofcolorspacetrans-
formationsandanellipticalskinsclassi¯er,whichareusedinourfacedetection
algorithm.Thetransformationsincludealineartransformationbetween
RGB
and
YCbCr
colorspacesandanonlineartransformationappliedto
YCbCr
forcompen-
satingthelumadependency.Theskinclassi¯erisdescribedbyanellipticalregion,
whichliesinthenonlinearlytransformed
YCbCr
space.
A.1LinearTransformation
Ourfacedetectionalgorithmutilizesalineartransformationtoconvertthecolor
componentsofaninputimageinthe
RGB
spaceintothoseinthe
YCbCr
spacefor
separatingthelumacomponentfromchromacomponentsoftheinputimage.The
transformationbetweenthesetwospaceisformulatedinEqs.(A.1)and(A.2)forthe
valueofcolorcomponentsthatrangefrom0to255(seethedetailsin[155]).
153
2
4
Y
Cb
Cr
3
5
=
1
256
2
4
65129
:
05725
:
064
¡
37
:
945
¡
74
:
494112
:
439
112
:
439
¡
94
:
154
¡
18
:
285
3
5
2
4
R
G
B
3
5
+
2
4
16
128
128
3
5
(A.1)
2
4
R
G
B
3
5
=
1
256
2
4
298
:
0820408
:
583
298
:
082
¡
100
:
291
¡
208
:
120
298
:
082516
:
4110
3
5
2
4
Y
Cb
Cr
3
5
(A.2)
FiguresA.1(a)and(b)illustrateasetofrandomlysampledreproduciblecolorsin
the
RGB
spaceanditscorrespondingsetinthe
YCbCr
space.
(a)(b)
FigureA.1.Colorspaces:(a)
RGB
;(b)
YCbCr
.
A.2NonlinearTransformation
Inthe
YC
b
C
r
colorspace,wecanregardthechroma(
C
b
and
C
r
)asfunctionsofthe
luma(
Y
):
C
b
(
Y
)and
C
r
(
Y
).Letthetransformedchromabe
C
0
b
(
Y
)and
C
0
r
(
Y
).The
nonlineartransformationconvertstheelongatedclusterintoacylinder-likeshape,
154
basedontheskinclustermodelobtainedfromasubsetoftheHHIdatabase.The
modelisspeci¯edbythecenters(denotedas
C
b
(
Y
)and
C
r
(
Y
))andwidthsofthe
cluster(denotedas
Wc
b
(
Y
)and
Wc
r
(
Y
))(SeeFig.3.5).Thefollowingequations
describehowthistransformationiscomputed.
C
0
i
(
Y
)=
8
>
>
<
>
>
:
¡
C
i
(
Y
)
¡
C
i
(
Y
)
¢
¢
Wc
i
Wc
i
(
Y
)
+
C
i
(
K
h
)if
Y<K
l
or
K
h
<Y;
C
i
(
Y
)if
Y
2
[
K
l
;K
h
]
;
(A.3)
Wc
i
(
Y
)=
8
>
>
<
>
>
:
WLc
i
+
(
Y
¡
Y
min
)
¢
(
Wc
i
¡
WLc
i
)
K
l
¡
Y
min
if
Y<K
l
;
WHc
i
+
(
Y
max
¡
Y
)
¢
(
Wc
i
¡
WHc
i
)
Y
max
¡
K
h
if
K
h
<Y;
(A.4)
C
b
(
Y
)=
8
>
>
<
>
>
:
108+
(
K
l
¡
Y
)
¢
(118
¡
108)
K
l
¡
Y
min
if
Y<K
l
;
108+
(
Y
¡
K
h
)
¢
(118
¡
108)
Y
max
¡
K
h
if
K
h
<Y;
(A.5)
C
r
(
Y
)=
8
>
>
<
>
>
:
154
¡
(
K
l
¡
Y
)
¢
(154
¡
144)
K
l
¡
Y
min
if
Y<K
l
;
154+
(
Y
¡
K
h
)
¢
(154
¡
132)
Y
max
¡
K
h
if
K
h
<Y;
(A.6)
where
C
i
inEqs.(A.3)and(A.4)iseither
C
b
or
C
r
,
Wc
b
=46
:
97,
WLc
b
=23,
WHc
b
=14,
Wc
r
=38
:
76,
WLc
r
=20,
WHc
r
=10,
K
1
=125,and
K
h
=188.All
valuesareestimatedfromtrainingsamplesofskinpatchesonasubsetoftheHHI
images.
Y
min
and
Y
max
inthe
YC
b
C
r
colorspaceare16and235,respectively.Note
thattheboundariesoftheclusteraredescribedbytwocurves
C
i
(
Y
)
§
Wc
i
(
Y
)
=
2,
155
andareshownasblue-dashedlinesinFig.3.5(a)for
C
b
andinFig.3.5(b)for
C
r
.
A.3SkinClassi¯er
Theellipticalmodelfortheskintonesinthetransformed
C
0
b
-
C
0
r
spaceisdescribedin
Eqs.(A.7)and(A.8),andisdepictedinFig.3.6.
(
x
¡
ecx
)
2
a
2
+
(
y
¡
ecy
)
2
b
2
=1
;
(A.7)
2
6
6
4
x
y
3
7
7
5
=
2
6
6
4
cos
µ
sin
µ
¡
sin
µ
cos
µ
3
7
7
5
2
6
6
4
C
0
b
¡
cx
C
0
r
¡
cy
3
7
7
5
;
(A.8)
where
cx
=109
:
38,
cy
=152
:
02,
µ
=2
:
53(inradian),
ecx
=1
:
60,
exy
=2
:
41,
a
=25
:
39,and
b
=14
:
03.Thesevaluesarecomputedfromtheskinclusterinthe
C
0
b
-
C
0
r
spaceat1%ofoutliers.
156
AppendixB
DistancebetweenSkinPatches
Facialskinareasareusuallysegmented/splitintoseveralclustersofskinpatchesdue
tothepresenceoffacialhair,glasses,andshadows.Animportantissuehereishow
togroup/mergetheseskinregionsbasedonthespatialdistancebetweenthem.Since
theclustershaveirregularshapes,boththeBhattacharryadistanceforageneralized
Gaussiandistributionandthedistancebasedonthecircularapproximationofthe
clusterareasdonotresultinasatisfactorymerging.Hence,wecombinethreetypes
ofclusterradii(circular,projection,andelliptical)inordertocomputean
e®ective
157
radius
ofacluster`
i
'w.r.t.anothercluster`
j
'asfollows.
R
i
=max(
R
p
i
;R
e
i
)+
k
¢
R
c
i
;
(B.1)
R
p
i
=
a
i
j
cos
(
µ
ij
)
j
;
(B.2)
R
e
i
=
µ
1
cos
2
(
µ
ij
)
=a
2
i
+
sin
2
(
µ
ij
)
=b
2
i
¶
1
=
2
;
(B.3)
R
c
i
=(
N
i
=¼
)
1
=
2
;
(B.4)
where
R
i
isthee®ectiveradiusofthecluster
i
;
R
p
i
isitsprojectionradius;
R
e
i
is
itsellipticalradius;
R
c
i
isthecircularradiususedin[84];theconstant
k
(equals
0
:
1)isusedtopreventthee®ectiveradiusfromvanishingwhentwoclustersarethin
andparallel;
a
i
and
b
i
arethelengthsofthemajorandminoraxesofthecluster
i
,
respectively;
µ
ij
istheanglebetweenthemajoraxisofthecluster
i
andthesegment
connectingthecentroidsofclusters
i
and
j
;and
N
i
istheareaofthecluster
i
.The
majorandminoraxesofthecluster
i
areestimatedbytheeigen-decompositionof
thecovariancematrix
C
=
2
4
¾
2
x
¾
xy
¾
xy
¾
2
y
3
5
;
(B.5)
where
¾
x
,
¾
y
,and
¾
xy
arethesecond-ordercentralmomentsoftheskincluster
i
.The
eigenvaluesofthecovariancematrix
C
andthelengthsofthemajorandminoraxes
158
oftheclusterarecomputedbyEqs.(B.6)-(B.10).
a
i
=
p
¸
1
(B.6)
b
i
=
p
¸
2
(B.7)
¸
1
=
1
2
¢
µ
¾
2
x
+
¾
2
y
+
q
¡
¾
2
x
¡
¾
2
y
¢
2
+4
¾
2
xy
¶
;
(B.8)
¸
2
=
1
2
¢
µ
¾
2
x
+
¾
2
y
¡
q
¡
¾
2
x
¡
¾
2
y
¢
2
+4
¾
2
xy
¶
;
(B.9)
®
=tan
¡
1
µ
¸
1
¡
¾
2
x
¾
xy
¶
;
(B.10)
where
a
i
and
b
i
aretheestimatedlengthsofthemajorandminoraxesofthecluster,
respectively;
¸
1
and
¸
2
arethelargestandsmallesteigenvaluesofthecovariance
matrix
C
,respectively;and
®
istheorientationofthemajoraxisofthecluster
i
.
Theorientation
®
isusedtocalculatetheangle
µ
ij
inEq.(B.2).Therefore,the
distancebetweenclusters
i
and
j
iscomputedas
d
ij
=
d
¡
R
i
¡
R
j
,where
d
isthe
Euclideandistancebetweenthecentroidsofthesetwoclusters.
159
AppendixC
ImageProcessingTemplate
Library(IPTL)
Thefacedetectionalgorithmhasbeenimplementedusing
our
ImageProcessing
TemplateLibrary(IPTL).Thislibrarybringstheabstractdataclass,
Image
,from
aclassleveltoacontainer(aclasstemplate)level,
ImageTemplate
.Ithasthe
advantagesofeasyconversionbetweenimagesofdi®erentpixeltypes,ahighreuse
rateofimageprocessingalgorithms,andabetteruserinterfaceformanipulatingdata
intheimageclasslevel.
C.1ImageandImageTemplate
Animage
capturesascene.Itisrepresentedbyatwo-dimensionalarrayofpicture
elements(socalledpixels)inthedigitalformat.Pixelscanbeofdi®erentdatatypes,
e.g.,onebitforbinaryimages,onebyteorwordforgrayscaleimages,threebytes
160
fortrue-colorimages,etc.Animageisaconcreteobject;however,
Image
canbe
regardedasanabstractdataclass/typeinthe¯eldofimageprocessing(IP)and
computervision(CV).ContemporaryIPlibraries,includingtheIntelIPL[186],the
IntelOpenCV[187],andtheCVIPTool[188],havedesigned
Image
classesusing
di®erentpixeldepthsinbits.OurImageProcessingTemplateLibrarybooststhis
abstract
Image
classfromaclassleveltoaclasstemplatelevel.Theimagetemplate,
ImageT
,isdesignedbasedonvariouspixelclasses.Forexample,pixelclassessuch
as
one-bitBoolean
,
one-bytegrayscale
,
two-bytegrayscale
,and
three-bytetruecolor
aretheargumentsoftheimageclasstemplate.Hence,theconversionbetweenimages
ofdi®erentpixelclassesisperformedatthepixellevel,notattheclasslevel.Hence,
alargenumberofalgorithmscanbereusedforimagesbelongingtodi®erentpixel
classes.
FigureC.1showsthearchitectureofIPTLclasstemplates.Thesoftwarearchitec-
turecanbedecomposedinto¯vemajorlevels:
platform
,
base
,
pixel
,
image/volume
,
and
movie/space
levels.Attheplatformlevel,declarationsandconstantsfordi®erent
workingplatforms,e.g.,theMicrosoftWindowsandtheSunUnix,arespeci¯edin
theheader¯le
iptl.workingenv.h
.Atthebaselevel,constantsforimageprocessing
arede¯nedintheheader¯le
iptl.base.h
,andspace-domainclassesformanipulation
ofdi®erentcoordinatesystemsandtime-domainclassesforevaluationofCPUspeed
arede¯nedin
iptl.geom.h
and
iptl.time.h
,respectively.Atthepixellevel,thepixel
classessuchas
GRAY8
,
GRAY16
,and
ColorRGB24
arede¯nedin
iptl.pixel.h
.
Attheimagelevel,theimagetemplate
ImageT
isde¯nedbasedonitsargument
ofpixelclasses.TheIPTLisalsodesignedforavolumetemplate,
VolumeT
,by
161
consideringpixelclassesasvoxelclasses.Atthemovielevel,wecanderivetemplates
forcolorimages(e.g.,
ImageRGB
and
ImageYCbCr
)forslices,movies,slides,
imagedisplay,andimageanalysisbasedontheimagetemplate.Similarly,basedon
FigureC.1.ArchitectureofIPTLclasstemplates.
thevolumetemplate,wecanobtainhigherleveltemplatesforspace,scene,volume
display,andvolumeanalysisatthespacelevel.
162
C.2ExampleCode
Examplecodeoftheuserinterfaceforthepixelclassesandtheimagetemplateis
givenbelow.
#include"iptl.imagechnl.h"
intmain()
f
//Conversionofpixeltypes
//
GREY8graypix=10;
FLOAT32°pix=3.5;
ColorRGBcolorpix(42,53,64);
colorpix=graypix;//Assignagrayvalue
graypix=°pix;//Truncatedata
colorpix.r=100;//Changetheredcomponent
graypix=colorpix;//Computeluminance
°pix+=20.7;//Arithmeticoperations
//Imagemanipulation
//
//ImageCreation
ImageT
<
GREY8
>
gray8imageA(HOSTRAM,128,128,GREY8(55));
ImageT
<
GREY8
>
gray8imageB(HOSTRAM,128,128,GREY8(100));
ImageT
<
GREY16
>
gray16imageC;//Anemptyimage
//Creationofcolorimages
//DataarrangementoftheimageisRGB...RGB...
ImageT
<
ColorRGB24
>
rgbimage(HOSTRAM,32,32,128);
//DataarrangementoftheimageisRRR...GGG...BBB...
ImageRGB
<
GREY8
>
rgbimagechnl(rgbimage1);
//Atemplatefunctionforconvertingimagesfromonetypetoanother
//
gray8imageA=rgbimage;//ExtractLuminance
gray16imageC=gray8imageB;//Enlargethedynamicrangeofgrayvalues
gray8imageB-=gray8imageA;//Imagesubtraction
gray8imageA[5]=100;//Assesspixelsasa1Dvector
163
gray8imageA(120,120)=200;//Assesspixelsasa2Dimage
g
//endofmain()
WereferthereadertotheIPTLreferencemanualforthedetailsoftemplateimple-
mentation.
164
Bibliography
Bibliography
[1]
VisionicsCorporation(FaceIt)
,
<
http://www.faceit.com/
>
.
[2]
FaceSnap
,
<
http://www.person-spotter.de/htdocs/english/frame
right/
produkte/facesnap/inhalt.html
>
.
[3]
ViisageTechnology
,
<
http://www.viisage.com/
>
.
[4]
EyematicInterfaces
,
<
http://www.eyematic.com/
>
.
[5]
InternationalBiometricGroup
,
<
http://www.biometricgroup.com/
>
.
[6]R.Hietmeyer,\Biometricidenti¯cationpromisesfastandsecureprocessingof
airlinepassengers,"
TheInt'lCivilAviationOrganizationJournal
,vol.55,no.
9,pp.10{11,2000.
[7]R.-L.HsuandA.K.Jain,\Semanticfacematching,"
toappearinProc.IEEE
Int'lConf.MultimediaandExpo(ICME)
,Aug.2002.
[8]P.SinhaandT.Poggio,\Ithink
I
knowthatface...,"
Nature
,vol.384,pp.404,
Dec.1996.
[9]
CaricatureZone
,
<
http://www.magixl.com/heads/view.html
>
.
[10]
BenjaminCaricature
,
<
http://www.interchile.com/benjamin
>
.
[11]
DestinyPrediction
,
<
http://www.destiny-prediction.com/face/image/pho02.
jpg
>
.
[12]
Marykateandashley.com
,
<
http://www.marykateandashley.com/
>
.
[13]
BBCnews
,
<
http://news.bbc.co.uk/hi/english/in
depth/americas/2000/us
elections/pro¯les/newsid
1012000/1012795.stm
>
.
[14]
Iransports.net
,
<
http://iransports.net/olympic/photo
gallery/08.html
>
.
[15]
MPEG7ContentSetfromHeinrichHertzInstitute
,
<
http://www.darmstadt.
gmd.de/mobile/hm/projects/MPEG7/Documents/N2466.html
>
,Oct.1998.
[16]
Corbis
,
<
http://www.corbis.com/
>
.
[17]
FaceGen,SingularInversions
,
<
http://www.facegen.com
>
.
165
[18]
TheFACEitSystem
,
<
http://www.ntu.edu.sg/eee/icis/Sta®/yhAng/faceim-
ages/live
rec.gif
>
.
[19]R.F¶eraud,O.J.Bernier,J.-E.Viallet,andM.Collobert,\Afastandaccurate
facedetectionbasedonneuralnetwork,"
IEEETrans.PatternAnalysisand
MachineIntelligence
,vol.23,no.1,pp.42{53,Jan.2001.
[20]D.MaioandD.Maltoni,\Real-timefacelocationongray-scalestaticimages,"
PatternRecognition
,vol.33,no.9,pp.1525{1539,Sept.2000.
[21]C.GarciaandG.Tziritas,\Facedetectionusingquantizedskincolorregions
mergingandwaveletpacketanalysis,"
IEEETransactionsMultimedia
,vol.
MM-1,no.3,pp.264{277,Sept.1999.
[22]H.SchneidermanandT.Kanade,\Astatisticalmethodfor3
D
objectdetection
appliedtofacesandcars,"
Proc.IEEEInt'lConf.ComputerVisionandPattern
Recognition
,pp.746{751,June2000.
[23]H.A.Rowley,S.Baluja,andT.Kanade,\Rotationinvariantneuralnetwork-
basedfacedetection,"
Proc.IEEEInt'lConf.ComputerVisionandPattern
Recognition
,pp.38{44,1998.
[24]H.A.Rowley,S.Baluja,andT.Kanade,\Neuralnetwork-basedfacedetection,"
IEEETrans.PatternAnalysisandMachineIntelligence
,vol.20,no.1,pp.23{
38,Jan.1998.
[25]K.K.SungandT.Poggio,\Example-basedlearningforview-basedhumanface
detection,"
IEEETrans.PatternAnalysisandMachineIntelligence
,vol.20,
no.1,pp.39{51,Jan.1998.
[26]K.C.YowandR.Cipolla,\Feature-basedhumanfacedetection,"
Imageand
VisionComputing
,vol.25,no.9,pp.713{735,Sept.1997.
[27]M.S.LewandN.Huijsmans,\Informationtheoryandfacedetection,"
Proc.
IEEEInt'lConf.PatternRecognition
,pp.601{605,Aug.1996.
[28]P.J.Phillips,H.Moon,S.A.Rizvi,andP.J.Rauss,\The
FERET
evaluation
methodologyforface-recognitionalgorithms,"
IEEETrans.PatternAnalysis
andMachineIntelligence
,vol.22,no.10,pp.1090{1104,Oct.2000.
[29]M.TurkandA.Pentland,\Eigenfacesforrecognition,"
JournalofCognitive
Neuroscience
,vol.3,no.1,pp.71{86,1991.
[30]
XM2VTSfacedatabase
,
<
http://xm2vtsdb.ee.surrey.ac.uk/home.html
>
.
[31]J.WengandD.L.Swets,\Facerecognition,"in
Biometrics:PersonalIdenti-
¯cationinNetworkedSociety
,A.K.Jain,R.Bolle,andS.Pankanti,Eds.,pp.
67{86,KluwerAcademic,Boston,MA,1999.
166
[32]L.Wiskott,J.M.Fellous,N.Kr_uger,andC.vonderMalsburg,\Facerecognition
byelasticbunchgraphmatching,"
IEEETrans.PatternAnalysisandMachine
Intelligence
,vol.19,no.7,pp.775{779,1997.
[33]
ReconstructionofImagesfromTransformedData&BunchGraph
,
<
http
://www.cnl.salk.edu/
»
wiskott/Projects/
f
GaborReconstruction.html,
BunchGraph.html
g
>
.
[34]P.S.PenevandJ.J.Atick,\Localfeatureanalysis:Ageneralstatisticaltheory
forobjectrepresentation,"
Network:ComputationinNeuralSystems
,vol.7,
no.3,pp.477{500,1996.
[35]
Facemodelgeneration
,
<
http://www.cs.rutgers.edu/
»
decarlo/anthface.html
>
.
[36]H.Wechsler,P.Phillips,V.Bruce,F.Soulie,andT.Huang,Eds.,
FaceRecog-
nition:FromTheorytoApplications
,Springer-Verlag,1998.
[37]R.Chellappa,C.L.Wilson,andS.Sirohey,\Humanandmachinerecognition
offaces:Asurvey,"
Proc.IEEE
,vol.83,pp.705{740,May1995.
[38]W.Zhao,R.Chellappa,A.Rosenfeld,andP.J.Phillips,\Facerecog-
nition:Aliteraturesurvey,"
CVLTechnicalReport,CenterforAu-
tomationResearch,UniversityofMarylandatCollegePark
,Oct.2000,
<
ftp://ftp.cfar.umd.edu/TRs/CVL-Reports-2000/TR4167-zhao.ps.gz
>
.
[39]
Faceblind.org
,
<
http://www.faceblind.org/research/index.php
>
.
[40]A.W.M.Smeulders,M.Worring,S.Santini,A.Gupta,andR.Jain,\Content-
basedimageretrievalattheendoftheearlyyears,"
IEEETrans.Pattern
AnalysisandMachineIntelligence
,vol.22,no.12,pp.1349{1380,Dec.2000.
[41]A.Lanitis,C.J.Taylor,andT.F.Cootes,\Towardautomaticsimulationof
aginge®ectsonfaceimages,"
IEEETrans.PatternAnalysisandMachine
Intelligence
,vol.24,no.4,Apr.2002.
[42]A.YilmazandM.GÄokmen,\Eigenhillvs.eigenfaceandeigenedge,"
Pattern
Recognition
,vol.34,no.1,pp.181{184,Jan.2001.
[43]Y.Adini,Y.Moses,andS.Ullman,\Facerecognition:Theproblemofcom-
pensatingforchangesinilluminationdirection,"
IEEETrans.PatternAnalysis
andMachineIntelligence
,vol.19,no.7,pp.721{732,July1997.
[44]J.B.Burns,\Recognitionviaconsensusoflocalmomentsofbrightnessand
orientation,"
Proc.IEEEInt'lConf.ComputerVisionandPatternRecognition
,
pp.891{898,June1996.
[45]G.W.Cottrell,M.N.Dailey,C.Padgett,andR.Adolphs,\Isallfaceprocessing
holistic?theviewfromUCSD,"in
Computational,Geometric,andProcess
PerspectivesonFacialCognition:ContextsandChallenges
,M.Wengerand
J.Townsend,Eds.,LawrenceErlbaumAssociates,Mahwah,NJ,2000.
167
[46]Li-FenChen,Hong-YuanMarkLiao,Ja-ChenLin,andChin-ChuanHan,\Why
recognitioninastatistics-basedfacerecognitionsystemshouldbebasedonthe
purefaceportion:aprobabilisticdecision-basedproof,"
PatternRecognition
,
vol.34,no.7,pp.1393{1403,July2001.
[47]C.LiuandH.Wechsler,\Evolutionarypursuitanditsapplicationtoface
recognition,"
IEEETrans.PatternAnalysisandMachineIntelligence
,vol.22,
no.6,pp.570{582,June2000.
[48]G.RhodesandT.Tremewan,\Understandingfacerecognition:Caricature
e®ects,inversion,andthehomogeneityproblem,"
VisualCognition
,vol.1,pp.
257{311,1994.
[49]V.BruceandM.Burton,Eds.,
ProcessingImagesofFaces
,Ablexpublishing,
Norwood,NJ,1992.
[50]M.B.LewisandR.A.Johnston,\Understandingcaricaturesoffaces,"
Quarterly
JournalofExperimentalPsychologyA
,vol.51,no.2,pp.321{346,May1998.
[51]P.E.MorrisandL.H.V.Wickham,\Typicalityandfacerecognition:Acritical
re-evaluationofthetwofactortheory,"
QuarterlyJournalofExperimental
PsychologyA
,vol.54,no.3,pp.863{877,Aug.2001.
[52]B.BatesandJ.Cleese,Eds.,
TheHumanFace
,Dorlingkindersleypublishing
Inc.,NewYork,NY,1992.
[53]H.LederandV.Bruce,\Wheninvertedfacesarerecognized:Theroleof
con¯guralinformationinfacerecognition,"
QuarterlyJournalofExperimental
PsychologyA
,vol.53,no.2,pp.513{536,May2000.
[54]E.HjelmasandJ.Wroldsen,\Recognizingfacesfromtheeyesonly,"
Proc.11th
ScandinavianConf.ImageAnalysis
,June1999,
<
http://citeseer.nj.nec.com/
hjelmas99recognizing.html
>
.
[55]R.G.UhlJr.andN.daVitoriaLobo,\Aframeworkforrecognizingafacial
imagefromapolicesketch,"
Proc.IEEEInt'lConf.ComputerVisionand
PatternRecognition
,pp.586{593,June1996.
[56]H.ChenandY.Q.Xu,H.Y.Shum,S.C.Zhu,andN.N.Zhen,\Example-based
facialsketchgenerationwithnon-parametricsampling,"
Proc.IEEEInt'lConf.
ComputerVision
,Vancouver,Canada,July2001.
[57]S.E.Brennan,\Caricaturegenerator:Thedynamicexaggerationoffacesby
computer,"
Leonardo
,vol.18,no.3,pp.170{178,1985.
[58]R.MauroandM.Kubovy,\Caricatureandfacerecognition,"
Memory&
Cognition
,vol.20,no.4,1992.
168
[59]M.Grudin,\Oninternalrepresentationinfacerecognitionsystems,"
Pattern
Recognition
,vol.33,no.7,pp.1161{1177,July2000.
[60]K.M.LamandH.Yan,\Ananalytic-to-holisticapproachforfacerecognition
basedonasinglefrontalview,"
IEEETrans.PatternAnalysisandMachine
Intelligence
,vol.20,no.7,pp.673{686,July1998.
[61]D.DeCarloandD.Metaxas,\Optical°owconstraintsondeformablemodels
withapplicationstofacetracking,"
Int'lJournalComputerVision
,vol.38,no.
2,pp.99{127,July2000.
[62]E.Osuna,R.Freund,andF.Girosi,\Trainingsupportvectormachines:an
applicationtofacedetection,"
Proc.IEEEInt'lConf.ComputerVisionand
PatternRecognition
,pp.130{136,June1997.
[63]M.A.TurkandA.P.Pentland,\Facerecognitionusingeigenfaces,"
Proc.IEEE
Int'lConf.ComputerVisionandPatternRecognition
,pp.586{591,June1991.
[64]A.Pentland,B.Moghaddam,andT.Starner,\View-basedandmodular
eigenspacesforfacerecognition,"
Proc.IEEEInt'lConf.ComputerVision
andPatternRecognition
,pp.84{91,June1994.
[65]R.BrunelliandT.Poggio,\Facerecognition:Featuresvs.templates,"
IEEE
Trans.PatternAnalysisandMachineIntelligence
,vol.15,no.10,pp.1042{
1052,Oct.1993.
[66]C.Kotropoulos,A.Tefas,andI.Pitas,\Frontalfaceauthenticationusing
morphologicalelasticgraphmatching,"
IEEETrans.ImageProcessing
,vol.9,
pp.555{560,Apr.2000.
[67]
Proc.IEEEInt'lConf.AutomaticFaceandGestureRecognition
,2000,
<
http://www-prima.inrialpes.fr/FG2000/
>
.
[68]P.Phillips,H.Wechsler,J.Huang,andP.Rauss,\The
FERET
database
andevaluationprocedureforface-recognitionalgorithms,"
ImageandVision
Computing
,vol.16,no.5,pp.295{306,Mar.1998.
[69]F.I.ParkeandK.Waters,\Appendix1:Three-dimensionalmusclemodelfa-
cialanimation,"in
ComputerFacialAnimation
,pp.337{338,A.K.Peters,
1996,
<
http://www.crl.research.digital.com/publications/books/waters/wa-
ters
book.html
>
.
[70]G.Miller,E.Ho®ert,S.E.Chen,E.Patterson,D.Blackketter,S.Rubin,S.A.
Applin,D.Yim,andJ.Hanan,\Thevirtualmuseum:Interactive3Dnaviga-
tionofamultimediadatabase,"
TheJournalofVisualizationandComputer
Animation
,vol.3,no.3,pp.183{197,July1992.
169
[71]H.Fuchs,G.Bishop,K.Arthur,L.McMillan,R.Bajcsy,S.Lee,H.Farid,and
T.Kanade,\Virtualspaceteleconferencingusingaseaofcameras,"
Technical
Report,DepartmentofComputerScience,UniversityofNorthCarolina-Chapel
Hill,NumberTR94-033
,May1994.
[72]M.J.T.Reinders,P.J.L.vanBeek,B.Sankur,andJ.C.A.vander
Lubbe,\Facialfeaturelocalizationandadaptationofagenericface
modelformodel-basedcoding,"
SignalProcessing:ImageCommunica-
tion
,vol.7,no.1,pp.57{74,Mar.1995,
<
http://www-it.et.tudelft.nl/
itbibliography/reports/1995/journal/imagecom95.reinders.ps.gz
>
.
[73]A.Hilton,D.Beresford,T.Gentils,R.Smith,andW.Sun,\Virtualpeo-
ple:Capturinghumanmodelstopopulatevirtualworlds,"
Proc.IEEEConf.
ComputerAnimation
,pp.174{185,May1999.
[74]R.T.Azuma,\Asurveyofaugmentedreality,"
Presence:Teleoperatorsand
VirtualEnvironments
,vol.6,no.4,pp.355{385,Aug.1997.
[75]G.TaubinandJ.Rossignac,\Geometriccompressionthroughtopological
surgery,"
ACMTrans.Graphics
,vol.17,pp.84{115,Apr.1998.
[76]M.Lounsbery,T.D.DeRose,andJ.Warren,\Multiresolutionanalysisfor
surfacesofarbitrarytopologicaltype,"
ACMTrans.Graphics
,vol.16,pp.
34{73,Jan.1997.
[77]M.Kass,A.Witkin,andD.Terzopoulos,\Snakes:activecontourmodels,"
Int'lJournalComputerVision
,vol.1,no.4,pp.321{331,1988.
[78]W.-S.HwangandJ.Weng,\Hierarchicaldiscriminantregression,"
IEEETrans.
PatternAnalysisandMachineIntelligence
,vol.22,pp.1277{1293,Nov.2000.
[79]J.Weng,J.McClelland,A.Pentland,O.Sporns,I.Stockman,M.Sur,and
E.Thelen,\Autonomousmentaldevelopmentbyrobotsandanimals,"
Science
,
vol.291,no.5504,pp.599{600,Jan.2000.
[80]J.Weng,C.H.Evans,andW.S.Hwang,\Anincrementallearningmethod
forfacerecognitionundercontinuousvideostream,"
Proc.IEEEInt'lConf.
AutomaticFaceandGestureRecognition
,pp.251{256,Mar.2000.
[81]M.PanticandL.J.M.Rothkrantz,\Automaticanalysisoffacialexpressions:
Thestateoftheart,"
IEEETrans.PatternAnalysisandMachineIntelligence
,
vol.22,no.12,pp.1424{1445,Dec.1996.
[82]M.-H.Yang,N.Ahuja,andD.Kriegman,\Detectingfacesinimages:Asurvey,"
IEEETrans.PatternAnalysisandMachineIntelligence
,vol.24,no.1,pp.34{
58,Jan.2001.
[83]E.HjelmandB.K.Low,\Facedetection:Asurvey,"
ComputerVisionand
ImageUnderstanding
,vol.83,pp.236{274,Sept.2001.
170
[84]M.Abdel-MottalebandA.Elgammal,\Facedetectionincomplexenvironments
fromcolorimages,"
Proc.IEEEInt'lConf.ImageProcessing
,pp.622{626,
1999.
[85]H.Wu,Q.Chen,andM.Yachida,\Facedetectionfromcolorimagesusinga
fuzzypatternmatchingmethod,"
IEEETrans.PatternAnalysisandMachine
Intelligence
,vol.21,pp.557{563,June1999.
[86]A.Colmenarez,B.Frey,andT.Huang,\Detectionandtrackingoffacesand
facialfeatures,"
Proc.IEEEInt'lConf.ImageProcessing
,pp.657{661,Oct.
1999.
[87]S.C.DassandA.K.Jain,\Markovfacemodels,"
Proc.IEEEInt'lConf.
ComputerVision
,pp.680{687,July2001.
[88]A.J.ColmenarezandT.S.Huang,\Facedetectionwithinformationbasedmax-
imumdiscrimination,"
Proc.IEEEInt'lConf.ComputerVisionandPattern
Recognition
,pp.782{787,June1997.
[89]V.BakicandG.Stockman,\Menuselectionbyfacialaspect,"
Proc.Vision
Interface,Canada
,pp.203{209,May1999.
[90]K.SobottkaandI.Pitas,\Anovelmethodforautomaticfacesegmentation,
facialfeatureextractionandtracking,"
SignalProcessing:ImageCommunica-
tion
,vol.12,no.3,pp.263{281,June1998.
[91]H.D.Ellis,M.A.Jeeves,F.Newcombe,andA.Young,Eds.,
AspectsofFace
Processing
,MartinusNijho®Publishers,Dordrecht,Netherlands,1985.
[92]O.A.UwechueandA.S.Pandya,Eds.,
HumanFaceRecognitionUsingThird-
orderSyntheticNeuralNetworks
,KluwerAcademicPublishers,Norwell,MA,
1997.
[93]P.L.Hallinan,G.G.Gordon,A.L.Yuille,P.Giblin,andD.Mumford,
Two-and
Three-DimensionalPatternsoftheFace
,A.K.Peters,Natick,MA,1999.
[94]S.Gong,S.J.McKenna,andA.Psarrou,
DynamicVision:FromImagesto
FaceRecognition
,ImperialCollegePress,London,1999.
[95]
MITfacedatabase
,
<
ftp://whitechapel.media.mit.edu/pub/images/
>
.
[96]
Yalefacedatabase
,
<
http://cvc.yale.edu/projects/yalefaces/yalefaces.html
>
.
[97]
ARfacedatabase
,
<
http://rvl1.ecn.purdue.edu/
»
aleix/aleix
face
DB.html
>
.
[98]
Olivettifacedatabase
,
<
http://www.cam-orl.co.uk/facedatabase.html
>
.
[99]B.MoghaddamandA.Pentland,\Facerecognitionusingview-basedandmod-
ulareigenspaces,"
AutomaticSystemsfortheIdenti¯cationandInspectionof
Humans,Proc.SPIE
,vol.2257,pp.12{21,July1994.
171
[100]B.MoghaddamandA.Pentland,\Probabilisticvisuallearningforobjectrep-
resentation,"
IEEETrans.PatternAnalysisandMachineIntelligence
,vol.19,
no.7,pp.696{710,July1997.
[101]P.S.PenevandL.Sirovich,\Theglobaldimensionalityoffacespace,"
Proc.
IEEEInt'lConf.AutomaticFaceandGestureRecognition
,pp.264{270,Mar.
2000.
[102]I.J.Cox,J.Ghosn,andP.N.Yianilos,\Feature-basedfacerecognitionus-
ingmixture-distance,"
Proc.IEEEInt'lConf.ComputerVisionandPattern
Recognition
,pp.209{216,June1996.
[103]M.S.Kamel,H.C.Shen,A.K.C.Wong,andR.I.Campeanu,\Systemforthe
recognitionofhumanfaces,"
IBMSystemsJournal
,vol.32,no.2,pp.307{320,
1993.
[104]I.Craw,N.Costen,T.Kato,G.Robertson,andS.Akamatsu,\Automaticface
recognition:Combiningcon¯gurationandtexture,"
Proc.IEEEInt'lConf.
AutomaticFaceandGestureRecognition
,pp.53{58,Sept.1995.
[105]G.G.GordonandM.E.Lewis,\Facerecognitionusingvideoclipsandmug
shots,"
Proc.O±ceofNationalDrugControlPolicy(ONDCP)Int'lTechni-
calSymposium
,Oct.1995,
<
http://http://www.vincent-net.com/gaile/papers
/ONDCPPaper/ONDCPPaper.html
>
.
[106]R.Lengagne,J.-P.Tarel,andO.Monga,\From2
d
imagesto3
d
facegeometry,"
Proc.IEEEInt'lConf.AutomaticFaceandGestureRecognition
,pp.301{306,
Oct.1996.
[107]J.J.Atick,P.A.Gri±n,andA.N.Redlich,\Statisticalapproachtoshapefrom
shading:Reconstructionof3
D
facesurfacesfromsingle2
D
images,"
Neural
Computation
,vol.8,no.6,pp.1321{1340,Aug.1996.
[108]Y.YanandJ.Zhang,\Rotation-invariant3
D
recognitionforfacerecognition,"
Proc.IEEEInt'lConf.ImageProcessing
,vol.1,pp.156{160,Oct.1998.
[109]W.Y.ZhaoandR.Chellappa,\3
D
modelenhancedfacerecognition,"
Proc.
IEEEInt'lConf.ImageProcessing
,Sept.2000,
<
http://www.cfar.umd.edu/
»
wyzhao/icip003Dmodel.ps
>
.
[110]P.SinhaandT.Poggio,\Roleoflearninginthree-dimensionalformpercep-
tion,"
Nature
,vol.384,pp.460{463,Dec.1996.
[111]D.DeCarlo,D.Metaxas,andM.Stone,\Ananthropometricfacemodelusing
variationaltechniques,"
Proc.SIGGRAPHConf.
,pp.67{74,July1998.
[112]Q.ChenandG.Medioni,\Buildinghumanfacemodelsfromtwoimages,"
IEEE2ndWorkshoponMultimediaSignalProcessing
,pp.117{122,Dec.1998.
172
[113]B.KimandP.Burger,\Depthandshapefromshadingusingthephotometric
stereomethod,"
ComputerVision,Graphics,andImageProcessing:Image
Understanding
,vol.54,no.3,pp.416{427,1991.
[114]D.R.HougenandN.Ahuja,\Estimationofthelightsourcedistributionand
itsuseinintegratedshaperecoveryfromstereoandshading,"
Proc.IEEEInt'l
Conf.ComputerVision
,pp.148{155,May1993.
[115]J.Cryer,P.-S.Tsai,andM.Shah,\Integrationofshapefromshadingand
stereo,"
PatternRecognition
,vol.28,no.7,pp.1033{1043,July1995.
[116]F.I.ParkeandK.Waters,\Modelingfaces,"in
ComputerFacialAnimation
,
pp.55{104,A.K.Peters,Wellesley,MA,1996.
[117]B.Guenter,C.Grimm,D.Wood,H.Malvar,andF.Pighin,\Makingfaces,"
Proc.SIGGRAPHConf.
,pp.55{66,July1998.
[118]L.YinandA.Basu,\
MPEG
4facemodelingusing¯ducialpoints,"
Proc.
IEEEInt'lConf.ImageProcessing
,pp.109{112,Oct.1997.
[119]W.LeeandN.Magnenat-Thalmann,\Fastheadmodelingforanimation,"
ImageandVisionComputing
,vol.18,no.4,pp.355{364,Mar.2000.
[120]R.Lengagne,P.Fua,andO.Monga,\3Dstereoreconstructionofhumanfaces
drivenbydi®erentialconstraints,"
ImageandVisionComputing
,vol.18,no.
4,pp.337{343,Mar.2000.
[121]P.Fua,\Usingmodel-drivenbundle-adjustmenttomodelheadsfromrawvideo
sequences,"
Proc.IEEEInt'lConf.ComputerVision
,pp.46{53,Sept.1999.
[122]J.Ahlberg,\Anexperimenton3
D
facemodeladaptationusingtheactive
appearancealgorithm,"
TechnicalReport,Dept.ofEE,LinkÄopingUniversity,
Sweden
,Jan.2001.
[123]J.Ahlberg,\Candide-3-anupdatedparameterizedface,"
ReportNo.LiTH-
ISY-R-2326,Dept.ofEE,LinkÄopingUniversity,Sweden
,Jan.2001.
[124]A.A.Amini,T.E.Weymouth,andR.C.Jain,\Usingdynamicprogramming
forsolvingvariationalproblemsinvision,"
IEEETrans.PatternAnalysisand
MachineIntelligence
,vol.12,no.9,pp.855{867,Sept.1990.
[125]B.OlstadandA.H.Torp,\Encodingofaprioriinformationinactivecontour
models,"
IEEETrans.PatternAnalysisandMachineIntelligence
,vol.18,no.
9,pp.863{872,Sept.1996.
[126]L.H.StaibandJ.S.Duncan,\Boundary¯ndingwithparametricallydeformable
models,"
IEEETrans.PatternAnalysisandMachineIntelligence
,vol.14,no.
11,pp.1061{1075,Nov.1992.
173
[127]C.Y.XuandJ.L.Prince,\Snakes,shapes,andgradientvector°ow,"
IEEE
Trans.ImageProcessing
,vol.7,no.3,pp.359{369,Mar.1998.
[128]R.Goldenberg,R.Kimmel,E.Rivlin,andM.Rudzsky,\Fastgeodesicactive
contours,"
IEEETrans.ImageProcessing
,vol.10,no.10,pp.1467{1475,Oct.
2001.
[129]X.M.Pardo,M.J.Carreira,A.Mosquera,andD.Cabello,\AsnakeforCT
imagesegmentationintegratingregionandedgeinformation,"
ImageandVision
Computing
,vol.19,no.7,pp.461{475,May2001.
[130]T.F.ChanandL.A.Vese,\Activecontourswithoutedges,"
IEEETrans.Image
Processing
,vol.10,no.2,pp.266{277,Feb.2001.
[131]C.Chesnaud,P.Refregier,andV.Boulet,\Statisticalregionsnake-basedseg-
mentationadaptedtodi®erentphysicalnoisemodels,"
IEEETrans.Pattern
AnalysisandMachineIntelligence
,vol.21,no.11,pp.1145{1157,Nov.1999.
[132]S.C.ZhuandA.Yuille,\Regioncompetition-unifyingsnakes,regiongrowing,
andBayes/MDLformultibandimagesegmentation,"
IEEETrans.Pattern
AnalysisandMachineIntelligence
,vol.18,no.9,pp.884{900,Sept.1996.
[133]J.IvinsandJ.Porrill,\Statisticalsnakes:activeregionmodels,"
Proc.Fifth
BritishMachineVisionConf.(BMVC)
,vol.2,pp.377{386,Dec.1994.
[134]T.AbeandY.Matsuzawa,\Multipleactivecontourmodelswithapplication
toregionextraction,"
Proc.15thInt'lConf.PatternRecognition
,vol.1,pp.
626{630,Sept.2000.
[135]V.Chalana,D.T.Linker,D.R.Haynor,andY.M.Kim,\Amultipleactive
contourmodelforcardiacboundarydetectiononechocardiographicsequences,"
IEEETrans.MedicalImaging
,vol.15,no.3,pp.290{298,1996.
[136]B.Fleming,
3DModeling&Surfacing
,MorganKaufmann,SanFrancisco,
California,1999.
[137]M.Deering,\Geometrycompression,"
Proc.SIGGRAPHConf.
,pp.13{20,
Aug.1995.
[138]M.Eck,T.DeRose,T.Duchamp,H.Hoppe,M.Lounsbery,andW.Stuetzle,
\Multiresolutionanalysisofarbitrarymeshes,"
Proc.SIGGRAPHConf.
,pp.
173{182,Aug.1995.
[139]R.-L.Hsu,A.K.Jain,andM.Tuceryan,\Multiresolutionmodelcompression
using3-
D
wavelets,"
Proc.AsianConf.ComputerVision
,pp.74{79,Jan.2000.
[140]A.R.Calderbank,I.Daubechies,W.Sweldens,andB.-L.Yeo,\Losslessimage
compressionusingintegertointegerwavelettransforms,"
Proc.IEEEInt'l
Conf.ImageProcessing
,vol.1,pp.596{599,Oct.1997.
174
[141]M.D.AdamsandF.Kossentini,\Reversibleinteger-to-integerwavelettrans-
formsforimagecompression:Performanceevaluationandanalysis,"
Proc.
IEEEInt'lConf.ImageProcessing
,vol.9,no.6,pp.1010{1024,June2000.
[142]
IBMQueryByImageContent(QBIC)
,
<
http://wwwqbic.almaden.ibm.com/
>
.
[143]
Photobook
,
<
http://www-white.media.mit.edu/vismod/demos/photobook/
>
.
[144]M.Abdel-Mottaleb,N.Dimitrova,R.Desai,andJ.Martino,\Conivas:
Content-basedimageandvideoaccesssystem,"
Proc.FourthACMMultimedia
Conf.
,pp.427{428,Nov.1996.
[145]
FourEyes
,
<
http://www-white.media.mit.edu/vismod/demos/photobook/
foureyes/
>
.
[146]
Virage
,
<
http://www.virage.com/
>
.
[147]J.-Y.Chen,C.Taskiran,E.J.Delp,andC.A.Bouman,\Vibe:Anew
paradigmforvideodatabasebrowsingandsearch,"
Proc.IEEEWorkshop
Content-BasedAccessofImageandVideoLibraries
,pp.96{100,June1998,
<
http://stargate.ecn.purdue.edu/
»
ips/ViBE/
>
.
[148]S.-F.Chang,W.Chen,H.Meng,H.Sundaram,andD.Zhong,
\Anautomatedcontent-basedvideosearchsystemusingvisualcues,"
Proc.ACMMultimedia
,vol.18,no.1,pp.313{324,Nov.1997,
<
http://www.ctr.columbia.edu/VideoQ/
>
.
[149]
Visualseek
,
<
http://www.ctr.columbia.edu/visualseek/
>
.
[150]W.Y.MaandB.S.Manjunath,\Netra:Atoolboxfornavigatinglargeimage
databases,"
Proc.IEEEInt'lConf.ImageProcessing
,vol.1,pp.568{571,Oct.
1997.
[151]S.Mehrotra,Y.Rui,M.Ortega,andT.S.Huang,\Supportingcontent-based
queriesoverimagesinMARS,"
Proc.IEEEInt'lConf.MultimediaComputing
andSystems
,pp.632{633,June1997.
[152]J.Laaksonen,M.Koskela,S.Laakso,andE.Oja,\Picsom-content-based
imageretrievalwithself-organizingmaps,"
PatternRecognitionLetters
,vol.
21,no.13-14,pp.1199{1207,Dec.2000,
<
http://www.cis.hut.¯/picsom/
>
.
[153]M.S.Lew,\Next-generationwebsearchesforvisualcontent,"
IEEEComputer
,
pp.46{53,Nov.2000,
<
http://skynet.liacs.nl
>
.
[154]A.Vailaya,M.Figueiredo,A.K.Jain,andH.-J.Zhang,\Imageclassi¯cation
forcontent-basedindexing,"
IEEETrans.ImageProcessing
,vol.10,no.1,pp.
117{130,Jan.2001.
[155]C.A.Poynton,
ATechnicalIntroductiontoDigitalVideo
,JohnWiley&Sons,
NewYork,1996.
175
[156]L.M.Bergasa,M.Mazo,A.Gardel,M.A.Sotelo,andL.Boquet,\Unsupervised
andadaptivegaussianskin-colormodel,"
ImageandVisionComputing
,vol.
18,pp.987{1003,Sept.2000.
[157]J.C.Terrillon,M.N.Shirazi,H.Fukamachi,andS.Akamatsu,\Comparative
performanceofdi®erentskinchrominancemodelsandchrominancespacesfor
theautomaticdetectionofhumanfacesincolorimages,"
Proc.IEEEInt'l
Conf.AutomaticFaceandGestureRecognition
,pp.54{61,Mar.2000.
[158]E.SaberandA.M.Tekalp,\Frontal-viewfacedetectionandfacialfeature
extractionusingcolor,shapeandsymmetrybasedcostfunctions,"
Pattern
RecognitionLetters
,vol.19,no.8,pp.669{680,June1998.
[159]M.J.JonesandJ.M.Rehg,\Statisticalcolormodelswithapplicationtoskin
detection,"
Proc.IEEEInt'lConf.ComputerVisionandPatternRecognition
,
vol.1,pp.274{280,June1999.
[160]B.MenserandM.Brunig,\Locatinghumanfacesincolorimageswithcomplex
background,"
IntelligentSignalProcessingandCommunicationsSystems
,pp.
533{536,Dec.1999.
[161]T.Horprasert,Y.Yacoob,andL.S.Davis,\Computing3-Dheadorientation
fromamonocularimage,"
Proc.IEEEInt'lConf.AutomaticFaceandGesture
Recognition
,pp.242{247,Oct.1996.
[162]A.NikolaidisandI.Pitas,\Facialfeatureextractionanddeterminationof
pose,"
PatternRecognition
,vol.33,pp.1783{1791,2000.
[163]W.Huang,Q.Sun,C.-P.Lam,andJ.-K.Wu,\Arobustapproachtofaceand
eyesdetectionfromimageswithclutteredbackground,"
Proc.IEEEInt'lConf.
PatternRecognition
,vol.1,pp.110{114,Aug.1998.
[164]K.M.LamandH.Yan,\Locatingandextractingtheeyeinhumanfaceimages,"
PatternRecognition
,vol.29,no.5,pp.771{779,1996.
[165]A.Lanitis,C.J.Taylor,andT.F.Cootes,\Automaticinterpretationandcod-
ingoffaceimagesusing°exiblemodels,"
IEEETrans.PatternAnalysisand
MachineIntelligence
,vol.19,no.7,pp.743{756,July1997.
[166]S.SiroheyandA.Rosenfeld,\Eyedetection,"
TechnicalReportCS-TR-3971,
Univ.ofMaryland
,Dec.1998.
[167]F.Smeraldi,O.Carmona,andJ.BigÄun,\SaccadicsearchwithGaborfea-
turesappliedtoeyedetectionandreal-timeheadtracking,"
ImageandVision
Computing
,vol.18,no.4,pp.323{329,2000.
[168]D.StorkandMHenneke,\Speechreading:Anoverviewofimageprocess-
ing,featureextraction,sensoryintegrationandpatternrecognitiontechniques,"
Proc.IEEEInt'lConf.AutomaticFaceandGestureRecognition
,pp.xvi{xxvi,
1996.
176
[169]P.T.JackwayandM.Deriche,\Scale-spacepropertiesofthemultiscalemor-
phologicaldilation-erosion,"
IEEETrans.PatternAnalysisandMachineIntel-
ligence
,vol.18,pp.38{51,Jan.1996.
[170]J.Canny,\Acomputationalapproachtoedgedetection,"
IEEETrans.Pattern
AnalysisandMachineIntelligence
,vol.8,pp.679{698,Nov.1986.
[171]
TheChampionDatabase
,
<
http://www.lib¯nd.unl.edu/alumni/events/break-
fast
for
champions.htm
>
,Mar.2001.
[172]
Yahoonewsphotos
,
<
http://dailynews.yahoo.com/h/g/ts/
>
,Dec.2001.
[173]R.-L.HsuandA.K.Jain,\Facemodelingforrecognition,"
Proc.IEEEInt'l
Conf.ImageProcessing
,vol.2,pp.693{696,Oct.2001.
[174]
SAMPLrangedatabases
,
<
http://sampl.eng.ohio-state.edu/
»
sampl/data/
3DDB/RID/minolta/faceimages.0300/
>
.
[175]R.-L.Hsu,M.Abdel-Mottaleb,andA.K.Jain,\Facedetectionincolorimages,"
IEEETrans.PatternAnalysisandMachineIntelligence
,vol.24,no.5,pp.696{
706,May2002.
[176]D.TerzopoulosandK.Waters,\Analysisandsynthesisoffacialimagesequences
usingphysicalandanatomicalmodels,"
IEEETrans.PatternAnalysisand
MachineIntelligence
,vol.15,no.6,pp.569{579,1993.
[177]D.Reisfeld,H.Wolfson,,andY.Yeshurun,\Contexfreeattentionaloperators:
Thegeneralizedsymmetrytransform,"
Int'lJournalComputerVision
,vol.14,
pp.119{130,1995.
[178]H.Breu,J.Gil,D.Kirkpatrick,andM.Werman,\Lineartimeeuclideandis-
tancetransformalgorithms,"
IEEETrans.PatternAnalysisandMachineIn-
telligence
,vol.17,no.5,pp.529{533,May1995.
[179]R.Zhang,P.-S.Tsai,J.Cryer,andM.Shah,\Shapefromshading:asurvey,"
IEEETrans.PatternAnalysisandMachineIntelligence
,vol.21,no.8,pp.
690{706,Aug.1999.
[180]E.TruccoandA.Verri,
IntroductoryTechniquesfor3-DComputerVision
,
PrenticeHall,1999.
[181]V.Caselles,R.Kimmel,,andG.Sapiro,\Geodesicactivecontours,"
Int'l
JournalComputerVision
,vol.22,no.1,pp.61{79,1997.
[182]D.AdalsteinssonandJ.A.Sethian,\Afastlevelsetmethodforpropagating
interfaces,"
JournalComputationalPhysics
,vol.118,pp.269{277,1995.
[183]X.Han,C.Xu,andJ.L.Prince,\Atopologypreservingdeformablemodelusing
levelsets,"
Proc.IEEEInt'lConf.ComputerVisionandPatternRecognition
,
vol.II,pp.765{770,Dec.2001.
177
[184]H.Cherno®,\Theuseoffacestorepresentpointsink-dimensionalspacegraph-
ically,"
JournaloftheAmericalStatisticsAssociation
,vol.68,pp.361{368,
1973.
[185]R.-L.HsuandA.K.Jain,\Detectionandtrackingofmultiplefacesinvideo,"
TechnicalReportMSU-CSE-02-13
,vol.Dept.ComputerScience&Engineering,
pp.MichiganStateUniversity,May2002.
[186]
IntelImageProcessingLibrary
,
<
http://developer.intel.com/software/products
/per°ib/ipl/index.htm
>
.
[187]
IntelOpenSourceComputerVisionLibrary
,
<
http://developer.intel.com/soft-
ware/opensource/cv°/opencv
download.htm
>
.
[188]S.E.Umbaugh,
ComputerVisionandImageProcessing:APracticalApproach
UsingCVIPTools
,PrenticeHall,UpperSaddleRiver,NJ,1997.
178
